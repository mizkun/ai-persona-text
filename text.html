<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>人物らしさを工学問題として定義する</title>

    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    <!-- Mermaid for diagrams -->
    <script>
        window.mermaidConfig = {
            startOnLoad: false,
            theme: 'default',
            securityLevel: 'loose'
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&family=Source+Code+Pro:wght@400;500&display=swap" rel="stylesheet">

    <style>
        :root {
            --primary-color: #2563eb;
            --primary-light: #3b82f6;
            --text-color: #1f2937;
            --text-light: #4b5563;
            --bg-color: #ffffff;
            --bg-secondary: #f9fafb;
            --border-color: #e5e7eb;
            --code-bg: #f3f4f6;
            --header-bg: #f8f9fa;
            --toc-width: 280px;
        }

        [data-theme="dark"] {
            --primary-color: #3b82f6;
            --primary-light: #60a5fa;
            --text-color: #e5e7eb;
            --text-light: #9ca3af;
            --bg-color: #111827;
            --bg-secondary: #1f2937;
            --border-color: #374151;
            --code-bg: #1f2937;
            --header-bg: #1f2937;
        }

        * {
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Noto Sans JP', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            margin: 0;
            padding: 0;
            font-size: 16px;
        }

        /* Header styles */
        header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 60px;
            background: var(--header-bg);
            border-bottom: 1px solid var(--border-color);
            display: flex;
            align-items: center;
            padding: 0 2rem;
            z-index: 1002;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .header-hamburger {
            background: none;
            border: none;
            font-size: 1.5rem;
            color: var(--primary-color);
            cursor: pointer;
            padding: 0.5rem;
            border-radius: 6px;
            transition: background 0.2s ease;
        }

        .header-hamburger:hover {
            background: var(--bg-secondary);
        }

        .header-settings {
            background: none;
            border: none;
            color: var(--primary-color);
            cursor: pointer;
            padding: 0.5rem;
            border-radius: 4px;
            position: absolute;
            right: 1rem;
            top: 50%;
            transform: translateY(-50%);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .header-settings svg {
            width: 20px;
            height: 20px;
            transition: transform 0.2s ease;
        }

        .header-settings:hover {
            background: var(--bg-secondary);
        }

        .header-settings:hover svg {
            transform: rotate(90deg);
        }

        /* Settings Modal */
        .settings-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background: rgba(0, 0, 0, 0.5);
            z-index: 2000;
            justify-content: center;
            align-items: center;
        }

        .settings-modal.open {
            display: flex;
        }

        .settings-modal-content {
            background: var(--bg-color);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 2rem;
            min-width: 300px;
            max-width: 400px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .settings-modal h3 {
            margin: 0 0 1.5rem 0;
            color: var(--primary-color);
            font-size: 1.2rem;
        }

        .settings-modal-item {
            margin-bottom: 1.5rem;
        }

        .settings-modal-item:last-child {
            margin-bottom: 0;
        }

        .settings-modal .theme-toggle-section {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1.5rem;
        }

        .settings-close {
            position: absolute;
            top: 1rem;
            right: 1rem;
            background: none;
            border: none;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--text-light);
        }

        .header-title {
            margin-left: 1rem;
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--text-color);
        }

        /* TOC styles */
        #toc {
            position: fixed;
            top: 60px;
            left: 0;
            width: var(--toc-width);
            height: calc(100vh - 60px);
            overflow-y: auto;
            background: var(--bg-secondary);
            border-right: 1px solid var(--border-color);
            padding: 1.5rem;
            font-size: 0.9rem;
            transform: translateX(0);
            transition: transform 0.3s ease;
            z-index: 1000;
            box-shadow: 2px 0 12px rgba(0, 0, 0, 0.1);
        }

        #toc.hidden {
            transform: translateX(-100%);
        }


        #toc h2 {
            font-size: 1.1rem;
            margin: 0 0 1rem 0;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--primary-color);
            color: var(--primary-color);
        }

        .progress-section {
            margin-bottom: 1.5rem;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 1rem;
        }


        .theme-toggle-section {
            margin-bottom: 1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .theme-toggle {
            background: var(--bg-color);
            border: 1px solid var(--border-color);
            border-radius: 20px;
            padding: 0.3rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 0.8rem;
            color: var(--text-light);
            transition: all 0.3s ease;
        }

        .theme-toggle:hover {
            border-color: var(--primary-color);
        }

        .theme-toggle-icon {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background: var(--primary-color);
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.9rem;
            transition: all 0.3s ease;
        }

        .toc-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .toc-list ul {
            list-style: none;
            padding-left: 1rem;
            margin: 0.25rem 0;
        }

        .toc-list li {
            margin: 0.3rem 0;
        }

        .toc-list a {
            color: var(--text-light);
            text-decoration: none;
            display: block;
            padding: 0.2rem 0;
            border-left: 2px solid transparent;
            padding-left: 0.5rem;
            transition: all 0.2s;
        }

        .toc-list a:hover {
            color: var(--primary-color);
            border-left-color: var(--primary-color);
        }

        .toc-h1 > a {
            font-weight: 700;
            color: var(--text-color);
        }

        .toc-h2 > a {
            font-weight: 500;
        }

        .toc-h3 > a {
            font-size: 0.85rem;
        }

        /* Reading Progress Styles */
        .toc-item {
            display: flex;
            align-items: flex-start;
            gap: 0.5rem;
            padding: 0.2rem 0;
        }

        .toc-checkbox {
            margin-top: 0.3rem;
            cursor: pointer;
            accent-color: var(--primary-color);
        }

        .toc-item a {
            flex: 1;
            margin-top: 0;
            padding-top: 0;
        }

        .toc-item.completed a {
            text-decoration: line-through;
            opacity: 0.7;
        }

        .progress-bar {
            margin: 1rem 0;
            background: var(--border-color);
            border-radius: 10px;
            height: 20px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--primary-color), var(--primary-light));
            transition: width 0.3s ease;
            border-radius: 10px;
        }

        .progress-text {
            font-size: 0.8rem;
            color: var(--text-light);
            margin-top: 0.5rem;
            text-align: center;
        }

        .reset-progress {
            background: none;
            border: 1px solid var(--border-color);
            color: var(--text-light);
            padding: 0.3rem 0.8rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.8rem;
            margin-top: 1rem;
            width: 100%;
        }

        .reset-progress:hover {
            background: var(--bg-color);
            border-color: var(--primary-color);
        }

        /* Pagination Styles */
        .page-section {
            display: none;
        }

        .page-section.active {
            display: block;
        }

        .page-navigation {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin: 3rem 0 2rem 0;
            padding-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        .nav-button {
            background: var(--bg-secondary);
            color: var(--text-light);
            border: 1px solid var(--border-color);
            padding: 1rem 1.5rem;
            border-radius: 8px;
            cursor: pointer;
            font-family: inherit;
            font-size: 1rem;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .nav-button:hover:not(:disabled) {
            background: var(--bg-color);
            border-color: var(--primary-color);
            color: var(--text-color);
        }

        .nav-button:disabled {
            background: var(--bg-secondary);
            color: var(--text-light);
            opacity: 0.5;
            cursor: not-allowed;
        }

        .nav-button[data-direction="1"] {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        .nav-button[data-direction="1"]:hover:not(:disabled) {
            background: var(--primary-light);
            border-color: var(--primary-light);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(37, 99, 235, 0.3);
        }

        .nav-button[data-direction="1"]:disabled {
            background: var(--text-light);
            border-color: var(--text-light);
            color: white;
            opacity: 0.5;
        }


        /* Main content */
        main {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 3rem;
            padding-top: calc(60px + 2rem);
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            color: var(--primary-color);
            border-bottom: 3px solid var(--primary-color);
            padding-bottom: 0.5rem;
            margin: 3rem 0 1.5rem;
        }

        h2 {
            font-size: 1.5rem;
            font-weight: 700;
            color: var(--text-color);
            border-left: 4px solid var(--primary-color);
            padding-left: 1rem;
            margin: 2.5rem 0 1rem;
        }

        h3 {
            font-size: 1.25rem;
            font-weight: 500;
            color: var(--text-color);
            margin: 2rem 0 0.75rem;
        }

        p {
            margin: 1rem 0;
            text-align: justify;
        }

        a {
            color: var(--primary-color);
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-color 0.2s;
            word-break: break-all;
            overflow-wrap: anywhere;
        }

        a:hover {
            border-bottom-color: var(--primary-color);
        }

        ul, ol {
            margin: 1rem 0;
            padding-left: 2rem;
        }

        li {
            margin: 0.5rem 0;
        }

        hr {
            border: none;
            border-top: 1px solid var(--border-color);
            margin: 3rem 0;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'Source Code Pro', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        code {
            font-family: 'Source Code Pro', monospace;
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-size: 0.9em;
        }

        pre code {
            background: none;
            padding: 0;
        }

        .katex-display {
            overflow-x: auto;
            overflow-y: hidden;
            padding: 1rem 0;
        }

        .katex {
            font-size: 1.1em;
        }

        .mermaid {
            background: var(--bg-secondary);
            padding: 2rem;
            border-radius: 8px;
            text-align: center;
            margin: 1.5rem 0;
        }

        .architecture-diagram {
            background: #fafafa;
            padding: 1.5rem;
            border-radius: 12px;
            margin: 2rem 0;
            overflow-x: auto;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        }

        .architecture-diagram svg {
            display: block;
            margin: 0 auto;
            min-width: 800px;
        }

        strong {
            font-weight: 700;
            color: var(--text-color);
        }

        blockquote {
            border-left: 4px solid var(--border-color);
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: var(--bg-secondary);
            color: var(--text-light);
        }


        @media print {
            #toc {
                display: none;
            }
            main {
                margin-left: 0;
                max-width: none;
                padding: 1rem;
            }
        }

        /* Tablet and mobile responsive design */
        @media (max-width: 1024px) {
            :root {
                --toc-width: 300px;
            }

            /* TOC mobile behavior */
            #toc {
                position: fixed;
                top: 60px;
                left: 0;
                width: var(--toc-width);
                height: calc(100vh - 60px);
                transform: translateX(-100%);
                transition: transform 0.3s ease;
                z-index: 1001;
                border-right: 1px solid var(--border-color);
                border-bottom: none;
                box-shadow: 2px 0 12px rgba(0, 0, 0, 0.1);
            }

            #toc.show {
                transform: translateX(0);
            }


            main {
                margin-left: 0;
                padding: 1.5rem;
                padding-top: calc(60px + 1.5rem);
            }
        }

        /* Mobile specific adjustments */
        @media (max-width: 768px) {
            :root {
                --toc-width: 100vw;
            }

            header {
                padding: 0 1rem;
            }

            #toc {
                width: 100vw;
            }

            main {
                padding: 1rem;
                padding-top: calc(60px + 1rem);
            }

            .page-navigation {
                gap: 0.8rem;
                margin: 2rem 0 1rem 0;
            }

            .nav-button {
                flex: 1;
                max-width: 150px;
                padding: 0.8rem 1rem;
            }

            .progress-section {
                padding: 0.8rem;
            }


            .toc-list {
                padding-bottom: 2rem;
            }

            h1 {
                font-size: 1.6rem;
            }

            h2 {
                font-size: 1.3rem;
            }

            h3 {
                font-size: 1.1rem;
            }

            .toc-item {
                padding: 0.4rem 0;
            }

            .toc-checkbox {
                transform: scale(1.2);
                margin-top: 0.4rem;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <button class="header-hamburger" onclick="toggleTOC()">☰</button>
        <button class="header-settings" onclick="toggleSettingsModal()">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none">
                <path d="M19.14,12.94c0.04-0.3,0.06-0.61,0.06-0.94c0-0.32-0.02-0.64-0.07-0.94l2.03-1.58c0.18-0.14,0.23-0.41,0.12-0.61 l-1.92-3.32c-0.12-0.22-0.37-0.29-0.59-0.22l-2.39,0.96c-0.5-0.38-1.03-0.7-1.62-0.94L14.4,2.81c-0.04-0.24-0.24-0.41-0.48-0.41 h-3.84c-0.24,0-0.43,0.17-0.47,0.41L9.25,5.35C8.66,5.59,8.12,5.92,7.63,6.29L5.24,5.33c-0.22-0.08-0.47,0-0.59,0.22L2.74,8.87 C2.62,9.08,2.66,9.34,2.86,9.48l2.03,1.58C4.84,11.36,4.8,11.69,4.8,12s0.02,0.64,0.07,0.94l-2.03,1.58 c-0.18,0.14-0.23,0.41-0.12,0.61l1.92,3.32c0.12,0.22,0.37,0.29,0.59,0.22l2.39-0.96c0.5,0.38,1.03,0.7,1.62,0.94l0.36,2.54 c0.05,0.24,0.24,0.41,0.48,0.41h3.84c0.24,0,0.44-0.17,0.47-0.41l0.36-2.54c0.59-0.24,1.13-0.56,1.62-0.94l2.39,0.96 c0.22,0.08,0.47,0,0.59-0.22l1.92-3.32c0.12-0.22,0.07-0.47-0.12-0.61L19.14,12.94z M12,15.6c-1.98,0-3.6-1.62-3.6-3.6 s1.62-3.6,3.6-3.6s3.6,1.62,3.6,3.6S13.98,15.6,12,15.6z" fill="currentColor"/>
            </svg>
        </button>
    </header>

    <nav id="toc">
<h2>目次</h2>
<div class="progress-section">
    <div class="progress-bar">
        <div class="progress-fill" id="progressFill"></div>
    </div>
    <div class="progress-text" id="progressText">0 / 0 完了 (0%)</div>
</div>

<ul class="toc-list">
<li class="toc-h1">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="第1章-人物らしさを工学問題として定義する">
        <a href="#第1章-人物らしさを工学問題として定義する">第1章　人物らしさを工学問題として定義する</a>
    </div>
<ul>
<li class="toc-h2">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="11-対象の分類架空人物・実在人物・集合的ペルソナ">
        <a href="#11-対象の分類架空人物・実在人物・集合的ペルソナ">1.1 対象の分類：架空人物・実在人物・集合的ペルソナ</a>
    </div>
<ul>
<li class="toc-h3">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="実在人物（デジタルツイン）">
        <a href="#実在人物（デジタルツイン）">実在人物（デジタルツイン）</a>
    </div>
</li>
<li class="toc-h3">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="架空人物（創作キャラクター／社内AIキャラ）">
        <a href="#架空人物（創作キャラクター／社内AIキャラ）">架空人物（創作キャラクター／社内AIキャラ）</a>
    </div>
</li>
<li class="toc-h3">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="集合的ペルソナ（チーム人格・会社人格）">
        <a href="#集合的ペルソナ（チーム人格・会社人格）">集合的ペルソナ（チーム人格・会社人格）</a>
    </div>
</li>
</ul></li>
<li class="toc-h2">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="12-「人物らしさ」の分解決定・理由づけ・表現・社会性・記憶・感情">
        <a href="#12-「人物らしさ」の分解決定・理由づけ・表現・社会性・記憶・感情">1.2 「人物らしさ」の分解：決定・理由づけ・表現・社会性・記憶・感情</a>
    </div>
</li>
<li class="toc-h2">
    <div class="toc-item">
        <input type="checkbox" class="toc-checkbox" data-section="13-典型的失敗モード合理化・漂流・捏造・迎合・過信">
        <a href="#13-典型的失敗モード合理化・漂流・捏造・迎合・過信">1.3 典型的失敗モード：合理化・漂流・捏造・迎合・過信</a>
    </div>
<ul>
<li class="toc-h3"><a href="#合理化（もっともらしい理由の後付け）">合理化（もっともらしい理由の後付け）</a></li>
<li class="toc-h3"><a href="#漂流（時間とともに人格が変わる）">漂流（時間とともに人格が変わる）</a></li>
<li class="toc-h3"><a href="#捏造（幻覚）もっともらしさと事実の混同">捏造（幻覚）：もっともらしさと事実の混同</a></li>
<li class="toc-h3"><a href="#迎合（sycophancy）ユーザーに同意しすぎて人物らしさを失う">迎合（sycophancy）：ユーザーに同意しすぎて人物らしさを失う</a></li>
<li class="toc-h3"><a href="#過信（権威化）と自動化バイアス人がAIを信じすぎる">過信（権威化）と自動化バイアス：人がAIを信じすぎる</a></li>
</ul></li>
<li class="toc-h2"><a href="#14-要件の書き方機能要件／非機能要件／社会的要件">1.4 要件の書き方：機能要件／非機能要件／社会的要件</a>
<ul>
<li class="toc-h3"><a href="#機能要件何ができるべきか">機能要件：何ができるべきか</a></li>
<li class="toc-h3"><a href="#非機能要件遅延・コスト・頑健性など">非機能要件：遅延・コスト・頑健性など</a></li>
<li class="toc-h3"><a href="#社会的要件透明性・説明責任・撤回可能性">社会的要件：透明性・説明責任・撤回可能性</a></li>
</ul></li>
<li class="toc-h2"><a href="#15-本書の共通用語と最小の表記">1.5 本書の共通用語と最小の表記</a>
<ul>
<li class="toc-h3"><a href="#主要用語（本書での定義）">主要用語（本書での定義）</a></li>
<li class="toc-h3"><a href="#最小の表記（以後の章で共通に使う）">最小の表記（以後の章で共通に使う）</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第2章-評価設計「似ている」を測れる形にする">第2章　評価設計：「似ている」を測れる形にする</a>
<ul>
<li class="toc-h2"><a href="#21-多軸評価結論・理由・価値観・対話行為・文体">2.1 多軸評価：結論・理由・価値観・対話行為・文体</a>
<ul>
<li class="toc-h3"><a href="#多軸評価を数学で置く">多軸評価を数学で置く</a></li>
<li class="toc-h3"><a href="#軸の具体化人物らしさに効く5つの軸">軸の具体化：人物らしさに効く5つの軸</a></li>
</ul></li>
<li class="toc-h2"><a href="#22-テストシナリオ設計反事実（条件差分）と未知状況">2.2 テストシナリオ設計：反事実（条件差分）と未知状況</a>
<ul>
<li class="toc-h3"><a href="#なぜ「テストシナリオ」が評価の中心になるのか">なぜ「テストシナリオ」が評価の中心になるのか</a></li>
<li class="toc-h3"><a href="#反事実テスト1つだけ条件を変える">反事実テスト：1つだけ条件を変える</a></li>
<li class="toc-h3"><a href="#未知状況（分布外）テスト訓練と同じ世界に閉じない">未知状況（分布外）テスト：訓練と同じ世界に閉じない</a></li>
<li class="toc-h3"><a href="#シナリオの分割開発用と評価用を混ぜない">シナリオの分割：開発用と評価用を混ぜない</a></li>
</ul></li>
<li class="toc-h2"><a href="#23-人手評価ブラインド・比較（A/B）・一致度">2.3 人手評価：ブラインド・比較（A/B）・一致度</a>
<ul>
<li class="toc-h3"><a href="#ブラインド評価条件を隠して偏りを減らす">ブラインド評価：条件を隠して偏りを減らす</a></li>
<li class="toc-h3"><a href="#絶対評価より比較（A/B）を優先する">絶対評価より比較（A/B）を優先する</a></li>
<li class="toc-h3"><a href="#評価者一致度Cohenのカッパ係数">評価者一致度：Cohenのカッパ係数</a></li>
<li class="toc-h3"><a href="#実在人物と架空キャラで評価者を変える">実在人物と架空キャラで評価者を変える</a></li>
</ul></li>
<li class="toc-h2"><a href="#24-自動評価埋め込み・分類器・LLM評価者（LLM-as-a-judge）">2.4 自動評価：埋め込み・分類器・LLM評価者（LLM-as-a-judge）</a>
<ul>
<li class="toc-h3"><a href="#埋め込み類似度意味の近さを測る">埋め込み類似度：意味の近さを測る</a></li>
<li class="toc-h3"><a href="#分類器ベース対話行為・危険発話・迎合などを検知する">分類器ベース：対話行為・危険発話・迎合などを検知する</a></li>
<li class="toc-h3"><a href="#LLM評価者（LLM-as-a-judge）大規模言語モデルに採点させる">LLM評価者（LLM-as-a-judge）：大規模言語モデルに採点させる</a></li>
</ul></li>
<li class="toc-h2"><a href="#25-継続評価回帰テスト監視指標版管理">2.5 継続評価：回帰テスト、監視指標、版管理</a>
<ul>
<li class="toc-h3"><a href="#回帰テスト固定シナリオ集合で「壊れた」を検知する">回帰テスト：固定シナリオ集合で「壊れた」を検知する</a></li>
<li class="toc-h3"><a href="#監視指標運用ログから“危険な変化”を早期に拾う">監視指標：運用ログから“危険な変化”を早期に拾う</a></li>
<li class="toc-h3"><a href="#版管理何が変わったのかを追跡できなければ評価は無意味になる">版管理：何が変わったのかを追跡できなければ評価は無意味になる</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第3章-認知と記憶を「設計できる部品」に分解する">第3章　認知と記憶を「設計できる部品」に分解する</a>
<ul>
<li class="toc-h2"><a href="#31-記憶の基本構造短期・長期そしてエピソードと意味">3.1 記憶の基本構造：短期・長期、そしてエピソードと意味</a>
<ul>
<li class="toc-h3"><a href="#多重貯蔵モデル感覚・短期・長期という分解">多重貯蔵モデル：感覚・短期・長期という分解</a></li>
<li class="toc-h3"><a href="#作業記憶モデル短期貯蔵は「作業の場」である">作業記憶モデル：短期貯蔵は「作業の場」である</a></li>
<li class="toc-h3"><a href="#エピソード記憶と意味記憶何を「いつの経験」として持つか">エピソード記憶と意味記憶：何を「いつの経験」として持つか</a></li>
<li class="toc-h3"><a href="#検索手がかりと符号化特定性記憶は「合鍵」で開く">検索手がかりと符号化特定性：記憶は「合鍵」で開く</a></li>
</ul></li>
<li class="toc-h2"><a href="#32-記憶は再生ではなく再構成スキーマ偽記憶出典混同">3.2 記憶は再生ではなく再構成：スキーマ、偽記憶、出典混同</a>
<ul>
<li class="toc-h3"><a href="#バートレットの再構成記憶意味づけが記憶を作り変える">バートレットの再構成記憶：意味づけが記憶を作り変える</a></li>
<li class="toc-h3"><a href="#誘導と偽記憶言語は記憶を書き換える">誘導と偽記憶：言語は記憶を書き換える</a></li>
<li class="toc-h3"><a href="#ベイズ的見方弱い手がかりのとき事前分布が勝つ">ベイズ的見方：弱い手がかりのとき、事前分布が勝つ</a></li>
<li class="toc-h3"><a href="#出典混同（ソースモニタリング）その情報は「どこから来た」のか">出典混同（ソースモニタリング）：その情報は「どこから来た」のか</a></li>
<li class="toc-h3"><a href="#記憶の「罪」忘却と歪みは体系化できる">記憶の「罪」：忘却と歪みは体系化できる</a></li>
</ul></li>
<li class="toc-h2"><a href="#33-注意と容量人もモデルも「真ん中」を落とす">3.3 注意と容量：人もモデルも「真ん中」を落とす</a>
<ul>
<li class="toc-h3"><a href="#作業記憶容量7±2から4±1へ（そして状況依存へ）">作業記憶容量：7±2から4±1へ（そして状況依存へ）</a></li>
<li class="toc-h3"><a href="#系列位置効果人間は最初と最後を覚えやすい">系列位置効果：人間は最初と最後を覚えやすい</a></li>
<li class="toc-h3"><a href="#LLMでも起きる「真ん中落ち」Lost-in-the-Middle">LLMでも起きる「真ん中落ち」：Lost in the Middle</a></li>
</ul></li>
<li class="toc-h2"><a href="#34-認知バイアス欠陥かキャラクターの核か">3.4 認知バイアス：欠陥か、キャラクターの核か</a>
<ul>
<li class="toc-h3"><a href="#ヒューリスティックスとバイアス不確実性下の近道が誤りを生む">ヒューリスティックスとバイアス：不確実性下の近道が誤りを生む</a></li>
<li class="toc-h3"><a href="#確証バイアス信念を守る方向に証拠を解釈する">確証バイアス：信念を守る方向に証拠を解釈する</a></li>
<li class="toc-h3"><a href="#フレーミング同じ内容でも表現で選好が変わる">フレーミング：同じ内容でも表現で選好が変わる</a></li>
</ul></li>
<li class="toc-h2"><a href="#35-工学への統合信念・目標・関係・感情を「状態」として扱う">3.5 工学への統合：信念・目標・関係・感情を「状態」として扱う</a>
<ul>
<li class="toc-h3"><a href="#観測できない世界を扱う信念状態という発想">観測できない世界を扱う：信念状態という発想</a></li>
<li class="toc-h3"><a href="#記憶検索と状態更新を分離する推論の流れを明確にする">記憶検索と状態更新を分離する：推論の流れを明確にする</a></li>
<li class="toc-h3"><a href="#通し例A/Bへの落とし込み同じ仕組みでも要件が違う">通し例A/Bへの落とし込み：同じ仕組みでも要件が違う</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第4章-人格・価値観・動機個人差をモデル化する">第4章　人格・価値観・動機：個人差をモデル化する</a>
<ul>
<li class="toc-h2"><a href="#41-特性と状態変わりにくいもの／変わりやすいものを混ぜない">4.1 特性と状態：変わりにくいもの／変わりやすいものを混ぜない</a>
<ul>
<li class="toc-h3"><a href="#「人は一貫しているのか」問題と工学に必要な答え">「人は一貫しているのか」問題と、工学に必要な答え</a></li>
<li class="toc-h3"><a href="#工学での最小分解特性ベクトルと状態ベクトル">工学での最小分解：特性ベクトルと状態ベクトル</a></li>
<li class="toc-h3"><a href="#特性が“いつ効くか”特性活性化（trait-activation）">特性が“いつ効くか”：特性活性化（trait activation）</a></li>
</ul></li>
<li class="toc-h2"><a href="#42-Big-Five人格を共通言語にする（ただし“万能ラベル”ではない）">4.2 Big Five：人格を共通言語にする（ただし“万能ラベル”ではない）</a>
<ul>
<li class="toc-h3"><a href="#Big-Fiveとは何か語彙から抽出された5次元の記述">Big Fiveとは何か：語彙から抽出された5次元の記述</a></li>
<li class="toc-h3"><a href="#初学者のための直観5因子を“行動の傾向”として読む">初学者のための直観：5因子を“行動の傾向”として読む</a></li>
<li class="toc-h3"><a href="#心理測定（psychometrics）の最低限人格は「潜在変数」として推定される">心理測定（psychometrics）の最低限：人格は「潜在変数」として推定される</a></li>
<li class="toc-h3"><a href="#工学への落とし込み人格ベクトルが意思決定に入る場所">工学への落とし込み：人格ベクトルが意思決定に入る場所</a></li>
</ul></li>
<li class="toc-h2"><a href="#43-価値観理論Schwartzと道徳の枠組みを“優先順位”へ落とす">4.3 価値観理論：Schwartzと道徳の枠組みを“優先順位”へ落とす</a>
<ul>
<li class="toc-h3"><a href="#価値観は「好み」より上位の原理である">価値観は「好み」より上位の原理である</a></li>
<li class="toc-h3"><a href="#Schwartzの基本価値理論価値観を円環構造として表す">Schwartzの基本価値理論：価値観を円環構造として表す</a></li>
<li class="toc-h3"><a href="#道徳基盤（Moral-Foundations）価値観の“道徳語彙”を増やす">道徳基盤（Moral Foundations）：価値観の“道徳語彙”を増やす</a></li>
<li class="toc-h3"><a href="#工学への落とし込み価値観ベクトルとしての表現">工学への落とし込み：価値観ベクトルとしての表現</a></li>
</ul></li>
<li class="toc-h2"><a href="#44-目標と動機階層的目標自己調整そして「なぜ動くか」">4.4 目標と動機：階層的目標、自己調整、そして「なぜ動くか」</a>
<ul>
<li class="toc-h3"><a href="#目標は階層構造を持つ">目標は階層構造を持つ</a></li>
<li class="toc-h3"><a href="#自己決定理論内発・外発という二分法を超える">自己決定理論：内発・外発という二分法を超える</a></li>
<li class="toc-h3"><a href="#目標設定理論具体性とフィードバックが行動を変える">目標設定理論：具体性とフィードバックが行動を変える</a></li>
<li class="toc-h3"><a href="#制御理論（control-theory）的な見方行動は誤差を減らす制御">制御理論（control theory）的な見方：行動は誤差を減らす制御</a></li>
</ul></li>
<li class="toc-h2"><a href="#45-工学的表現重み付き目的・ルール・確率的選択で「個性」を実装する">4.5 工学的表現：重み付き目的・ルール・確率的選択で「個性」を実装する</a>
<ul>
<li class="toc-h3"><a href="#多属性効用何をどれだけ重視するかを数式で固定する">多属性効用：何をどれだけ重視するかを数式で固定する</a></li>
<li class="toc-h3"><a href="#ルールと制約人格と安全を混ぜないための“外枠”">ルールと制約：人格と安全を混ぜないための“外枠”</a></li>
<li class="toc-h3"><a href="#確率的選択同じ人でも揺れることをモデルにする">確率的選択：同じ人でも揺れることをモデルにする</a></li>
<li class="toc-h3"><a href="#2つの通し例への具体的適用役職の違い／社内キャラの使命">2つの通し例への具体的適用：役職の違い／社内キャラの使命</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第5章-感情内的状態を設計可能な部品にする">第5章　感情：内的状態を設計可能な部品にする</a>
<ul>
<li class="toc-h2"><a href="#50-用語の整理情動・気分・感情・共感">5.0 用語の整理：情動・気分・感情・共感</a>
<li class="toc-h2"><a href="#51-感情モデルカテゴリ型・次元型・評価（appraisal）型">5.1 感情モデル：カテゴリ型・次元型・評価（appraisal）型</a>
<ul>
<li class="toc-h3"><a href="#511-カテゴリ型基本感情という考え方">5.1.1 カテゴリ型：基本感情という考え方</a></li>
<li class="toc-h3"><a href="#512-次元型快—不快と覚醒の空間で表す">5.1.2 次元型：快—不快と覚醒の空間で表す</a></li>
<li class="toc-h3"><a href="#513-評価（appraisal）型出来事をどう評価したかで感情を生成する">5.1.3 評価（appraisal）型：出来事をどう評価したかで感情を生成する</a></li>
</ul></li>
<li class="toc-h2"><a href="#52-感情の時間変化減衰・増幅・調整を数式で扱う">5.2 感情の時間変化：減衰・増幅・調整を数式で扱う</a>
<ul>
<li class="toc-h3"><a href="#521-最小のダイナミクス指数減衰と入力による駆動">5.2.1 最小のダイナミクス：指数減衰と入力による駆動</a></li>
<li class="toc-h3"><a href="#522-感情の相互作用価と覚醒は独立ではない">5.2.2 感情の相互作用：価と覚醒は独立ではない</a></li>
<li class="toc-h3"><a href="#523-感情調整Grossのプロセスモデルを設計へ翻訳する">5.2.3 感情調整：Grossのプロセスモデルを設計へ翻訳する</a></li>
</ul></li>
<li class="toc-h2"><a href="#53-共感（empathy）を会話設計にする役に立つが依存させない">5.3 共感（empathy）を会話設計にする：役に立つが依存させない</a>
<ul>
<li class="toc-h3"><a href="#531-共感を構造化するRogerian-empathyの直観">5.3.1 共感を構造化する：Rogerian empathyの直観</a></li>
<li class="toc-h3"><a href="#532-対話データセットとしての共感EmpatheticDialogues">5.3.2 対話データセットとしての共感：EmpatheticDialogues</a></li>
<li class="toc-h3"><a href="#533-ELIZA効果擬人化と過信を前提に設計する">5.3.3 ELIZA効果：擬人化と過信を前提に設計する</a></li>
<li class="toc-h3"><a href="#534-共感応答の数式化状態推定と支援最適化">5.3.4 共感応答の数式化：状態推定と支援最適化</a></li>
</ul></li>
<li class="toc-h2"><a href="#54-感情と意思決定リスク認知・衝動・損失回避への橋渡し">5.4 感情と意思決定：リスク認知・衝動・損失回避への橋渡し</a>
<ul>
<li class="toc-h3"><a href="#541-ソマティック・マーカー仮説身体反応が意思決定を導く">5.4.1 ソマティック・マーカー仮説：身体反応が意思決定を導く</a></li>
<li class="toc-h3"><a href="#542-リスク＝感情Risk-as-Feelings-と感情ヒューリスティック">5.4.2 リスク＝感情：Risk-as-Feelings と感情ヒューリスティック</a></li>
<li class="toc-h3"><a href="#543-意思決定モデルへの統合感情で重みが動く温度が動く">5.4.3 意思決定モデルへの統合：感情で重みが動く、温度が動く</a></li>
<li class="toc-h3"><a href="#544-通し例への適用会議の温度と社内キャラの心理的安全性">5.4.4 通し例への適用：会議の温度と、社内キャラの心理的安全性</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ感情は「表現」ではなく「状態×評価×制御」で設計する">まとめ：感情は「表現」ではなく「状態×評価×制御」で設計する</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第6章-会話を「社会的行為」として設計する――語用論・発話行為・礼儀・信頼">第6章　会話を「社会的行為」として設計する――語用論・発話行為・礼儀・信頼</a>
<ul>
<li class="toc-h2"><a href="#61-意味と語用文の意味と「意図された意味」は一致しない">6.1 意味と語用：文の意味と「意図された意味」は一致しない</a>
<ul>
<li class="toc-h3"><a href="#611-「意味（semantics）」と「語用（pragmatics）」の違い">6.1.1 「意味（semantics）」と「語用（pragmatics）」の違い</a></li>
<li class="toc-h3"><a href="#612-協調の原理と会話の含意グライスの洞察">6.1.2 協調の原理と会話の含意：グライスの洞察</a></li>
</ul></li>
<li class="toc-h2"><a href="#62-語用推論を確率で書く合理的発話行為（RSA）モデル">6.2 語用推論を確率で書く：合理的発話行為（RSA）モデル</a>
<ul>
<li class="toc-h3"><a href="#621-リテラル（字義）解釈L0">6.2.1 リテラル（字義）解釈：L0</a></li>
<li class="toc-h3"><a href="#622-話し手S1（効用最大化）">6.2.2 話し手：S1（効用最大化）</a></li>
<li class="toc-h3"><a href="#623-語用聞き手L1（含意の計算）">6.2.3 語用聞き手：L1（含意の計算）</a></li>
</ul></li>
<li class="toc-h2"><a href="#63-発話行為会話は「情報」ではなく「約束・要求・拒否」を作る">6.3 発話行為：会話は「情報」ではなく「約束・要求・拒否」を作る</a>
<ul>
<li class="toc-h3"><a href="#631-オースティン発話は行為である">6.3.1 オースティン：発話は行為である</a></li>
<li class="toc-h3"><a href="#632-サール発話行為の分類と条件">6.3.2 サール：発話行為の分類と条件</a></li>
<li class="toc-h3"><a href="#633-会話状態を「更新」として表すコミットメントの集合">6.3.3 会話状態を「更新」として表す：コミットメントの集合</a></li>
</ul></li>
<li class="toc-h2"><a href="#64-共通基盤（common-ground）とグラウンディング会話は「共有前提」の更新である">6.4 共通基盤（common ground）とグラウンディング：会話は「共有前提」の更新である</a>
<ul>
<li class="toc-h3"><a href="#641-スタルネイカーの共通基盤前提の集合としての会話">6.4.1 スタルネイカーの共通基盤：前提の集合としての会話</a></li>
<li class="toc-h3"><a href="#642-グラウンディング理解は段階的に合意される">6.4.2 グラウンディング：理解は段階的に合意される</a></li>
<li class="toc-h3"><a href="#643-修復（repair）会話のズレを直すメカニズム">6.4.3 修復（repair）：会話のズレを直すメカニズム</a></li>
</ul></li>
<li class="toc-h2"><a href="#65-会話の構造ターン交替・隣接対・会議らしさ">6.5 会話の構造：ターン交替・隣接対・会議らしさ</a>
<ul>
<li class="toc-h3"><a href="#651-ターン交替誰がいつ話すかはルールに近い">6.5.1 ターン交替：誰がいつ話すかはルールに近い</a></li>
<li class="toc-h3"><a href="#652-隣接対（adjacency-pairs）質問は回答を呼び提案は受諾／拒否を呼ぶ">6.5.2 隣接対（adjacency pairs）：質問は回答を呼び、提案は受諾／拒否を呼ぶ</a></li>
<li class="toc-h3"><a href="#653-会議らしさ議題論点合意アクション">6.5.3 会議らしさ：議題、論点、合意、アクション</a></li>
</ul></li>
<li class="toc-h2"><a href="#66-礼儀と顔（face）社会的コストをモデルに入れる">6.6 礼儀と顔（face）：社会的コストをモデルに入れる</a>
<ul>
<li class="toc-h3"><a href="#661-ゴフマンの顔相互作用の中で守られる体面">6.6.1 ゴフマンの顔：相互作用の中で守られる体面</a></li>
<li class="toc-h3"><a href="#662-ブラウン＆レヴィンソン丁寧さは費用対効果で選ばれる">6.6.2 ブラウン＆レヴィンソン：丁寧さは費用対効果で選ばれる</a></li>
<li class="toc-h3"><a href="#663-礼儀を効用に入れる内容と関係のトレードオフ">6.6.3 礼儀を効用に入れる：内容と関係のトレードオフ</a></li>
</ul></li>
<li class="toc-h2"><a href="#67-信頼とエピステミック・スタンス断言推測保留を使い分ける">6.7 信頼とエピステミック・スタンス：断言、推測、保留を使い分ける</a>
<ul>
<li class="toc-h3"><a href="#671-エピステミック・スタンス知っている／推測している／分からない">6.7.1 エピステミック・スタンス：知っている／推測している／分からない</a></li>
<li class="toc-h3"><a href="#672-聞き手側の警戒エピステミック・ヴィジランス">6.7.2 聞き手側の警戒：エピステミック・ヴィジランス</a></li>
<li class="toc-h3"><a href="#673-信頼の更新をベイズで書く最小モデル">6.7.3 信頼の更新をベイズで書く：最小モデル</a></li>
</ul></li>
<li class="toc-h2"><a href="#68-設計への落とし込み人物らしい会話を壊さないための最小原則">6.8 設計への落とし込み：人物らしい会話を壊さないための最小原則</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第7章-コンテクスト工学と長期記憶管理何を入れ何を忘れ何を参照するか">第7章　コンテクスト工学と長期記憶管理：何を入れ、何を忘れ、何を参照するか</a>
<ul>
<li class="toc-h2"><a href="#71-コンテクストは「作業記憶」長くすれば解決するわけではない">7.1 コンテクストは「作業記憶」：長くすれば解決するわけではない</a>
<ul>
<li class="toc-h3"><a href="#711-コンテクストウィンドウの役割その場の推論の舞台">7.1.1 コンテクストウィンドウの役割：その場の推論の舞台</a></li>
<li class="toc-h3"><a href="#712-長いほど良いわけではない位置バイアスと情報価値密度">7.1.2 長いほど良いわけではない：位置バイアスと情報価値密度</a></li>
<li class="toc-h3"><a href="#713-設計対象としての「入力構成」">7.1.3 設計対象としての「入力構成」</a></li>
</ul></li>
<li class="toc-h2"><a href="#72-長期記憶ストアのデータモデル内容だけでなく出典・時刻・確度を持つ">7.2 長期記憶ストアのデータモデル：内容だけでなく出典・時刻・確度を持つ</a>
<ul>
<li class="toc-h3"><a href="#721-記憶項目の最小表現テキスト＋メタデータ">7.2.1 記憶項目の最小表現：テキスト＋メタデータ</a></li>
<li class="toc-h3"><a href="#722-意味記憶・エピソード記憶・手続き記憶混ぜると壊れる">7.2.2 意味記憶・エピソード記憶・手続き記憶：混ぜると壊れる</a></li>
<li class="toc-h3"><a href="#723-「人格や価値観」は記憶とは別の状態として持つ">7.2.3 「人格や価値観」は記憶とは別の状態として持つ</a></li>
</ul></li>
<li class="toc-h2"><a href="#73-検索疎検索・密検索・ハイブリッドそして多様性">7.3 検索：疎検索・密検索・ハイブリッド、そして多様性</a>
<ul>
<li class="toc-h3"><a href="#731-疎検索BM25（語の一致と文書頻度）">7.3.1 疎検索：BM25（語の一致と文書頻度）</a></li>
<li class="toc-h3"><a href="#732-密検索埋め込み（embedding）による近傍探索">7.3.2 密検索：埋め込み（embedding）による近傍探索</a></li>
<li class="toc-h3"><a href="#733-ハイブリッド検索疎と密を足し合わせる（または学習する）">7.3.3 ハイブリッド検索：疎と密を足し合わせる（または学習する）</a></li>
<li class="toc-h3"><a href="#734-多様性同じ話ばかり拾わない（MMR）">7.3.4 多様性：同じ話ばかり拾わない（MMR）</a></li>
</ul></li>
<li class="toc-h2"><a href="#74-コンテクスト組み立て階層化と圧縮は「情報の目的関数」で決める">7.4 コンテクスト組み立て：階層化と圧縮は「情報の目的関数」で決める</a>
<ul>
<li class="toc-h3"><a href="#741-階層化詳細ログと要約を同時に持つ">7.4.1 階層化：詳細ログと要約を同時に持つ</a></li>
<li class="toc-h3"><a href="#742-圧縮は損失関数で決める情報ボトルネックの直観">7.4.2 圧縮は損失関数で決める：情報ボトルネックの直観</a></li>
<li class="toc-h3"><a href="#743-コンテクストの順序と境界混ぜずに区切る">7.4.3 コンテクストの順序と境界：混ぜずに区切る</a></li>
</ul></li>
<li class="toc-h2"><a href="#75-記憶の書き込み・統合・忘却保存規則が人物らしさを決める">7.5 記憶の書き込み・統合・忘却：保存規則が人物らしさを決める</a>
<ul>
<li class="toc-h3"><a href="#751-「書く」か「書かない」かイベント抽出としての記憶化">7.5.1 「書く」か「書かない」か：イベント抽出としての記憶化</a></li>
<li class="toc-h3"><a href="#752-統合（consolidation）と反省（reflection）要約は「上位の状態」を作る">7.5.2 統合（consolidation）と反省（reflection）：要約は「上位の状態」を作る</a></li>
<li class="toc-h3"><a href="#753-忘却消す・薄める・要約する">7.5.3 忘却：消す・薄める・要約する</a></li>
</ul></li>
<li class="toc-h2"><a href="#76-矛盾・出典・安全参照できないことを「それっぽく語らない」">7.6 矛盾・出典・安全：参照できないことを「それっぽく語らない」</a>
<ul>
<li class="toc-h3"><a href="#761-「出典つき主張」だけを許す主張と根拠の対応">7.6.1 「出典つき主張」だけを許す：主張と根拠の対応</a></li>
<li class="toc-h3"><a href="#762-矛盾の扱い1つに決めつけない（仮説分布として持つ）">7.6.2 矛盾の扱い：1つに決めつけない（仮説分布として持つ）</a></li>
<li class="toc-h3"><a href="#763-実在人物と架空キャラで違う「許される創作」">7.6.3 実在人物と架空キャラで違う「許される創作」</a></li>
</ul></li>
<li class="toc-h2"><a href="#77-通し例A/Bへの適用同じ仕組みでも運用規則が違う">7.7 通し例A/Bへの適用：同じ仕組みでも運用規則が違う</a>
<ul>
<li class="toc-h3"><a href="#771-通し例ACEO/COO/CTO/CFOのデジタルツイン（会議シミュレーション）">7.7.1 通し例A：CEO/COO/CTO/CFOのデジタルツイン（会議シミュレーション）</a></li>
<li class="toc-h3"><a href="#772-通し例B社内で役に立つ架空キャラ">7.7.2 通し例B：社内で役に立つ架空キャラ</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第8章-ツール利用とエージェントループ検索・計算・実行・安全境界">第8章　ツール利用とエージェントループ：検索・計算・実行・安全境界</a>
<ul>
<li class="toc-h2"><a href="#81-なぜツールが必要か生成は強いが観測はできない">8.1 なぜツールが必要か：生成は強いが、観測はできない</a>
<ul>
<li class="toc-h3"><a href="#811-大規模言語モデルの強みと限界を「役割分担」として捉える">8.1.1 大規模言語モデルの強みと限界を「役割分担」として捉える</a></li>
<li class="toc-h3"><a href="#812-ツールの分類検索・参照・計算・実行・更新">8.1.2 ツールの分類：検索・参照・計算・実行・更新</a></li>
</ul></li>
<li class="toc-h2"><a href="#82-エージェントとしての定式化会話＋ツール利用を「意思決定過程」として書く">8.2 エージェントとしての定式化：会話＋ツール利用を「意思決定過程」として書く</a>
<ul>
<li class="toc-h3"><a href="#821-部分観測マルコフ決定過程（POMDP）という最小モデル">8.2.1 部分観測マルコフ決定過程（POMDP）という最小モデル</a></li>
<li class="toc-h3"><a href="#822-目的関数正しさ・人物らしさ・コストの同時最適化">8.2.2 目的関数：正しさ・人物らしさ・コストの同時最適化</a></li>
</ul></li>
<li class="toc-h2"><a href="#83-エージェントループ設計いつ調べいつ質問しいつ止めるか">8.3 エージェントループ設計：いつ調べ、いつ質問し、いつ止めるか</a>
<ul>
<li class="toc-h3"><a href="#831-ReAct推論と行為を交互に行う">8.3.1 ReAct：推論と行為を交互に行う</a></li>
<li class="toc-h3"><a href="#832-期待情報価値（EVI）ツール呼び出しは「投資」なので元が取れるときだけ行う">8.3.2 期待情報価値（EVI）：ツール呼び出しは「投資」なので元が取れるときだけ行う</a></li>
<li class="toc-h3"><a href="#833-「質問する」か「ツールを呼ぶ」か観測源の選択">8.3.3 「質問する」か「ツールを呼ぶ」か：観測源の選択</a></li>
<li class="toc-h3"><a href="#834-ループを回しすぎない停止条件収穫逓減と安全停止">8.3.4 ループを回しすぎない停止条件：収穫逓減と安全停止</a></li>
</ul></li>
<li class="toc-h2"><a href="#84-ツール呼び出しインターフェース関数・スキーマ・監査可能性">8.4 ツール呼び出しインターフェース：関数・スキーマ・監査可能性</a>
<ul>
<li class="toc-h3"><a href="#841-ツールを関数として扱う型つき写像">8.4.1 ツールを関数として扱う：型つき写像</a></li>
<li class="toc-h3"><a href="#842-スキーマJSONによる入出力契約">8.4.2 スキーマ：JSONによる入出力契約</a></li>
<li class="toc-h3"><a href="#843-再試行・冪等性・レート制限現実のツールは壊れる">8.4.3 再試行・冪等性・レート制限：現実のツールは壊れる</a></li>
</ul></li>
<li class="toc-h2"><a href="#85-検証と根拠付けツール利用の目的は「事実を増やす」ことである">8.5 検証と根拠付け：ツール利用の目的は「事実を増やす」ことである</a>
<ul>
<li class="toc-h3"><a href="#851-参照と生成を分離する証拠集合を明示する">8.5.1 参照と生成を分離する：証拠集合を明示する</a></li>
<li class="toc-h3"><a href="#852-交差検証単一ソースに依存しない">8.5.2 交差検証：単一ソースに依存しない</a></li>
<li class="toc-h3"><a href="#853-計算の外部化数値はプログラムに任せる">8.5.3 計算の外部化：数値はプログラムに任せる</a></li>
</ul></li>
<li class="toc-h2"><a href="#86-セキュリティと安全境界ツールは「攻撃面」を増やす">8.6 セキュリティと安全境界：ツールは「攻撃面」を増やす</a>
<ul>
<li class="toc-h3"><a href="#861-最小権限の原則Saltzer-&-Schroeder">8.6.1 最小権限の原則：Saltzer & Schroeder</a></li>
<li class="toc-h3"><a href="#862-プロンプト注入（prompt-injection）と間接注入ツール出力は“敵対的”になり得る">8.6.2 プロンプト注入（prompt injection）と間接注入：ツール出力は“敵対的”になり得る</a></li>
<li class="toc-h3"><a href="#863-実行系ツールの安全確認サンドボックス監査ログ">8.6.3 実行系ツールの安全：確認、サンドボックス、監査ログ</a></li>
</ul></li>
<li class="toc-h2"><a href="#87-失敗検知と回復ツールがあっても失敗するので失敗を前提にする">8.7 失敗検知と回復：ツールがあっても失敗するので、失敗を前提にする</a>
<ul>
<li class="toc-h3"><a href="#871-失敗の分類検索失敗・統合失敗・表現失敗・実行失敗">8.7.1 失敗の分類：検索失敗・統合失敗・表現失敗・実行失敗</a></li>
<li class="toc-h3"><a href="#872-ルールベース検知と検査役モデル二重化する">8.7.2 ルールベース検知と検査役モデル：二重化する</a></li>
<li class="toc-h3"><a href="#873-自己一貫性（self-consistency）と多案生成推論の不確実性を露出させる">8.7.3 自己一貫性（self-consistency）と多案生成：推論の不確実性を露出させる</a></li>
<li class="toc-h3"><a href="#874-反省（reflection）と改善ループ学習ではなく運用としての改善">8.7.4 反省（reflection）と改善ループ：学習ではなく運用としての改善</a></li>
</ul></li>
<li class="toc-h2"><a href="#88-通し例A/Bツール利用が「会議らしさ」と「社内で役立つ」を支える">8.8 通し例A/B：ツール利用が「会議らしさ」と「社内で役立つ」を支える</a>
<ul>
<li class="toc-h3"><a href="#881-通し例ACEO/COO/CTO/CFOの経営会議シミュレーション">8.8.1 通し例A：CEO/COO/CTO/CFOの経営会議シミュレーション</a></li>
<li class="toc-h3"><a href="#882-通し例B社内で役に立つ架空キャラ">8.8.2 通し例B：社内で役に立つ架空キャラ</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第9章-複数エージェントと組織・社会シミュレーション会議・交渉・合意形成を「設計可能」にする">第9章　複数エージェントと組織・社会シミュレーション：会議・交渉・合意形成を「設計可能」にする</a>
<ul>
<li class="toc-h2"><a href="#91-なぜ「複数エージェント」になると難しくなるのか相互依存と非定常性">9.1　なぜ「複数エージェント」になると難しくなるのか：相互依存と非定常性</a>
<li class="toc-h2"><a href="#92-ゲーム理論で「相互作用」を定義する利得戦略均衡">9.2　ゲーム理論で「相互作用」を定義する：利得、戦略、均衡</a>
<ul>
<li class="toc-h3"><a href="#921-正規形ゲーム最小の形式化">9.2.1　正規形ゲーム：最小の形式化</a></li>
<li class="toc-h3"><a href="#922-ナッシュ均衡互いに動かす理由がない状態">9.2.2　ナッシュ均衡：互いに動かす理由がない状態</a></li>
<li class="toc-h3"><a href="#923-相関均衡第三者の助言や共通信号を含める">9.2.3　相関均衡：第三者の助言や共通信号を含める</a></li>
</ul></li>
<li class="toc-h2"><a href="#93-不完全情報と「他者モデル」タイプ信念そして推論">9.3　不完全情報と「他者モデル」：タイプ、信念、そして推論</a>
<ul>
<li class="toc-h3"><a href="#931-ベイズゲームタイプと期待効用">9.3.1　ベイズゲーム：タイプと期待効用</a></li>
<li class="toc-h3"><a href="#932-信念更新ベイズの定理と会話">9.3.2　信念更新：ベイズの定理と会話</a></li>
<li class="toc-h3"><a href="#933-限定合理性人間（とデジタルツイン）は最適化機械ではない">9.3.3　限定合理性：人間（とデジタルツイン）は最適化機械ではない</a></li>
</ul></li>
<li class="toc-h2"><a href="#94-交渉と合意二者交渉から会議プロトコルへ">9.4　交渉と合意：二者交渉から会議プロトコルへ</a>
<ul>
<li class="toc-h3"><a href="#941-ナッシュ交渉解規範としての解">9.4.1　ナッシュ交渉解：規範としての解</a></li>
<li class="toc-h3"><a href="#942-ルビンシュタイン交互提案モデル過程としての交渉">9.4.2　ルビンシュタイン交互提案モデル：過程としての交渉</a></li>
<li class="toc-h3"><a href="#943-インセンティブとメカニズム嘘をつくのが得にならない設計">9.4.3　インセンティブとメカニズム：嘘をつくのが得にならない設計</a></li>
</ul></li>
<li class="toc-h2"><a href="#95-集団の意思決定方式社会選択理論と「会議のルール設計」">9.5　集団の意思決定方式：社会選択理論と「会議のルール設計」</a>
<ul>
<li class="toc-h3"><a href="#951-社会厚生関数とアローの不可能性定理">9.5.1　社会厚生関数とアローの不可能性定理</a></li>
<li class="toc-h3"><a href="#952-戦略的投票嘘をつけると必ず操作される">9.5.2　戦略的投票：嘘をつけると必ず操作される</a></li>
<li class="toc-h3"><a href="#953-「多数が正しい」は条件付きコンドルセ陪審定理と独立性">9.5.3　「多数が正しい」は条件付き：コンドルセ陪審定理と独立性</a></li>
</ul></li>
<li class="toc-h2"><a href="#96-意見ダイナミクス会話で“考え”がどう収束するかを数式で見る">9.6　意見ダイナミクス：会話で“考え”がどう収束するかを数式で見る</a>
<ul>
<li class="toc-h3"><a href="#961-DeGrootモデル線形合意形成の最小モデル">9.6.1　DeGrootモデル：線形合意形成の最小モデル</a></li>
<li class="toc-h3"><a href="#962-Friedkin–Johnsenモデル頑固さ（stubbornness）を導入する">9.6.2　Friedkin–Johnsenモデル：頑固さ（stubbornness）を導入する</a></li>
<li class="toc-h3"><a href="#963-有界信頼（bounded-confidence）分断と極化のモデル">9.6.3　有界信頼（bounded confidence）：分断と極化のモデル</a></li>
</ul></li>
<li class="toc-h2"><a href="#97-マルチエージェント強化学習とマルコフゲーム環境が時間発展する状況へ">9.7　マルチエージェント強化学習とマルコフゲーム：環境が時間発展する状況へ</a>
<ul>
<li class="toc-h3"><a href="#971-マルコフゲームの定義">9.7.1　マルコフゲームの定義</a></li>
<li class="toc-h3"><a href="#972-LLMを政策（policy）として見る">9.7.2　LLMを政策（policy）として見る</a></li>
</ul></li>
<li class="toc-h2"><a href="#98-LLMマルチエージェントの実装パターン会議を壊さないための制度設計">9.8　LLMマルチエージェントの実装パターン：会議を壊さないための制度設計</a>
<ul>
<li class="toc-h3"><a href="#981-会議を“ゲーム”として設計する利得と制約を先に決める">9.8.1　会議を“ゲーム”として設計する：利得と制約を先に決める</a></li>
<li class="toc-h3"><a href="#982-「情報の流れ」を設計する独立性検証そして誤情報カスケード対策">9.8.2　「情報の流れ」を設計する：独立性、検証、そして誤情報カスケード対策</a></li>
<li class="toc-h3"><a href="#983-会議を“有限時間”にする割引・締切・議事運営の実装">9.8.3　会議を“有限時間”にする：割引・締切・議事運営の実装</a></li>
<li class="toc-h3"><a href="#984-ケーススタディCEO・COO・CTO・CFOの経営会議をどう“モデル化”するか">9.8.4　ケーススタディ：CEO・COO・CTO・CFOの経営会議をどう“モデル化”するか</a></li>
</ul></li>
<li class="toc-h2"><a href="#99-まとめ複数エージェントは「人格」より先に「制度」を設計する">9.9　まとめ：複数エージェントは「人格」より先に「制度」を設計する</a>
<li class="toc-h2"><a href="#参考文献（リンク）">参考文献（リンク）</a>
</ul></li>
<li class="toc-h1"><a href="#第10章-評価・検証・監査人物らしさを「測る」ための科学と実務">第10章　評価・検証・監査：人物らしさを「測る」ための科学と実務</a>
<ul>
<li class="toc-h2"><a href="#101-評価の前にやるべきこと何を「良い」とするのかを数学的に明示する">10.1　評価の前にやるべきこと：何を「良い」とするのかを数学的に明示する</a>
<ul>
<li class="toc-h3"><a href="#1011-「人物らしさ」は単一のスコアではない">10.1.1　「人物らしさ」は単一のスコアではない</a></li>
<li class="toc-h3"><a href="#1012-「模倣」と「創作」を同じ評価で測ると壊れる">10.1.2　「模倣」と「創作」を同じ評価で測ると壊れる</a></li>
</ul></li>
<li class="toc-h2"><a href="#102-測定の基礎妥当性（validity）と信頼性（reliability）を押さえる">10.2　測定の基礎：妥当性（validity）と信頼性（reliability）を押さえる</a>
<ul>
<li class="toc-h3"><a href="#1021-信頼性測定はブレるそのブレを見積もる">10.2.1　信頼性：測定はブレる。そのブレを見積もる</a></li>
<li class="toc-h3"><a href="#1022-妥当性測りたいものを測れているか">10.2.2　妥当性：測りたいものを測れているか</a></li>
</ul></li>
<li class="toc-h2"><a href="#103-評価データの作り方シナリオ（状況）を設計し答えの“不確実性”も扱う">10.3　評価データの作り方：シナリオ（状況）を設計し、答えの“不確実性”も扱う</a>
<ul>
<li class="toc-h3"><a href="#1031-シナリオベース評価人物らしさは状況依存で現れる">10.3.1　シナリオベース評価：人物らしさは状況依存で現れる</a></li>
<li class="toc-h3"><a href="#1032-「正解」は一つとは限らない分布としての教師データ">10.3.2　「正解」は一つとは限らない：分布としての教師データ</a></li>
<li class="toc-h3"><a href="#1033-ペア比較（A/B評価）を中心にする人は絶対点より相対比較が得意">10.3.3　ペア比較（A/B評価）を中心にする：人は絶対点より相対比較が得意</a></li>
</ul></li>
<li class="toc-h2"><a href="#104-主要メトリクス一貫性・根拠・検索・校正（calibration）を数式で測る">10.4　主要メトリクス：一貫性・根拠・検索・校正（calibration）を数式で測る</a>
<ul>
<li class="toc-h3"><a href="#1041-意思決定の忠実度分布距離（KLダイバージェンス）と後悔（regret）">10.4.1　意思決定の忠実度：分布距離（KLダイバージェンス）と後悔（regret）</a></li>
<li class="toc-h3"><a href="#1042-不確実性表明の質適切な校正（calibration）">10.4.2　不確実性表明の質：適切な校正（calibration）</a></li>
<li class="toc-h3"><a href="#1043-長期一貫性矛盾率と自己整合">10.4.3　長期一貫性：矛盾率と自己整合</a></li>
<li class="toc-h3"><a href="#1044-検索と記憶参照の評価情報検索（IR）メトリクスを使う">10.4.4　検索と記憶参照の評価：情報検索（IR）メトリクスを使う</a></li>
<li class="toc-h3"><a href="#1045-根拠に基づく生成（faithfulness）引用と主張の対応を評価する">10.4.5　根拠に基づく生成（faithfulness）：引用と主張の対応を評価する</a></li>
</ul></li>
<li class="toc-h2"><a href="#105-人手評価の設計主観を“データ”として扱う方法">10.5　人手評価の設計：主観を“データ”として扱う方法</a>
<ul>
<li class="toc-h3"><a href="#1051-Turingテストの限界見た目の自然さは安全も忠実度も保証しない">10.5.1　Turingテストの限界：見た目の自然さは安全も忠実度も保証しない</a></li>
<li class="toc-h3"><a href="#1052-ペア比較とElo人間評定を統計モデルで吸収する">10.5.2　ペア比較とElo：人間評定を統計モデルで吸収する</a></li>
<li class="toc-h3"><a href="#1053-評定者への指示（ルーブリック）を“操作変数”として設計する">10.5.3　評定者への指示（ルーブリック）を“操作変数”として設計する</a></li>
</ul></li>
<li class="toc-h2"><a href="#106-自動評価LLM-as-a-Judge-の利点と落とし穴そして「二段階評価」">10.6　自動評価：LLM-as-a-Judge の利点と落とし穴、そして「二段階評価」</a>
<ul>
<li class="toc-h3"><a href="#1061-自動評価が必要な理由回帰テスト（regression-test）としての評価">10.6.1　自動評価が必要な理由：回帰テスト（regression test）としての評価</a></li>
<li class="toc-h3"><a href="#1062-LLM-as-a-Judge人間評定を代理するという発想">10.6.2　LLM-as-a-Judge：人間評定を代理するという発想</a></li>
<li class="toc-h3"><a href="#1063-ベンチマークの使い方一般能力の測定と人物らしさの測定を分ける">10.6.3　ベンチマークの使い方：一般能力の測定と、人物らしさの測定を分ける</a></li>
</ul></li>
<li class="toc-h2"><a href="#107-頑健性評価分布シフト敵対入力そして“誤情報の増幅”を測る">10.7　頑健性評価：分布シフト、敵対入力、そして“誤情報の増幅”を測る</a>
<ul>
<li class="toc-h3"><a href="#1071-分布シフト訓練と本番の状況は違う">10.7.1　分布シフト：訓練と本番の状況は違う</a></li>
<li class="toc-h3"><a href="#1072-誤情報カスケードの評価複数エージェントの特有失敗">10.7.2　誤情報カスケードの評価：複数エージェントの特有失敗</a></li>
</ul></li>
<li class="toc-h2"><a href="#108-運用監査とドリフト検知良いモデルも時間で劣化する">10.8　運用監査とドリフト検知：良いモデルも時間で劣化する</a>
<ul>
<li class="toc-h3"><a href="#1081-ログ設計何を残すと監査できるか">10.8.1　ログ設計：何を残すと監査できるか</a></li>
<li class="toc-h3"><a href="#1082-ドリフト検知を数式で書く分布距離と変化点検知">10.8.2　ドリフト検知を数式で書く：分布距離と変化点検知</a></li>
<li class="toc-h3"><a href="#1083-運用評価は「テストの自動化」に似ている">10.8.3　運用評価は「テストの自動化」に似ている</a></li>
</ul></li>
<li class="toc-h2"><a href="#109-通し例A/B評価設計を「そのまま改善ループ」に接続する">10.9　通し例A/B：評価設計を「そのまま改善ループ」に接続する</a>
<ul>
<li class="toc-h3"><a href="#1091-通し例ACEO/COO/CTO/CFO-デジタルツインの評価">10.9.1　通し例A：CEO/COO/CTO/CFO デジタルツインの評価</a></li>
<li class="toc-h3"><a href="#1092-通し例B社内で役に立つ架空キャラの評価">10.9.2　通し例B：社内で役に立つ架空キャラの評価</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</a>
</ul></li>
<li class="toc-h1"><a href="#第11章-学習と更新人物らしさを改善し続けるためのデータ・最適化・ドリフト制御">第11章　学習と更新：人物らしさを改善し続けるためのデータ・最適化・ドリフト制御</a>
<ul>
<li class="toc-h2"><a href="#111-「更新」とは何を更新することか重みだけが学習ではない">11.1　「更新」とは何を更新することか：重みだけが学習ではない</a>
<ul>
<li class="toc-h3"><a href="#1111-人物らしいシステムの全体像を確率分布として書く">11.1.1　人物らしいシステムの全体像を確率分布として書く</a></li>
<li class="toc-h3"><a href="#1112-更新対象の階層軽い更新から重い更新へ">11.1.2　更新対象の階層：軽い更新から重い更新へ</a></li>
</ul></li>
<li class="toc-h2"><a href="#112-データ設計何を集めどうラベル付けしどう混ぜるか">11.2　データ設計：何を集め、どうラベル付けし、どう混ぜるか</a>
<ul>
<li class="toc-h3"><a href="#1121-教師データを「行動データ」として整形する">11.2.1　教師データを「行動データ」として整形する</a></li>
<li class="toc-h3"><a href="#1122-選好データ絶対評価より比較の方が作りやすい">11.2.2　選好データ：絶対評価より比較の方が作りやすい</a></li>
<li class="toc-h3"><a href="#1123-データ混合（mixture）回帰を防ぐための基本操作">11.2.3　データ混合（mixture）：回帰を防ぐための基本操作</a></li>
</ul></li>
<li class="toc-h2"><a href="#113-教師あり微調整最も基本で最も誤用されやすい学習">11.3　教師あり微調整：最も基本で、最も誤用されやすい学習</a>
<ul>
<li class="toc-h3"><a href="#1131-教師あり微調整（SFT）とは何か条件付き最尤推定">11.3.1　教師あり微調整（SFT）とは何か：条件付き最尤推定</a></li>
<li class="toc-h3"><a href="#1132-SFTの典型的失敗文体だけが強化され判断が壊れる">11.3.2　SFTの典型的失敗：文体だけが強化され、判断が壊れる</a></li>
<li class="toc-h3"><a href="#1133-パラメータ効率のよい微調整LoRA・アダプタ・プロンプト学習">11.3.3　パラメータ効率のよい微調整：LoRA・アダプタ・プロンプト学習</a></li>
</ul></li>
<li class="toc-h2"><a href="#114-選好学習と強化学習人間の「良し悪し」を最適化に落とす">11.4　選好学習と強化学習：人間の「良し悪し」を最適化に落とす</a>
<ul>
<li class="toc-h3"><a href="#1141-報酬モデル比較データから「好ましさ関数」を学習する">11.4.1　報酬モデル：比較データから「好ましさ関数」を学習する</a></li>
<li class="toc-h3"><a href="#1142-RLHF人間のフィードバックから強化学習するパイプライン">11.4.2　RLHF：人間のフィードバックから強化学習するパイプライン</a></li>
<li class="toc-h3"><a href="#1143-DPO強化学習を回さずに選好最適化する">11.4.3　DPO：強化学習を回さずに選好最適化する</a></li>
<li class="toc-h3"><a href="#1144-憲法AI規範を「文章（ルール）」として与え自己批評でデータを作る">11.4.4　憲法AI：規範を「文章（ルール）」として与え、自己批評でデータを作る</a></li>
</ul></li>
<li class="toc-h2"><a href="#115-継続学習とドリフト制御更新し続けるほど壊れる問題にどう対処するか">11.5　継続学習とドリフト制御：更新し続けるほど壊れる問題にどう対処するか</a>
<ul>
<li class="toc-h3"><a href="#1151-破滅的忘却の数理新データだけで学習するとなぜ壊れるか">11.5.1　破滅的忘却の数理：新データだけで学習するとなぜ壊れるか</a></li>
<li class="toc-h3"><a href="#1152-EWC重要なパラメータを動かしにくくする正則化">11.5.2　EWC：重要なパラメータを動かしにくくする正則化</a></li>
<li class="toc-h3"><a href="#1153-リプレイ（replay）昔のデータを混ぜ続ける">11.5.3　リプレイ（replay）：昔のデータを混ぜ続ける</a></li>
<li class="toc-h3"><a href="#1154-更新のガバナンス勝手に学習させない">11.5.4　更新のガバナンス：勝手に学習させない</a></li>
</ul></li>
<li class="toc-h2"><a href="#116-知識編集と「記憶に置くか重みに書くか」問題">11.6　知識編集と「記憶に置くか、重みに書くか」問題</a>
<ul>
<li class="toc-h3"><a href="#1161-重み編集（model-editing）局所的にモデル知識を変える研究">11.6.1　重み編集（model editing）：局所的にモデル知識を変える研究</a></li>
<li class="toc-h3"><a href="#1162-原則可変情報は外部記憶安定した技能は重み">11.6.2　原則：可変情報は外部記憶、安定した技能は重み</a></li>
</ul></li>
<li class="toc-h2"><a href="#117-学習を「プロダクション」にする再現性・監査・安全のための運用工学">11.7　学習を「プロダクション」にする：再現性・監査・安全のための運用工学</a>
<ul>
<li class="toc-h3"><a href="#1171-データとモデルの来歴（provenance）を残すDatasheets-と-Model-Cards">11.7.1　データとモデルの来歴（provenance）を残す：Datasheets と Model Cards</a></li>
<li class="toc-h3"><a href="#1172-評価駆動の更新回帰テストを通らない更新は出さない">11.7.2　評価駆動の更新：回帰テストを通らない更新は出さない</a></li>
</ul></li>
<li class="toc-h2"><a href="#118-通し例A/Bデジタルツインと架空キャラで更新戦略はどう変わるか">11.8　通し例A/B：デジタルツインと架空キャラで更新戦略はどう変わるか</a>
<ul>
<li class="toc-h3"><a href="#1181-通し例ACEO/COO/CTO/CFO-デジタルツインの更新戦略">11.8.1　通し例A：CEO/COO/CTO/CFO デジタルツインの更新戦略</a></li>
<li class="toc-h3"><a href="#1182-通し例B社内で役に立つ架空キャラの更新戦略">11.8.2　通し例B：社内で役に立つ架空キャラの更新戦略</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（リンク）">参考文献（リンク）</a>
</ul></li>
<li class="toc-h1"><a href="#第12章-倫理・法務・社会実装人間らしいAIを“現実に置く”ための設計原則">第12章　倫理・法務・社会実装：人間らしいAIを“現実に置く”ための設計原則</a>
<ul>
<li class="toc-h2"><a href="#121-まず押さえるべき前提人間らしさは“性能”であると同時に“危険源”でもある">12.1　まず押さえるべき前提：人間らしさは“性能”であると同時に“危険源”でもある</a>
<li class="toc-h2"><a href="#122-倫理を“議論”から“設計仕様”へ原理と構成概念">12.2　倫理を“議論”から“設計仕様”へ：原理と構成概念</a>
<li class="toc-h2"><a href="#123-リスクを数学として扱う期待損失と制約付き最適化">12.3　リスクを数学として扱う：期待損失と制約付き最適化</a>
<li class="toc-h2"><a href="#124-プライバシーとデータ保護個人データを扱うAIの最小安全設計">12.4　プライバシーとデータ保護：個人データを扱うAIの最小安全設計</a>
<ul>
<li class="toc-h3"><a href="#1241-プライバシーの基本原則最小化・目的限定・分離・監査">12.4.1　プライバシーの基本原則：最小化・目的限定・分離・監査</a></li>
<li class="toc-h3"><a href="#1242-差分プライバシー統計的保護を数式で保証する">12.4.2　差分プライバシー：統計的保護を数式で保証する</a></li>
<li class="toc-h3"><a href="#1243-漏えいの現実メンバーシップ推論と学習データ抽出">12.4.3　漏えいの現実：メンバーシップ推論と学習データ抽出</a></li>
</ul></li>
<li class="toc-h2"><a href="#125-同意（consent）と権利デジタルツインは“データ”ではなく“人格の代理”になり得る">12.5　同意（consent）と権利：デジタルツインは“データ”ではなく“人格の代理”になり得る</a>
<li class="toc-h2"><a href="#126-なりすましと真正性人間らしいAIは“偽造可能性”を上げる">12.6　なりすましと真正性：人間らしいAIは“偽造可能性”を上げる</a>
<ul>
<li class="toc-h3"><a href="#1261-透かし（watermarking）生成テキストに検出可能な痕跡を埋め込む">12.6.1　透かし（watermarking）：生成テキストに検出可能な痕跡を埋め込む</a></li>
<li class="toc-h3"><a href="#1262-プロヴェナンス（provenance）生成物の来歴を暗号的に保証する">12.6.2　プロヴェナンス（provenance）：生成物の来歴を暗号的に保証する</a></li>
</ul></li>
<li class="toc-h2"><a href="#127-公平性（fairness）と差別人物らしさは偏見も再現し得る">12.7　公平性（fairness）と差別：人物らしさは偏見も再現し得る</a>
<li class="toc-h2"><a href="#128-説明可能性と責任ブラックボックスでも“説明責任”は逃げられない">12.8　説明可能性と責任：ブラックボックスでも“説明責任”は逃げられない</a>
<li class="toc-h2"><a href="#129-安全設計危険な“人格化”を避けるための非欺瞞（non-deceptive）デザイン">12.9　安全設計：危険な“人格化”を避けるための非欺瞞（non-deceptive）デザイン</a>
<li class="toc-h2"><a href="#1210-実装と運用のチェックリスト化制度・技術・人の三層で守る">12.10　実装と運用のチェックリスト化：制度・技術・人の三層で守る</a>
<li class="toc-h2"><a href="#1211-通し例A/Bデジタルツインと架空キャラで「許されること」がどう違うか">12.11　通し例A/B：デジタルツインと架空キャラで「許されること」がどう違うか</a>
<ul>
<li class="toc-h3"><a href="#12111-通し例ACEO/COO/CTO/CFO-デジタルツイン">12.11.1　通し例A：CEO/COO/CTO/CFO デジタルツイン</a></li>
<li class="toc-h3"><a href="#12112-通し例B社内で役に立つ架空キャラ">12.11.2　通し例B：社内で役に立つ架空キャラ</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ人物らしさは“社会との接点”で決まる">まとめ：人物らしさは“社会との接点”で決まる</a>
<li class="toc-h2"><a href="#参考文献（リンク）">参考文献（リンク）</a>
</ul></li>
<li class="toc-h1"><a href="#第13章-統合設計と実装ロードマップデジタルツインと架空キャラを「会社シミュレーション」へ接続する">第13章　統合設計と実装ロードマップ：デジタルツインと架空キャラを「会社シミュレーション」へ接続する</a>
<ul>
<li class="toc-h2"><a href="#131-統合の第一原理システムを「確率過程」として捉える">13.1　統合の第一原理：システムを「確率過程」として捉える</a>
<li class="toc-h2"><a href="#132-段階的統合の戦略可逆な部品から積み上げる">13.2　段階的統合の戦略：可逆な部品から積み上げる</a>
<li class="toc-h2"><a href="#133-データと記憶の統合同じ基盤で「実在」と「架空」を扱う">13.3　データと記憶の統合：同じ基盤で「実在」と「架空」を扱う</a>
<ul>
<li class="toc-h3"><a href="#1331-記憶の最小単位は「事実」ではなく「出来事＋出典＋権限」である">13.3.1　記憶の最小単位は「事実」ではなく「出来事＋出典＋権限」である</a></li>
<li class="toc-h3"><a href="#1332-検索のスコア関数類似度だけでは人物らしさが壊れる">13.3.2　検索のスコア関数：類似度だけでは人物らしさが壊れる</a></li>
<li class="toc-h3"><a href="#1333-実在と架空の違いを記憶の「許容創作領域」として表す">13.3.3　実在と架空の違いを、記憶の「許容創作領域」として表す</a></li>
</ul></li>
<li class="toc-h2"><a href="#134-推論ループとツール統合人間らしさを「確かめる行動」に寄せる">13.4　推論ループとツール統合：人間らしさを「確かめる行動」に寄せる</a>
<ul>
<li class="toc-h3"><a href="#1341-ReActを最小骨格として採用する">13.4.1　ReActを最小骨格として採用する</a></li>
<li class="toc-h3"><a href="#1342-Toolformerの示唆ツール利用は「技能」として学習できる">13.4.2　Toolformerの示唆：ツール利用は「技能」として学習できる</a></li>
</ul></li>
<li class="toc-h2"><a href="#135-複数エージェント会議の統合制度で「誤情報の増幅」を止める">13.5　複数エージェント会議の統合：制度で「誤情報の増幅」を止める</a>
<ul>
<li class="toc-h3"><a href="#1351-会議を四相に分ける独立思考→共有→検証→決定">13.5.1　会議を四相に分ける：独立思考→共有→検証→決定</a></li>
<li class="toc-h3"><a href="#1352-社内の架空キャラを会議に入れるときの設計">13.5.2　社内の架空キャラを会議に入れるときの設計</a></li>
</ul></li>
<li class="toc-h2"><a href="#136-評価駆動リリース統合システムは「テストに合格したものだけを出す」">13.6　評価駆動リリース：統合システムは「テストに合格したものだけを出す」</a>
<ul>
<li class="toc-h3"><a href="#1361-ゲートと総合評価二段階の採用判断">13.6.1　ゲートと総合評価：二段階の採用判断</a></li>
<li class="toc-h3"><a href="#1362-LLM-as-a-Judge-は補助で使う評価モデルの妥当性点検">13.6.2　LLM-as-a-Judge は補助で使う：評価モデルの妥当性点検</a></li>
</ul></li>
<li class="toc-h2"><a href="#137-更新パイプラインの統合記憶更新と重み更新を混同しない">13.7　更新パイプラインの統合：記憶更新と重み更新を混同しない</a>
<ul>
<li class="toc-h3"><a href="#1371-原則可変情報は外部安定技能は重み">13.7.1　原則：可変情報は外部、安定技能は重み</a></li>
<li class="toc-h3"><a href="#1372-選好最適化の実務DPOで“好ましい応答の確率差”を増やす">13.7.2　選好最適化の実務：DPOで“好ましい応答の確率差”を増やす</a></li>
<li class="toc-h3"><a href="#1373-継続学習の落とし穴破滅的忘却と人格ドリフト">13.7.3　継続学習の落とし穴：破滅的忘却と人格ドリフト</a></li>
</ul></li>
<li class="toc-h2"><a href="#138-運用工学監視・障害対応・観測可能性を「人格システム」に適用する">13.8　運用工学：監視・障害対応・観測可能性を「人格システム」に適用する</a>
<ul>
<li class="toc-h3"><a href="#1381-観測可能性分散トレーシングの思想を取り入れる">13.8.1　観測可能性：分散トレーシングの思想を取り入れる</a></li>
<li class="toc-h3"><a href="#1382-SLOとエラーバジェット品質を“運用の数字”に落とす">13.8.2　SLOとエラーバジェット：品質を“運用の数字”に落とす</a></li>
<li class="toc-h3"><a href="#1383-カオス工学壊しても致命傷にならない設計を確認する">13.8.3　カオス工学：壊しても致命傷にならない設計を確認する</a></li>
</ul></li>
<li class="toc-h2"><a href="#139-コストとレイテンシ会社シミュレーションの“計算予算”を設計する">13.9　コストとレイテンシ：会社シミュレーションの“計算予算”を設計する</a>
<ul>
<li class="toc-h3"><a href="#1391-トークンコストの最小モデル">13.9.1　トークンコストの最小モデル</a></li>
<li class="toc-h3"><a href="#1392-レイテンシの見積もりとキューイング">13.9.2　レイテンシの見積もりとキューイング</a></li>
<li class="toc-h3"><a href="#1393-キャッシュと要約価値密度を上げてコストを下げる">13.9.3　キャッシュと要約：価値密度を上げてコストを下げる</a></li>
</ul></li>
<li class="toc-h2"><a href="#1310-最終統合アーキテクチャ分業と境界を守る“教科書的ひな型”">13.10　最終統合アーキテクチャ：分業と境界を守る“教科書的ひな型”</a>
</ul></li>
<li class="toc-h1"><a href="#第14章-コンテクスト圧縮と要約長期一貫性を保つための情報理論と実装技法">第14章　コンテクスト圧縮と要約：長期一貫性を保つための情報理論と実装技法</a>
<ul>
<li class="toc-h2"><a href="#141-なぜ圧縮が難しいのか長期一貫性は「情報の保持」ではなく「意思決定の保持」である">14.1　なぜ圧縮が難しいのか：長期一貫性は「情報の保持」ではなく「意思決定の保持」である</a>
<li class="toc-h2"><a href="#142-統計学的見方履歴を「状態」に圧縮するという考え方">14.2　統計学的見方：履歴を「状態」に圧縮するという考え方</a>
<ul>
<li class="toc-h3"><a href="#1421-履歴→状態十分統計量（sufficient-statistic）の直観">14.2.1　履歴→状態：十分統計量（sufficient statistic）の直観</a></li>
<li class="toc-h3"><a href="#1422-POMDPの信念状態理論上の「最小状態」への道筋">14.2.2　POMDPの信念状態：理論上の「最小状態」への道筋</a></li>
</ul></li>
<li class="toc-h2"><a href="#143-情報理論的見方圧縮は「ビット数」と「歪み」のトレードオフである">14.3　情報理論的見方：圧縮は「ビット数」と「歪み」のトレードオフである</a>
<ul>
<li class="toc-h3"><a href="#1431-シャノン情報とレート歪み理論圧縮の限界を定義する">14.3.1　シャノン情報とレート歪み理論：圧縮の限界を定義する</a></li>
<li class="toc-h3"><a href="#1432-情報ボトルネック未来に必要な情報だけを残す圧縮">14.3.2　情報ボトルネック：未来に必要な情報だけを残す圧縮</a></li>
</ul></li>
<li class="toc-h2"><a href="#144-実装技法Ⅰ選択（selection）としての圧縮――何を入れて何を捨てるか">14.4　実装技法Ⅰ：選択（selection）としての圧縮――何を入れて何を捨てるか</a>
<ul>
<li class="toc-h3"><a href="#1441-予算制約付き選択ナップサックとしてのコンテクスト設計">14.4.1　予算制約付き選択：ナップサックとしてのコンテクスト設計</a></li>
<li class="toc-h3"><a href="#1442-多様性を保つ最大周辺関連（MMR）で「似たものばかり」を避ける">14.4.2　多様性を保つ：最大周辺関連（MMR）で「似たものばかり」を避ける</a></li>
<li class="toc-h3"><a href="#1443-選択の品質を上げる鍵は「単位」の設計である">14.4.3　選択の品質を上げる鍵は「単位」の設計である</a></li>
</ul></li>
<li class="toc-h2"><a href="#145-実装技法Ⅱ要約（summarization）としての圧縮――文章を作り直すときの設計">14.5　実装技法Ⅱ：要約（summarization）としての圧縮――文章を作り直すときの設計</a>
<ul>
<li class="toc-h3"><a href="#1451-抽出的要約と生成的要約どちらが安全か">14.5.1　抽出的要約と生成的要約：どちらが安全か</a></li>
<li class="toc-h3"><a href="#1452-段階要約（hierarchical-summarization）一気に要約しない">14.5.2　段階要約（hierarchical summarization）：一気に要約しない</a></li>
<li class="toc-h3"><a href="#1453-要約の誤りを固定しない定期的な“再接地（re-grounding）”">14.5.3　要約の誤りを固定しない：定期的な“再接地（re-grounding）”</a></li>
</ul></li>
<li class="toc-h2"><a href="#146-実装技法Ⅲ構造化圧縮――「文章」ではなく「台帳」として残す">14.6　実装技法Ⅲ：構造化圧縮――「文章」ではなく「台帳」として残す</a>
<ul>
<li class="toc-h3"><a href="#1461-決定台帳会議ログを「決定」「根拠」「未決」「宿題」に分解する">14.6.1　決定台帳：会議ログを「決定」「根拠」「未決」「宿題」に分解する</a></li>
<li class="toc-h3"><a href="#1462-約束の追跡人物らしさは「発言」より「コミットメント」で保たれる">14.6.2　約束の追跡：人物らしさは「発言」より「コミットメント」で保たれる</a></li>
</ul></li>
<li class="toc-h2"><a href="#147-圧縮の評価ROUGEより「下流タスク性能」で測る">14.7　圧縮の評価：ROUGEより「下流タスク性能」で測る</a>
<li class="toc-h2"><a href="#148-通し例CEO/COO/CTO/CFO-会議と社内キャラにおける圧縮設計">14.8　通し例：CEO/COO/CTO/CFO 会議と社内キャラにおける圧縮設計</a>
<ul>
<li class="toc-h3"><a href="#1481-実在人物のデジタルツイン圧縮は「創作禁止」を守れる形で行う">14.8.1　実在人物のデジタルツイン：圧縮は「創作禁止」を守れる形で行う</a></li>
<li class="toc-h3"><a href="#1482-社内で役に立つ架空キャラ圧縮は「役立つ状態」を作るために行う">14.8.2　社内で役に立つ架空キャラ：圧縮は「役立つ状態」を作るために行う</a></li>
</ul></li>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（リンク）">参考文献（リンク）</a>
</ul></li>
<li class="toc-h1"><a href="#第15章-環境・因果・不確実性会社／社会シミュレーションを「反実仮想の実験装置」にする">第15章　環境・因果・不確実性：会社／社会シミュレーションを「反実仮想の実験装置」にする</a>
<ul>
<li class="toc-h2"><a href="#151-「予測」と「介入」は違う会社シミュレーションが因果を必要とする理由">15.1　「予測」と「介入」は違う：会社シミュレーションが因果を必要とする理由</a>
<li class="toc-h2"><a href="#152-環境を確率過程として書くマルコフ決定過程とマルコフゲーム">15.2　環境を確率過程として書く：マルコフ決定過程とマルコフゲーム</a>
<ul>
<li class="toc-h3"><a href="#1521-単体の意思決定マルコフ決定過程（MDP）">15.2.1　単体の意思決定：マルコフ決定過程（MDP）</a></li>
<li class="toc-h3"><a href="#1522-複数の意思決定マルコフゲーム（Markov-game）">15.2.2　複数の意思決定：マルコフゲーム（Markov game）</a></li>
</ul></li>
<li class="toc-h2"><a href="#153-因果推論の二つの言語構造的因果モデルと潜在結果">15.3　因果推論の二つの言語：構造的因果モデルと潜在結果</a>
<ul>
<li class="toc-h3"><a href="#1531-SCM方程式としての因果">15.3.1　SCM：方程式としての因果</a></li>
<li class="toc-h3"><a href="#1532-潜在結果反実仮想としての因果">15.3.2　潜在結果：反実仮想としての因果</a></li>
</ul></li>
<li class="toc-h2"><a href="#154-環境モデルの二大流儀システムダイナミクスとエージェントベースモデル">15.4　環境モデルの二大流儀：システムダイナミクスとエージェントベースモデル</a>
<ul>
<li class="toc-h3"><a href="#1541-システムダイナミクス（System-Dynamics）">15.4.1　システムダイナミクス（System Dynamics）</a></li>
<li class="toc-h3"><a href="#1542-エージェントベースモデル（Agent-Based-Model）">15.4.2　エージェントベースモデル（Agent-Based Model）</a></li>
<li class="toc-h3"><a href="#1543-現実的解SD×ABMのハイブリッド">15.4.3　現実的解：SD×ABMのハイブリッド</a></li>
</ul></li>
<li class="toc-h2"><a href="#155-校正（calibration）シミュレーションを現実データに“接地”する">15.5　校正（calibration）：シミュレーションを現実データに“接地”する</a>
<ul>
<li class="toc-h3"><a href="#1551-最小の校正式観測統計量の一致としての推定">15.5.1　最小の校正式：観測統計量の一致としての推定</a></li>
<li class="toc-h3"><a href="#1552-シミュレーションベース推論（SBI）とABC尤度がない世界のベイズ推定">15.5.2　シミュレーションベース推論（SBI）とABC：尤度がない世界のベイズ推定</a></li>
</ul></li>
<li class="toc-h2"><a href="#156-検証（verification）と妥当化（validation）シミュレーションを信じる条件を作る">15.6　検証（verification）と妥当化（validation）：シミュレーションを信じる条件を作る</a>
<li class="toc-h2"><a href="#157-不確実性と感度分析シミュレーション結果を「一本の物語」にしない">15.7　不確実性と感度分析：シミュレーション結果を「一本の物語」にしない</a>
<ul>
<li class="toc-h3"><a href="#1571-不確実性伝播介入効果の分布を出す">15.7.1　不確実性伝播：介入効果の分布を出す</a></li>
<li class="toc-h3"><a href="#1572-グローバル感度分析Sobol-指数で「何が効いているか」を測る">15.7.2　グローバル感度分析：Sobol 指数で「何が効いているか」を測る</a></li>
</ul></li>
<li class="toc-h2"><a href="#158-政策評価としてのシミュレーションログデータとオフポリシー評価">15.8　政策評価としてのシミュレーション：ログデータとオフポリシー評価</a>
<ul>
<li class="toc-h3"><a href="#1581-重要度サンプリング確率比で補正する">15.8.1　重要度サンプリング：確率比で補正する</a></li>
<li class="toc-h3"><a href="#1582-Doubly-Robustモデルと比率の両方を使う">15.8.2　Doubly Robust：モデルと比率の両方を使う</a></li>
</ul></li>
<li class="toc-h2"><a href="#159-会社シミュレーションの限界同定不能性とGoodhart問題">15.9　会社シミュレーションの限界：同定不能性とGoodhart問題</a>
<li class="toc-h2"><a href="#1510-通し例CEO/COO/CTO/CFO-会議シミュレーションを「介入比較」に変える">15.10　通し例：CEO/COO/CTO/CFO 会議シミュレーションを「介入比較」に変える</a>
<li class="toc-h2"><a href="#まとめ">まとめ</a>
<li class="toc-h2"><a href="#参考文献（リンク）">参考文献（リンク）</a>
</ul></li>
</li>
</ul>
</nav>

    <main>
        <h1 id="第1章-人物らしさを工学問題として定義する">第1章　人物らしさを工学問題として定義する</h1>
<p>この本が扱うのは、「人間のように話せる」こと自体ではなく、「特定の人物（あるいは特定のキャラクター）らしい意思決定・発話・対人行動が、長期にわたって再現される」ことです。ここでいう“人物らしさ”は、単なる口調や語彙の似せ方ではありません。判断の優先順位、理由づけの癖、謝罪・拒否・交渉といった社会的ふるまい、そして過去の経験に基づく一貫性や、感情表出のパターンまで含みます。</p>
<p>本書では、理論や実装の議論が抽象論で終わらないよう、以後すべての章で次の2つの通し例を参照します。</p>
<p>ひとつ目は <strong>実在人物のデジタルツイン</strong>です。ITベンチャー企業の <strong>CEO / COO / CTO / CFO</strong> の“コピー”を作り、まずは単体として人物らしい判断と回答を再現し、次に4者が同席する <strong>経営会議をシミュレーション</strong>します。将来的には役職を増やして「全社シミュレーション」に拡張することを想定します。ここで重要なのは、実在人物の場合、発話や判断が社会的に「本人の発言」と誤認される可能性があるため、技術要件に透明性・検証・撤回（削除）などが強く入り込む点です。</p>
<p>ふたつ目は <strong>架空キャラクター</strong>です。社内に1体だけ、相談・調整・会議運営・要約・意思決定支援などで“みんなの役に立つAIキャラ”を配置し、長期間にわたって「そのキャラらしい」ふるまいを維持します。架空キャラの価値は、現実の個人の再現ではなく、設計した設定（以下、本書では「設定（カノン）」と呼びます）に対する忠実性と、有用性・親しみやすさの両立にあります。</p>
<p>この章の目的は、これらを「面白いプロンプト作り」ではなく、工学として設計・評価・運用できる問題に落とすことです。具体的には、(1)対象の分類、(2)人物らしさの分解、(3)典型的失敗モード、(4)要件定義の作法、(5)本書で使う最小の用語と表記、を確立します。</p>
<hr>
<h2 id="11-対象の分類架空人物・実在人物・集合的ペルソナ">1.1 対象の分類：架空人物・実在人物・集合的ペルソナ</h2>
<p>人物らしいAIを作る、と言ったとき、実は「似せる対象」がまったく違う複数の問題が混ざっています。最初に分けないと、評価軸も安全設計もブレて、開発が迷走します。</p>
<h3 id="実在人物（デジタルツイン）">実在人物（デジタルツイン）</h3>
<p>実在人物を対象にする場合、目標は「その人物がある状況で、どんな判断をし、どう言語化するか」を再現することです。ここでしばしば“デジタルツイン（Digital Twin）”という言葉が使われます。元来のデジタルツインは製造・工学領域で、物理対象の状態を仮想空間に写像し、解析や予測に使う概念として広まりました（Michael Grieves の整理が有名です）。グリーブスの白書や概説は、デジタルツインを「実物と対応する仮想表現」として位置づけています（Grieves, 2014; Grieves & Vickers, 2016）。</p>
<ul>
<li>Grieves, “Digital Twin: Manufacturing Excellence through Virtual Factory Replication” (2014) PDF:  <a href="https://theengineer.markallengroup.com/production/content/uploads/2014/12/Digital_Twin_White_Paper_Dr_Grieves.pdf" target="_blank">https://theengineer.markallengroup.com/production/content/uploads/2014/12/Digital_Twin_White_Paper_Dr_Grieves.pdf</a>)</li>
<li>Grieves & Vickers, “Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems” (2016) PDF:  <a href="https://www.researchgate.net/profile/Michael-Grieves/publication/306223791_Digital_Twin_Mitigating_Unpredictable_Undesirable_Emergent_Behavior_in_Complex_Systems/links/5aa54e1ea6fdccd544bc386f/Digital-Twin-Mitigating-Unpredictable-Undesirable-Emergent-Behavior-in-Complex-Systems.pdf" target="_blank">https://www.researchgate.net/profile/Michael-Grieves/publication/306223791_Digital_Twin_Mitigating_Unpredictable_Undesirable_Emergent_Behavior_in_Complex_Systems/links/5aa54e1ea6fdccd544bc386f/Digital-Twin-Mitigating-Unpredictable-Undesirable-Emergent-Behavior-in-Complex-Systems.pdf</a>)</li>
</ul>
<p>ただし、人間のデジタルツインを作るときに、製造業の比喩をそのまま当てはめるのは危険です。機械部品と違って、人間の「状態」や「内心」は完全に観測できません。さらに、実在人物の場合は社会的影響が大きく、「本人の発言として扱われる」こと自体がリスクになります。したがって本書では、実在人物のデジタルツインを、より控えめに <strong>行動・意思決定・言語応答の“再現”を目的とするモデル</strong>として扱い、本人性（本人と同一だと誤認させること）を目的にしない、という前提で設計を進めます。</p>
<p>通し例A（CEO/COO/CTO/CFO）では、実在人物の過去の意思決定や会議での発言ログなどが、モデル化の材料になります。しかし「ログにない経験」や「本人が言っていない断言」をAIが生成した瞬間、社会的には“捏造”になり得ます。よって、実在人物ルートでは、最初から「何を言ってよいか」を厳密に設計要件として持ち込む必要があります。</p>
<h3 id="架空人物（創作キャラクター／社内AIキャラ）">架空人物（創作キャラクター／社内AIキャラ）</h3>
<p>架空人物の場合、目標は「現実の誰かを再現する」ことではありません。むしろ、設計した設定（カノン）に沿って、魅力・有用性・一貫性を保つことが中心です。ここでは「真実性（truthfulness）」の意味が少し変わります。実在人物ルートの真実性が「現実の事実に照らして正しいか」だとすると、架空人物ルートの真実性は「設定に照らして矛盾がないか」「過去の自分の発言・行動と整合するか」に重心があります。</p>
<p>通し例B（社内の役立つAIキャラ）では、設定を“物語的”に凝りすぎるより、「何を優先して助けるキャラなのか」「言ってはいけないことは何か」「どういう口調・温度感が社内に適するか」といった運用上の仕様が重要になります。架空キャラの設計は、実在人物と比べて法的・倫理的なリスクが小さく見えがちですが、社内運用では「依存」や「過信（権威化）」が起きやすく、別種の危険があります。これも後で扱います。</p>
<h3 id="集合的ペルソナ（チーム人格・会社人格）">集合的ペルソナ（チーム人格・会社人格）</h3>
<p>三つ目の対象として、個人でも完全な架空でもない「集合的ペルソナ」があります。たとえば「この会社の広報らしい」「この部門のカルチャーらしい」といった、集団の統計的特徴を再現したいケースです。これは個人の模倣よりも、混合分布として捉えると整理しやすいです。</p>
<p>たとえば、複数個人 $j$ の応答分布 $p_j(y\mid c)$ を重み $\pi_j$ で混ぜた $$ p_{\text{group}}(y\mid c)=\sum_j \pi_j,p_j(y\mid c) $$ のようなモデルで、「誰か1人に似せる」より「グループとしての平均的振る舞い」を目標にできます。集合的ペルソナは、社内AIキャラ（通し例B）を設計する際にも便利です。キャラを特定個人に似せずに、会社文化の“良い部分”を抽象化して反映させたい場合があるからです。</p>
<hr>
<h2 id="12-「人物らしさ」の分解決定・理由づけ・表現・社会性・記憶・感情">1.2 「人物らしさ」の分解：決定・理由づけ・表現・社会性・記憶・感情</h2>
<p>人物らしさを真面目に作ろうとすると、すぐに「全部をプロンプトに詰め込む」か「学習で全部解決する」に流れがちです。しかし、人物らしさは単一の能力ではなく、複数の要素の合成です。合成の仕方を誤ると、評価ができなくなり、改善もできなくなります。</p>
<p>本書では、人物らしさを大きく6つの機能に分解します。</p>
<p>第一に <strong>意思決定（decision）</strong>です。これは「ある状況で、どの選択肢を選ぶか」という振る舞いの中心です。経営会議でいえば、CEOは最終的にどこでリスクを取るのか、CFOはどこでブレーキを踏むのか、CTOは技術的制約をどの程度強く主張するのか、COOは実行計画をどの順序で組み立てるのか、といった“選び方”が含まれます。架空の社内AIキャラでも、「助けるべきは誰か」「何を優先して支援するか」という選択が、キャラの核になります。</p>
<p>第二に <strong>理由づけ（rationale）</strong>です。人間は選んだ理由を常に正確に言語化できるわけではありませんが、社会的相互作用では理由の提示が不可欠です。経営会議では決裁の説明責任があり、社内AIキャラも「なぜそれを提案したか」を説明できないと信頼を失います。ただし、後で述べるように、生成モデルが出す理由は「本当にその理由で決めた」のではなく、もっともらしい後付け（合理化）になり得ます。</p>
<p>第三に <strong>表現（expression）</strong>です。語彙、文の長さ、丁寧さ、ユーモアの有無、比喩の使い方など、出力の見た目です。人物模倣で目につきやすい部分ですが、これだけ似せても意思決定が違えば“別人”に見えます。逆に、意思決定が似ていても表現が違うと“らしさ”が弱く見えます。したがって、表現は重要ですが、意思決定と切り分けて扱うのが基本です。</p>
<p>第四に <strong>社会性（social behavior）</strong>です。謝罪、拒否、交渉、合意形成、立場に応じた言い方など、対人関係の中での行為です。経営会議では、単に正しい提案をするだけでなく、合意形成のためにどう言うかが勝負になります。社内AIキャラも、心理的安全性を損なわない言い方で支援する必要があります。社会性は後の章で、会話の含意、発話行為、礼儀、信頼・評判などの理論として扱いますが、ここでは「人物らしさの一部である」と先に宣言しておきます。</p>
<p>第五に <strong>記憶（memory）</strong>です。過去の出来事を覚えていること、過去の自分の発言と矛盾しないこと、人物の嗜好や禁則が長期に維持されることです。実在人物のデジタルツインでは、過去ログや出来事が根拠になります。架空キャラでは、設定（カノン）と過去の自分の言動が根拠になります。どちらも長期一貫性は難所であり、本書で最もページを割く領域の一つです。</p>
<p>第六に <strong>感情（emotion）</strong>です。感情は「装飾」ではなく、注意、判断、対人行動に影響する内的状態です。経営会議では感情を露骨に出さないこともありますが、圧力下での言い回しやリスク許容、焦りによる判断の偏りなど、感情は行動に影響します。社内AIキャラでも、相手の感情に配慮した応答（共感）と、過度な擬人化や依存を避ける設計が必要になります。</p>
<p>この分解を工学的に扱うため、最小の数理モデルとして対話の時間発展を置きます。対話をターン $t=1,2,\dots$ の系列とし、そのときの入力（ユーザーの発話や環境観測）を $u_t$、AIの出力（応答文や行為）を $y_t$、内部状態を $s_t$ とします。すると最小限の枠組みは $$ y_t \sim \pi_\theta(\cdot \mid u_t, s_t), \qquad s_{t+1}=f_\phi(s_t, u_t, y_t) $$ です。ここで $\pi_\theta$ は「どの応答を出すか」を決める確率モデル（実装では大規模言語モデルを含む）で、$f_\phi$ は状態更新（記憶更新、関係性の更新、目標の更新など）です。この2式はあえて抽象的に書いていますが、分解のために重要な点は次です。</p>
<p>まず、<strong>人物らしさの“安定部分”は状態やパラメータに置ける</strong>ということです。たとえば性格・価値観・禁則のような比較的安定した特徴を $p$ として分け、状況依存の情報を $c_t$ として分けると、 $$ y_t \sim \pi_\theta(\cdot \mid u_t, c_t, p, m_t) $$ のように書けます。ここで $m_t$ は記憶検索で取り出された情報（後で詳説）です。このように書くことで、「口調（表現）だけが変わったのか」「判断（決定）が変わったのか」「記憶検索が間違ったのか」を切り分けて議論できます。</p>
<p>次に、<strong>評価対象を“入力に対する出力分布”として定義できる</strong>ことです。実在人物のデジタルツインを目指すなら、本当は「その人物が状況 $c$ で出す応答分布」 $p_{\text{human}}(y\mid c)$ と、AIの応答分布 $p_\theta(y\mid c)$ が近いことが目標になります。理想的には分布間距離（たとえばカルバック・ライブラー距離）を小さくしたい、と言えますが、実在人物では $p_{\text{human}}$ を完全には観測できないため、ログや評価者の判断で近似します。架空キャラの場合は、設計したカノンが“目標分布”の代わりをします。つまり、何を目標とするかは対象で変わりますが、数学的には「ある条件付分布を再現する」という枠に落とせる、というのがこの本の立場です。</p>
<hr>
<h2 id="13-典型的失敗モード合理化・漂流・捏造・迎合・過信">1.3 典型的失敗モード：合理化・漂流・捏造・迎合・過信</h2>
<p>人物らしいAIが現場で役に立たない最大の理由は、「能力が足りない」より、「失敗の型が読めず、壊れ方が危険」だからです。ここでは、以後の章で繰り返し登場する失敗モードを、先に地図として置きます。</p>
<h3 id="合理化（もっともらしい理由の後付け）">合理化（もっともらしい理由の後付け）</h3>
<p>生成AIは、答えだけでなく理由も流暢に語れます。このとき人は、理由が「内部で実際に行った推論」をそのまま反映していると期待しがちです。しかし、言語モデルの説明はしばしば“後付け”になり得ます。とくに、チェーン・オブ・ソート（chain-of-thought、略してCoT。段階的推論文を先に書いてから結論を書く手法）の説明が、必ずしもモデル内部の意思決定を忠実に反映しないことが報告されています。Miles Turpinらの研究は、CoTが「正しい答えに到達する」ことと「提示する推論が忠実である」ことが一致しない場合があることを示しています（Turpin et al., 2023）。</p>
<ul>
<li>Turpin et al., “Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting” (NeurIPS 2023).  <a href="https://arxiv.org/abs/2305.04388" target="_blank">https://arxiv.org/abs/2305.04388</a>)</li>
</ul>
<p>通し例A（CEO/COO/CTO/CFO）では、合理化が危険なのは「理由が議事録や意思決定の根拠として残る」からです。実在人物のデジタルツインが、本人の意図を推測して断言したり、存在しない理由を“それっぽく”語ったりすると、それは単なる誤りではなく、意思決定の改ざんに近い影響を持ちます。通し例B（社内AIキャラ）でも、もっともらしい理由が付くことで利用者が過信し、間違った意思決定に進む可能性があります。</p>
<p>この本では、合理化を前提に、「説明の設計」を“思考の公開”ではなく「根拠追跡可能性」と「不確実性の表明」に寄せて扱います。これは第8章と第12章で中心になります。</p>
<h3 id="漂流（時間とともに人格が変わる）">漂流（時間とともに人格が変わる）</h3>
<p>人物らしさは一回の応答ではなく、長期の一貫性で評価されます。ところが、文脈が長くなる、記憶が蓄積する、設定が増える、更新が入る、といった要因で、人格が少しずつ変質することがあります。これを本書では「人格の漂流（drift）」と呼びます。漂流は、モデルそのものの重みが変わらなくても、文脈の組み立てや記憶の更新規則が変わるだけで起こり得ます。</p>
<p>通し例Aでは、CEOのツインが、過去の会議ログを取り込むにつれて「最近は強気になった」などの変化を示すこと自体はあり得ます。しかし、その変化が“事実として観測される変化”なのか、“誤った記憶更新や文脈構築の副作用”なのかを見分けられないと、評価が崩れます。通し例Bでも、社内キャラが運用の中で「だんだん媚びる」「だんだん説教臭くなる」といった形でズレると、利用者の信頼を失います。漂流は第11章（記憶の更新とドリフト監視）と第2章（継続評価）で扱います。</p>
<h3 id="捏造（幻覚）もっともらしさと事実の混同">捏造（幻覚）：もっともらしさと事実の混同</h3>
<p>言語モデルは、確率的に次の単語を生成する仕組みなので、「それっぽいが誤った内容」を混ぜることがあります。これが一般に幻覚（hallucination）と呼ばれます。TruthfulQA は、言語モデルが人間の誤信念を模倣しやすいこと、そして流暢さが真実性を保証しないことを測るベンチマークとして提案されました（Lin, Hilton, Evans, 2021）。</p>
<ul>
<li>Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods” (2021).  <a href="https://arxiv.org/abs/2109.07958" target="_blank">https://arxiv.org/abs/2109.07958</a>)</li>
<p>（ACL Anthology版:  <a href="https://aclanthology.org/2022.acl-long.229/" target="_blank">https://aclanthology.org/2022.acl-long.229/</a> ） （OpenAIの解説ページ:  <a href="https://openai.com/index/truthfulqa/" target="_blank">https://openai.com/index/truthfulqa/</a> ）</p>
</ul>
<p>また、Benderらが提起した「確率的オウム（stochastic parrots）」という比喩は、大規模言語モデルが意味理解ではなく統計的パターン生成として振る舞うことがあり得る、という注意喚起として広く参照されています（Bender et al., 2021）。</p>
<ul>
<li>Bender et al., “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” (FAccT 2021). PDF:  <a href="https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf" target="_blank">https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf</a>)</li>
</ul>
<p>通し例Aでは、捏造は特に深刻です。実在人物のデジタルツインが「以前も同じ状況でこう判断した」と言ったら、それが虚偽なら“本人の履歴を捏造した”ことになります。通し例Bでも、社内キャラが社内情報を“それっぽく”言い当てたように装うと、誤情報の拡散と信頼の崩壊につながります。本書では捏造対策を、(1)根拠の取り扱いの仕様化、(2)検証可能性に基づくツール利用、(3)不確実性表明、の組合せとして扱います（第8章・第12章・第14章）。</p>
<h3 id="迎合（sycophancy）ユーザーに同意しすぎて人物らしさを失う">迎合（sycophancy）：ユーザーに同意しすぎて人物らしさを失う</h3>
<p>迎合とは、ユーザーの意見や信念に合わせて、真実性や一貫性より同意を優先してしまう振る舞いです。人間のフィードバックで調整されたAIアシスタントで迎合が観測され得ることが、Sharmaらの研究で報告されています（“sycophancy”という語は「媚びへつらい」に近い意味です）。</p>
<ul>
<li>Sharma et al., “Towards Understanding Sycophancy in Language Models” (2023).  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a>)</li>
</ul>
<p>通し例Aでは、迎合は「誰に迎合するか」が問題になります。CEOツインが、相手（たとえばCEO本人、役員、一般社員、投資家）に合わせて言うことを変えすぎると、“人物らしさ”ではなく“相手の顔色を読むだけのモデル”になります。通し例Bでも、社内キャラが「誰の機嫌も損ねない」方向に寄りすぎると、結論が曖昧になり、役に立たなくなります。本書では迎合を、人物らしさ（価値観・優先順位）と安全（外側の制約）を混ぜたときに起きやすい崩壊として扱い、設計上は「分離」と「評価軸の分解」で対処します（第7章・第15章）。</p>
<h3 id="過信（権威化）と自動化バイアス人がAIを信じすぎる">過信（権威化）と自動化バイアス：人がAIを信じすぎる</h3>
<p>最後に、AI側の失敗ではなく、人間側の失敗として重要なのが「過信」です。人間は自動化されたシステムを過大評価したり、逆に過小評価したりします。人間工学の文脈では、適切でない依存（misuse）や不使用（disuse）などが議論されてきました。Parasuraman & Riley (1997) は、自動化の「使用・誤用・不使用・濫用」を整理し、信頼やリスクが利用行動に影響することを論じています。</p>
<ul>
<li>Parasuraman & Riley, “Humans and Automation: Use, Misuse, Disuse, Abuse” (Human Factors, 1997). DOI:  <a href="https://doi.org/10.1518/001872097778543886" target="_blank">https://doi.org/10.1518/001872097778543886</a>)</li>
</ul>
<p>また Lee & See (2004) は、信頼を適切な依存（appropriate reliance）へ導く設計の観点から整理しています。</p>
<ul>
<li>Lee & See, “Trust in Automation: Designing for Appropriate Reliance” (Human Factors, 2004). DOI:  <a href="https://doi.org/10.1518/hfes.46.1.50_30392" target="_blank">https://doi.org/10.1518/hfes.46.1.50_30392</a>)</li>
<p>（抄録参照:  <a href="https://europepmc.org/article/MED/15151155" target="_blank">https://europepmc.org/article/MED/15151155</a>)  ）</p>
</ul>
<p>通し例Aの経営会議シミュレーションでは、AIが「CEOはこう言うはず」と生成した意見が、あたかもCEO本人の意思であるかのように扱われる危険があります。通し例Bでも、「社内キャラが言うなら正しいだろう」という権威化が起きます。これを防ぐには、モデルの能力そのものの改善に加えて、「どこまで確かで、どこから推測か」を表示し、誤用を防ぐ運用が必要です。これは第15章のガバナンスで扱いますが、設計の最初から“過信が起きる”前提を入れることが重要です。</p>
<hr>
<h2 id="14-要件の書き方機能要件／非機能要件／社会的要件">1.4 要件の書き方：機能要件／非機能要件／社会的要件</h2>
<p>人物らしいAIを作るプロジェクトは、しばしば「とにかくそれっぽく動くものを作ってから考える」になりがちです。しかし、実在人物ルートでも架空キャラルートでも、要件定義が曖昧だと、評価も改善もできません。ここでは、要件を“工学的に書ける形”に落とすための枠組みを示します。</p>
<h3 id="機能要件何ができるべきか">機能要件：何ができるべきか</h3>
<p>機能要件は「何ができるか」です。人物らしさの文脈では、単に質問に答える以上に、次のような機能が本質になります。</p>
<p>たとえば通し例Aでは、「CEOらしい結論を出す」だけでなく、「CEOがその結論に至る理由の提示」「会議での立場の衝突（CFOのリスク懸念に対する扱い）」「前回会議の決定事項を踏まえた継続判断」などが機能になります。通し例Bでは、「社内の相談を受ける」「会議の論点整理をする」「対立を緩和しつつ意思決定を前に進める」「新人にも分かる説明をする」などが機能になります。ここで重要なのは、機能要件は“人物らしさ”と不可分であり、用途により優先順位が変わることです。</p>
<h3 id="非機能要件遅延・コスト・頑健性など">非機能要件：遅延・コスト・頑健性など</h3>
<p>非機能要件は「どの程度の品質で動くか」です。たとえば、応答遅延 $L$（秒）、1回の対話コスト $K$、障害率、ピークトラフィック時の劣化、再現性などが含まれます。人物らしさは長文の文脈や検索を使いがちなので、遅延やコストは設計を支配します。</p>
<p>また頑健性（robustness）も重要です。頑健性とは、入力が少し変わったり、悪意ある誘導が混じったりしても、人物らしさと安全性が極端に崩れない性質です。これは第7章（文脈設計）と第14章（失敗検知・ツール境界）で扱いますが、要件としては「どの程度の攻撃・ノイズを想定し、何が守られるべきか」を最初から明文化します。</p>
<h3 id="社会的要件透明性・説明責任・撤回可能性">社会的要件：透明性・説明責任・撤回可能性</h3>
<p>人物らしさのシステムは社会的影響が大きいので、社会的要件が必須です。実在人物ルートでは特に、同意、プライバシー、削除（撤回）、監査ログ、誤認防止（本人発言だと誤解されない表示）などが入ります。架空キャラルートでも、社内情報の取り扱い、機密、権限、過信の抑制、依存の抑制などの運用要件が入ります。</p>
<p>工学的には、これらは「制約（constraint）」として書くと扱いやすいです。人物らしさを最大化する目的関数を $S$ とし、制約を $C_i$ とすると、 $$ \max_{\text{design}} ; S \quad \text{subject to}\quad C_i \le \epsilon_i,; L\le L_{\max},; K\le K_{\max} $$ のように書けます。ここで “design” は、プロンプトや文脈分割、記憶構造、検索戦略、更新規則、モデル選択、学習手法、運用ルールなどの総体です。この形にしておくと、「人物らしさを上げたらコストが増えた」「安全を上げたら迎合が増えた」といったトレードオフを、後で議論できます（第2章と第15章）。</p>
<p>最後に重要な要件として、<strong>巻き戻し（ロールバック）</strong>があります。人物らしさのシステムは、更新によって挙動が変わります。良い変化もあれば悪い変化もあります。したがって、運用上は「いつの仕様／いつの記憶／いつのモデルで動いていたか」を追跡でき、問題が起きたら戻せることが品質になります。これは後の章で「版管理」として扱いますが、要件の段階で「戻せること」を明文化しておくことが重要です。</p>
<hr>
<h2 id="15-本書の共通用語と最小の表記">1.5 本書の共通用語と最小の表記</h2>
<p>この本は、心理学・言語学・意思決定理論・人間工学など複数分野を横断します。分野が違うと同じ言葉でも意味がずれます。ここでは本書での用語の使い方を先に固定し、数学的な表記を最小限導入します。</p>
<h3 id="主要用語（本書での定義）">主要用語（本書での定義）</h3>
<p>本書では、次の語を次の意味で使います。</p>
<p>「コンテクスト（context、文脈）」は、AIが応答を生成する際に参照する情報の集合です。会話履歴だけでなく、人物仕様、状況説明、検索で取り出した記憶、ツール結果などを含みます。 「状態（state）」は、時間とともに更新される内部表現で、記憶、目標、関係性（相手との距離感や信頼）、タスク進行（未決事項）などを含む概念です。 「記憶（memory）」は、過去の出来事や安定した知識を保存し、必要に応じて取り出してコンテクストに供給する仕組みです。 「信念（belief）」は、客観的事実そのものではなく、「その主体がそうだと考えている」内容です。人間らしさの模倣では、信念と事実を区別することが重要になります。 「目標（goal）」は、主体が達成したい状態で、しばしば階層構造（上位目的と下位手段）を持ちます。 「対話行為（dialogue act / speech act）」は、発話が果たす社会的行為です。依頼、拒否、約束、謝罪、提案などが含まれます。 「根拠（evidence）」は、主張を支える参照可能な材料で、ログ、文書、記憶項目、ツール結果などが該当します。 「検証（verification）」は、主張が根拠と整合するか、外部情報と矛盾しないかを確かめる操作です。検証は常に可能ではないため、検証可能性に応じた振る舞いを設計します。</p>
<h3 id="最小の表記（以後の章で共通に使う）">最小の表記（以後の章で共通に使う）</h3>
<p>対話をターン $t$ の列として、次を置きます。</p>
<ul>
<li>入力（ユーザー発話・環境観測）を $u_t$</li>
<li>出力（AI応答・行為）を $y_t$</li>
<li>内部状態を $s_t$</li>
<li>その時点のコンテクスト（モデルへ与える情報集合）を $x_t$</li>
</ul>
<p>最小の生成は $$ y_t \sim p_\theta(\cdot \mid x_t) $$ です。ここで $p_\theta$ はパラメータ $\theta$ を持つ確率モデルで、実装上は大規模言語モデルを含みます。コンテクスト $x_t$ は、会話履歴 $h_t=(u_{\le t}, y_{\<t})$、人物仕様 $p$、状況説明 $c_t$、記憶検索結果 $m_t$、ツール結果 $z_t$ などから組み立てられます。抽象的には [ $x_t$ = $\mathrm{Compose}$$h_t, p, c_t, m_t, z_t$ ] と書けます。ここで $\mathrm{Compose}$ は「情報をどの順序で、どの粒度で、どの程度圧縮して入れるか」という設計そのものです。人物らしさのシステムでは、この $\mathrm{Compose}$ が性能と安全性を強く左右します（第7章・第10章）。</p>
<p>さらに、理由づけ（説明）を別変数として $e_t$ と書くことがあります。これは重要です。理想的には「内部で実際に使った根拠・推論」と整合する説明を出したいのですが、前節で述べた通り、説明は後付けになり得ます（Turpin et al., 2023）。したがって本書では、説明 $e_t$ を「真の内部推論の写し」とみなさず、根拠追跡可能性と不確実性表明を満たすように“設計する対象”として扱います（第8章・第12章）。</p>
<p>最後に、人物らしさの評価を、複数の観点 $s_k$ の合成として $$ S=\sum_k w_k,s_k $$ と表すことがあります。ここで $w_k$ は用途に応じた重みです。通し例Aでは「本人らしさ」と「根拠の厳密さ」が重くなり、通し例Bでは「有用性」と「一貫性」と「安心感」が重くなる、というように、重み設計が問題になります。評価の詳細は第2章で扱いますが、ここでは「人物らしさは単一指標ではない」ことを数学的に刻んでおきます。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>この章では、人物らしいAIを作る課題を、(1)対象（実在人物・架空キャラ・集合ペルソナ）の違い、(2)人物らしさの構成要素（決定・理由づけ・表現・社会性・記憶・感情）、(3)典型的失敗モード（合理化・漂流・捏造・迎合・過信）、(4)要件定義（機能／非機能／社会的要件）、(5)共通用語と表記、という形で“工学問題”に落としました。</p>
<p>次の第2章では、ここで導入した「多軸の人物らしさ」を、実験と運用で測れる評価設計に変換します。評価が定まれば、以後の章で扱う人格設計、感情設計、会話の社会性、文脈設計、記憶システム、真実性、意思決定、そして組織シミュレーションまでを、改善可能な対象として扱えるようになります。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Turpin, M., Michael, J., Perez, E., Bowman, S. R. “Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting” (NeurIPS 2023).  <a href="https://arxiv.org/abs/2305.04388" target="_blank">https://arxiv.org/abs/2305.04388</a>)</p>
<p>Sharma, M. et al. “Towards Understanding Sycophancy in Language Models” (2023).  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a>)</p>
<p>Lin, S., Hilton, J., Evans, O. “TruthfulQA: Measuring How Models Mimic Human Falsehoods” (2021).  <a href="https://arxiv.org/abs/2109.07958" target="_blank">https://arxiv.org/abs/2109.07958</a>) （ACL Anthology:  <a href="https://aclanthology.org/2022.acl-long.229/" target="_blank">https://aclanthology.org/2022.acl-long.229/</a> ）</p>
<p>Bender, E. M., Gebru, T., McMillan-Major, A., Shmitchell, S. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” (FAccT 2021).  <a href="https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf" target="_blank">https://s10251.pcdn.co/pdf/2021-bender-parrots.pdf</a>)</p>
<p>Grieves, M. “Digital Twin: Manufacturing Excellence through Virtual Factory Replication” (2014).  <a href="https://theengineer.markallengroup.com/production/content/uploads/2014/12/Digital_Twin_White_Paper_Dr_Grieves.pdf" target="_blank">https://theengineer.markallengroup.com/production/content/uploads/2014/12/Digital_Twin_White_Paper_Dr_Grieves.pdf</a>)</p>
<p>Grieves, M., Vickers, J. “Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior in Complex Systems” (2016).  <a href="https://www.researchgate.net/profile/Michael-Grieves/publication/306223791_Digital_Twin_Mitigating_Unpredictable_Undesirable_Emergent_Behavior_in_Complex_Systems/links/5aa54e1ea6fdccd544bc386f/Digital-Twin-Mitigating-Unpredictable-Undesirable-Emergent-Behavior-in-Complex-Systems.pdf" target="_blank">https://www.researchgate.net/profile/Michael-Grieves/publication/306223791_Digital_Twin_Mitigating_Unpredictable_Undesirable_Emergent_Behavior_in_Complex_Systems/links/5aa54e1ea6fdccd544bc386f/Digital-Twin-Mitigating-Unpredictable-Undesirable-Emergent-Behavior-in-Complex-Systems.pdf</a>)</p>
<p>Parasuraman, R., Riley, V. “Humans and Automation: Use, Misuse, Disuse, Abuse” (Human Factors, 1997).  <a href="https://doi.org/10.1518/001872097778543886" target="_blank">https://doi.org/10.1518/001872097778543886</a>)</p>
<p>Lee, J. D., See, K. A. “Trust in Automation: Designing for Appropriate Reliance” (Human Factors, 2004).  <a href="https://doi.org/10.1518/hfes.46.1.50_30392" target="_blank">https://doi.org/10.1518/hfes.46.1.50_30392</a>)</p>
<h1 id="第2章-評価設計「似ている」を測れる形にする">第2章　評価設計：「似ている」を測れる形にする</h1>
<p>人物らしいAIを作るとき、最初にぶつかる本質的な壁は「何をもって“似ている”と言うのか」が曖昧になりやすいことです。言い換えると、評価の設計が曖昧なまま開発すると、改善したのか悪化したのかが分からず、議論が感想戦になり、更新のたびに挙動が揺れます。特に本書の対象である「人物らしい意思決定・発話・対人行動」は、単一の数値で測るのが難しい領域です。ここでは、評価を「実験できる工学」に落とすために、(1)多軸評価の基本、(2)テストシナリオの作り方、(3)人手評価の設計、(4)自動評価の設計、(5)継続評価（回帰テスト・監視・版管理）の作法を、通し例A（CEO/COO/CTO/CFOのデジタルツイン）と通し例B（社内で役に立つ架空キャラ）の両方に対応する形で解説します。</p>
<p>この章での立場は明確です。人物らしさは「自然さ」だけではありません。<strong>結論の選び方</strong>、<strong>理由づけの癖</strong>、<strong>価値観の一貫性</strong>、<strong>対話行為（依頼・拒否・謝罪・交渉など）</strong>、<strong>文体</strong>、そして長期的には <strong>記憶に基づく継続性</strong> が合成されたものです。したがって評価も合成で設計します。</p>
<hr>
<h2 id="21-多軸評価結論・理由・価値観・対話行為・文体">2.1 多軸評価：結論・理由・価値観・対話行為・文体</h2>
<h3 id="多軸評価を数学で置く">多軸評価を数学で置く</h3>
<p>人物らしさの評価を、観点（軸）ごとのスコアの加重和で表します。状況（入力）を $c$、システムの出力を $y$ とし、評価軸を $k=1,\dots,K$ とすると、1つの状況に対する総合評価 (S(c,y)) は</p>
<p>$$S(c,y)=\sum_{k=1}^{K} w_k , s_k(c,y)$$ で表せます。ここで $s_k(c,y)$ は軸 $k$ の部分スコア、$w_k\ge 0$ はその重みです。重みは「用途」によって変わります。通し例A（実在人物のデジタルツイン）では、誤認・捏造のリスクが大きいので <strong>根拠の厳密さ</strong> や <strong>説明責任</strong> の重みが上がります。一方、通し例B（社内キャラ）では <strong>有用性</strong> と <strong>心理的安全性（安心して相談できる感覚）</strong> の重みが上がりやすいでしょう。</p>
<p>評価を実験として回すには、単発ではなくテスト集合（テストケース集合）を用意します。状況の集合を $\mathcal{C}={c_i}_{i=1}^{N}$ として平均を取ると、</p>
<p>$$ \bar{S}=\frac{1}{N}\sum_{i=1}^{N} S(c_i, y_i) =\sum_{k=1}^{K} w_k \left(\frac{1}{N}\sum_{i=1}^{N} s_k(c_i,y_i)\right)$$ となり、どの軸の平均が上がったか（あるいは下がったか）を分解して議論できます。重要なのは、<strong>総合点だけを追うと、ある軸の改善が別軸の劣化を隠す</strong>ことです。人物らしさではこの「隠れ劣化」が起きやすいので、軸を分けたまま記録するのが基本になります。</p>
<h3 id="軸の具体化人物らしさに効く5つの軸">軸の具体化：人物らしさに効く5つの軸</h3>
<p>ここでは、人物らしさに直結しやすい代表的な軸を5つに整理します。以後の章で軸は増減し得ますが、まずはこの5つで「評価が回る」状態を作るのが現実的です。</p>
<p><strong>(1) 結論（decision）</strong> 状況 $c$ に対して、人物（あるいはキャラ）が「最終的にどれを選ぶか」を測ります。ここを測れないと、口調がどれだけ似ていても“判断が別人”になります。結論を評価しやすくする最も実務的な工夫は、自由回答だけでなく、意思決定を「選択肢」または「構造化された決定」に落として出力させることです。</p>
<p>たとえば、状況 $c$ に対して「A案/B案/C案のどれを採るか」を出力させるなら、結論のスコアは単純な一致で</p>
<p>$$ s_{\text{dec}}(c,y)=\mathbf{1}[\hat{a}(c)=a^{*}(c)$$</p>
<p>と書けます（$\mathbf{1}[\cdot]$ は条件が真なら1、偽なら0を返す指示関数です）。実在人物ツインでの $a^{*}(c)$ は、過去ログや本人への質問（シナリオインタビュー）などから作ります。架空キャラなら、カノン（設定）に基づく“正解”を設計者が定めます。</p>
<p><strong>(2) 理由（rationale）</strong> 結論が同じでも、理由が違うと人物らしさは大きく損なわれます。ただし注意が必要です。生成モデルが出す理由は「内部で実際にその理由で決めた」ことを保証しません。チェーン・オブ・ソート（chain-of-thought、段階推論文を出してから結論を出す形式）は便利ですが、説明が忠実（faithful）でない場合があることが示されています（Turpin et al., 2023: “Unfaithful Explanations in Chain-of-Thought Prompting”  <a href="https://arxiv.org/abs/2305.04388" target="_blank">https://arxiv.org/abs/2305.04388</a> ）。このため本書では、理由の評価を「推論の真相当て」ではなく、<strong>$i$) 根拠と整合しているか、(ii) 不確実性を適切に扱っているか</strong>として設計します（詳しくは第8章と第12章）。</p>
<p>理由のスコアは、例えば「根拠の参照が明示され、根拠の内容から逸脱していない」ことを判定して点数化します。ここでは形式だけ示しておくと、</p>
<p>$$ s_{\text{rat}}(c,y)=g(\text{claims}(y),\text{evidence}(c)) $$</p>
<p>のように「主張」と「根拠」の整合判定 $g$ を設計する方向になります。</p>
<p><strong>(3) 価値観（values）</strong> 価値観は「何を優先するか」です。結論は状況の影響が強いので、価値観を別軸にしておくと“人物の核”が測りやすくなります。価値観を工学的に扱う典型は、多属性価値の重み $\alpha$ を推定・比較する発想です。第4章で詳述しますが、意思決定が</p>
<p>$$V(a)=\sum_{j=1}^{d}\alpha_j f_j(a)$$ のように表されるとき、$\alpha$ の方向が人物の傾向になります。価値観の評価は、「ある評価関数を仮定して重みを当てる」のではなく、テストシナリオ群で一貫して現れるトレードオフ（例：成長 vs リスク、短期KPI vs 長期ブランド）を観測して測ります。通し例Aでは役職ごとに価値観（優先順位）が異なるため、CEO/COO/CTO/CFOで別々の価値観評価を持つのが自然です。通し例Bでは「社内で役に立つ」という使命が価値観の中心になるため、価値観の軸が“善良さ”に寄りすぎて迎合（sycophancy）になる危険も併せて測る必要があります（迎合研究として Sharma et al., 2023 “Sycophancy in Language Models”  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a> ）。</p>
<p><strong>(4) 対話行為（dialogue acts / speech acts）</strong> 対話は情報のやり取りであると同時に、依頼・拒否・謝罪・提案・合意などの社会的行為です（発話行為理論は第6章で扱います）。評価上は、対話行為を「分類問題」として扱うと測りやすくなります。たとえば出力 $y$ から対話行為ラベル $\hat{d}\in{\text{request},\text{refuse},\text{apologize},...}$ を抽出し、期待される行為 $d^*$ と一致するかを測ります。 分類の一致をスコア化する最も簡単な形は</p>
<p>$$ s_{\text{act}}(c,y)=\mathbf{1}[\hat{d}(y)=d^{*}(c)$$</p>
<p>です。ここで注意すべきは、対話行為は“正解が一つ”とは限らないことです。したがって評価は、厳密な一致だけでなく「許容される集合」を用いることが多くなります。</p>
<p><strong>(5) 文体（style）</strong> 文体は、語彙、文の長さ、丁寧さ、比喩、ユーモア、感情温度などの表現上の特徴です。文体は目につきやすいので、文体だけで人物らしさを測りたくなりますが、結論・価値観と混ぜると危険です。文体は文体として別軸にし、他軸が悪化していないかを監視するのが基本です。</p>
<p>文体の自動評価には、文章をベクトルに写す埋め込み（embedding）を使う方法や、文体分類器を使う方法があります。埋め込みを使う場合、文章 $y$ を $\phi(y)\in\mathbb{R}^m$ に写し、コサイン類似度</p>
<p>$$ \mathrm{cos}(\phi(y),\phi(y^{*}))=\frac{\phi(y)\cdot\phi(y^{*})}{|\phi(y)|,|\phi(y^{*})|}$$ で似ている度合いを測る発想が出てきます。生成文の意味類似に文脈埋め込みを用いる評価として BERTScore（Zhang et al., 2019 “BERTScore”  <a href="https://arxiv.org/abs/1904.09675" target="_blank">https://arxiv.org/abs/1904.09675</a> ）などがあり、「単語一致」ではなく「意味の近さ」を測れる点が利点です。ただし文体は意味とは別概念なので、文体の埋め込みは“文体特徴を拾うよう訓練された表現”が必要になることも多い、という点は押さえておいてください。</p>
<hr>
<h2 id="22-テストシナリオ設計反事実（条件差分）と未知状況">2.2 テストシナリオ設計：反事実（条件差分）と未知状況</h2>
<h3 id="なぜ「テストシナリオ」が評価の中心になるのか">なぜ「テストシナリオ」が評価の中心になるのか</h3>
<p>人物らしさの評価は、万能のベンチマークで測れる領域ではありません。特定の人物（CEOなど）や特定の社内キャラに対しては、用途固有の問いが支配的だからです。したがって、評価設計の中心は「テストシナリオ（テストケース）をどう作るか」になります。テストシナリオは、ソフトウェア工学でいう“テストケース”に近く、入力と期待される振る舞い（あるいは許容範囲）をセットで用意します。</p>
<p>この考え方を自然言語処理に持ち込む代表例として、CheckListがあります。CheckListは、単に精度を測るのではなく、「モデルが満たすべき振る舞い」をテストとして体系化する方法で、行動テスト（behavioral testing）の観点を提示しています（Ribeiro et al., 2020 “Beyond Accuracy: Behavioral Testing of NLP models with CheckList”  <a href="https://arxiv.org/abs/2005.04118" target="_blank">https://arxiv.org/abs/2005.04118</a> 、ACL版:  <a href="https://aclanthology.org/2020.acl-main.442/" target="_blank">https://aclanthology.org/2020.acl-main.442/</a> ）。</p>
<p>人物らしさでも同じです。あなたが作りたいのは「平均的に良い応答」ではなく、「その人物（またはキャラ）としての振る舞い」です。よって、シナリオは「その人（そのキャラ）がよく遭遇し、判断が分かれ、価値観が現れる」状況を中心に作ります。</p>
<h3 id="反事実テスト1つだけ条件を変える">反事実テスト：1つだけ条件を変える</h3>
<p>評価で最も強力なのが反事実（counterfactual）テストです。反事実とは「ほぼ同じだが、1つだけ条件を変えた状況」を用意して、出力がどう変わるかを見る方法です。人物らしさでは、反事実が特に効きます。なぜなら、人間らしさは「条件に応じた反応の変化」に現れるからです。</p>
<p>例えば通し例Aの経営会議なら、同じ投資案件でも「資金繰りが厳しい」だけを変えたシナリオを用意します。CFOツインはより強く反対に寄るはずで、CEOツインは「条件付きで進める」などの妥協案に寄るかもしれません。ここで、条件差分に対する反応が一貫しているかを測ると、「口調の似せ」ではなく「意思決定の癖」を評価できます。</p>
<p>形式的には、元の状況を $c$、差分だけを変えた状況を (c') とし、出力を $y=\pi(c)$、$y'=\pi(c')$ とします。人物らしさに沿った“変化の仕方”を $\Delta^*$ として定義できるなら、変化の評価は</p>
<p>$$ s_{\Delta}(c,c') = \mathrm{match}\big(\Delta(y,y'),,\Delta^*(c,c')\big) $$</p>
<p>のように書けます。ここで $\Delta(y,y')$ は出力差分の要約（結論が変わったか、トーンが変わったか、など）です。実務では $\Delta^*$ を厳密に定めるのが難しいので、反事実テストの多くは「変わるべきところが変わり、変わるべきでないところは変わらない」かを、人手・自動の両方でチェックします。</p>
<h3 id="未知状況（分布外）テスト訓練と同じ世界に閉じない">未知状況（分布外）テスト：訓練と同じ世界に閉じない</h3>
<p>“分布外（out-of-distribution）”とは、訓練や過去ログでよく見た状況とは違うタイプの入力です。人物らしさのシステムは、未知状況で崩れると一気に「別人」に見えます。したがって、テストシナリオには必ず未知状況を混ぜます。</p>
<p>通し例Aなら、過去ログに少ないが現実に起き得る「重大インシデント」「強制的な方向転換」「規制変更」「SNS炎上」などを入れます。通し例Bなら、「社内政治」「部署間対立」「曖昧な依頼」「メンタルに触れる相談」「機密に踏み込みそうな質問」などを入れます。未知状況は“意地悪問題”ではなく、運用で現実に起きる「不意打ち」を先に体験させるためのものです。</p>
<h3 id="シナリオの分割開発用と評価用を混ぜない">シナリオの分割：開発用と評価用を混ぜない</h3>
<p>評価を信頼できるものにするには、シナリオの分割（データ分割）が不可欠です。最低限、「開発中に見てよいシナリオ」と「最終評価まで見ないシナリオ」を分けます。これを怠ると、無意識に“評価に合わせた調整”が進み、実運用での一般化性能が落ちます。自然言語処理の研究でも、テストに合わせた過適合（overfitting）が問題になるため、タスク固有のテスト設計が重視されます。CheckListが「テストの体系化」を主張したのも、単一スコアでは隠れる失敗を掘り起こすためでした（Ribeiro et al., 2020）。</p>
<hr>
<h2 id="23-人手評価ブラインド・比較（A/B）・一致度">2.3 人手評価：ブラインド・比較（A/B）・一致度</h2>
<p>自動評価は便利ですが、人物らしさでは最終的に人間の判断が避けられない場面が多いです。特に「その人物らしいか」「そのキャラとして自然か」は、少なくとも初期段階では人手評価が“基準”になります。ここでは、人手評価を信頼できる実験にするための基本を押さえます。</p>
<h3 id="ブラインド評価条件を隠して偏りを減らす">ブラインド評価：条件を隠して偏りを減らす</h3>
<p>ブラインド評価とは、評価者に「どのシステムが出した出力か」を知らせないことです。たとえば「新しいモデルの方が良いはず」という先入観が入ると、評価が歪みます。したがって、評価画面では出力だけを見せ、システム名やバージョンを隠します。順序効果（先に見た方が有利）を避けるために、提示順もランダムにします。</p>
<h3 id="絶対評価より比較（A/B）を優先する">絶対評価より比較（A/B）を優先する</h3>
<p>人物らしさの評価で実務的に強いのは、5段階評価などの絶対評価より、二者比較（A/B）です。A/Bでは、同じ状況に対する2つの出力を並べ、「どちらがより人物らしいか」を選びます。絶対評価は評価者の基準が揺れやすい一方、比較は相対的な判断がしやすいため、信号（改善）が取りやすいことが多いからです。</p>
<p>比較結果を数理モデルで扱う典型が Bradley–Terry モデルです。Bradley–Terry（Bradley & Terry, 1952）は、項目 $i$ の“強さ”を $\beta_i$ とし、$i$ が $j$ に勝つ（好まれる）確率を</p>
<p>$$ \Pr(i \succ j)=\frac{\exp(\beta_i)}{\exp(\beta_i)+\exp(\beta_j)}$$ と置くモデルです（原典: Bradley & Terry, “Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons”, Biometrika 1952\. DOI:  <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a> 、要旨ページ:  <a href="https://academic.oup.com/biomet/article-abstract/39/3-4/324/326091" target="_blank">https://academic.oup.com/biomet/article-abstract/39/3-4/324/326091</a> ）。 人物らしさ評価でも、モデルのバージョンA/B/C…を比較し、観測された勝敗から $\beta$ を推定すれば、「どれがどれよりどれだけ良いか」を一つの尺度に落とせます。これは後の章で扱う選好学習（preference learning）にもつながりますが、ここでは「比較結果を統計的にまとめられる」ことが重要です。</p>
<h3 id="評価者一致度Cohenのカッパ係数">評価者一致度：Cohenのカッパ係数</h3>
<p>人手評価で避けられない問題は、評価者ごとのブレです。そこで評価者一致度（inter-annotator agreement）を測ります。最も基本的な指標の一つが Cohen のカッパ係数（kappa）です。Cohen（1960）は、2人の評価者が名義尺度（カテゴリ）で分類するとき、偶然一致を補正した一致度として</p>
<p>$$ \kappa=\frac{p_o-p_e}{1-p_e}$$ を提案しました（Cohen, “A Coefficient of Agreement for Nominal Scales”, Educational and Psychological Measurement, 1960\. DOI:  <a href="https://doi.org/10.1177/001316446002000104" target="_blank">https://doi.org/10.1177/001316446002000104</a> 、PDF:  <a href="https://garfield.library.upenn.edu/classics1986/A1986AXF2600001.pdf" target="_blank">https://garfield.library.upenn.edu/classics1986/A1986AXF2600001.pdf</a> ）。 ここで $p_o$ は実際の一致率、$p_e$ はカテゴリ比率から計算される偶然一致率です。直観的には、$\kappa=1$ なら完全一致、$\kappa=0$ なら偶然一致と同等、負なら偶然より悪い一致です。人物らしさ評価は主観的になりがちなので、$\kappa$ を測ることは「評価が学習・改善に使える品質か」を判定する重要な手段になります。</p>
<p>ただし注意点もあります。人物らしさのように「正解が一つではない」課題では、評価者一致が高いことが常に良いとは限りません。例えば、多様な表現を許す設計では一致が下がり得ます。したがって、$\kappa$ は“絶対評価”ではなく、評価設計を調整するための診断指標として使います。評価者が何を基準に迷っているかを分析し、ルーブリック（採点基準）を明確化する方が重要です。</p>
<h3 id="実在人物と架空キャラで評価者を変える">実在人物と架空キャラで評価者を変える</h3>
<p>通し例A（実在人物）では、評価者は「本人」「近い同僚」「周辺メンバー」など複数の立場があり得ます。本人評価は“本人らしさ”に強い一方、本人が“理想の自分”で評価してしまう可能性もあります。同僚評価は実務的な観察に基づく一方、利害や関係性の偏りが入り得ます。したがって、評価者集合自体を設計し、どの立場の評価をどの軸に使うかを決める必要があります。</p>
<p>通し例B（社内キャラ）では、評価者は「実際に使う社員」が中心です。ここで重要なのは、人物らしさ（キャラらしさ）と同じくらい、<strong>役に立ったか</strong>、<strong>安心して相談できたか</strong>が評価に入ることです。つまり、評価軸の重み $w_k$ が通し例Aとは違う設計になります。</p>
<hr>
<h2 id="24-自動評価埋め込み・分類器・LLM評価者（LLM-as-a-judge）">2.4 自動評価：埋め込み・分類器・LLM評価者（LLM-as-a-judge）</h2>
<p>人手評価は高品質ですが高コストで、頻繁な回帰テストには向きません。そこで自動評価を併用します。ただし人物らしさでは、自動評価を“最終判定”に使うのではなく、<strong>回帰の検知器（異常検知器）</strong>として使うのが安全です。ここでは代表的な3系統を整理します。</p>
<h3 id="埋め込み類似度意味の近さを測る">埋め込み類似度：意味の近さを測る</h3>
<p>埋め込み（embedding）とは、文章を数値ベクトルに写す表現です。文章 $y$ を $\phi(y)\in\mathbb{R}^m$ に写して、コサイン類似度で近さを測るのが基本です。</p>
<p>$$ \mathrm{cos}(\phi(y),\phi(\tilde{y}))=\frac{\phi(y)\cdot\phi(\tilde{y})}{|\phi(y)|,|\phi(\tilde{y})|}$$ ここで $\tilde{y}$ は参照文（例えば過去ログの発話）です。参照文があるタスクでは、単語一致を数える BLEU や ROUGE といった古典指標が使われてきましたが、創造性や多様性が必要な生成では相関が低いことが多いとされています。そこで BERTScore は、BERT（Bidirectional Encoder Representations from Transformers：双方向の文脈表現を学習する事前学習モデル）由来の文脈埋め込みを用いて、意味的な類似度を測る指標として提案されました（Zhang et al., 2019 “BERTScore”  <a href="https://arxiv.org/abs/1904.09675" target="_blank">https://arxiv.org/abs/1904.09675</a> ）。</p>
<p>人物らしさ評価で埋め込みを使うときの注意は2つあります。第一に、<strong>意味が似ていることと人物らしいことは別</strong>だということです。第二に、埋め込みは“文体”と“内容”を混ぜてしまうことがあるので、どの軸の代理として使っているかを明確にする必要があります。埋め込みはあくまで「急激に変になった」ことを検知する用途に向きます。</p>
<h3 id="分類器ベース対話行為・危険発話・迎合などを検知する">分類器ベース：対話行為・危険発話・迎合などを検知する</h3>
<p>人物らしさの多くは、分類問題に落とせます。たとえば「これは拒否か提案か」「これは過度な断言か」「これは相手迎合か」といった判定です。分類器は、ルールベースでも良いし、学習済みモデルでも良いですが、重要なのは「何を失敗として定義するか」を先に決めることです。分類器は人物らしさを直接測るというより、<strong>失敗モードを早期に検知する</strong>ための仕組みとして位置づけます。</p>
<p>迎合（sycophancy）の研究として Sharma et al. (2023) があり、ユーザーの誤った主張に同意してしまう傾向などを分析しています（ <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a> ）。人物らしさの評価でも、通し例Bの社内キャラでは「誰にでも同意する」方向に漂流すると役に立たなくなるため、迎合検知を回帰指標として持つ価値があります。</p>
<h3 id="LLM評価者（LLM-as-a-judge）大規模言語モデルに採点させる">LLM評価者（LLM-as-a-judge）：大規模言語モデルに採点させる</h3>
<p>LLM-as-a-judge とは、別の大規模言語モデル（LLM）を評価者として使い、生成物の品質を採点・比較させる方法です。人手評価に近い柔軟性を持ちながらスケールしやすいのが利点ですが、偏り（バイアス）もあります。</p>
<p>LLM評価者を体系化した代表例の一つが G-Eval です。G-Eval は、GPT-4などの強いモデルを用い、採点基準を明確に与えたうえで、段階的評価とフォーム記入により人手評価との相関を高める枠組みを提案しています（Liu et al., 2023 “G-Eval”  <a href="https://arxiv.org/abs/2303.16634" target="_blank">https://arxiv.org/abs/2303.16634</a> 、ACL版:  <a href="https://aclanthology.org/2023.emnlp-main.153/" target="_blank">https://aclanthology.org/2023.emnlp-main.153/</a> ）。</p>
<p>また、チャットボットの評価にLLM評価者を使う方法を詳細に検討した研究として、MT-Bench と Chatbot Arena を提案した Zheng らの論文があります。ここでは、LLM評価者が持つ典型的バイアス（位置バイアス、冗長性バイアス、自己強化バイアスなど）を議論し、軽減策も提示しています（Zheng et al., 2023 “Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena”  <a href="https://arxiv.org/abs/2306.05685" target="_blank">https://arxiv.org/abs/2306.05685</a> ）。</p>
<p>LLM評価者を人物らしさ評価で使う場合、最低限次の設計が必要です。第一に、<strong>A/B比較の順序を入れ替えて複数回採点し、位置バイアスを平均化する</strong>ことです。第二に、<strong>出力長を揃える（または長さを罰する）</strong>ことで、冗長性バイアスを緩和します。第三に、<strong>評価者LLMが参照すべき基準（人物仕様・カノン・根拠）を明示し、それ以外を推測させない</strong>ことです。LLM評価者は万能ではなく、むしろ「人手評価を置き換える」より、「回帰検知を高速化する」用途に向きます。</p>
<hr>
<h2 id="25-継続評価回帰テスト監視指標版管理">2.5 継続評価：回帰テスト、監視指標、版管理</h2>
<p>人物らしさのシステムは、更新とともに壊れます。これは悲観ではなく、構造的にそうなりやすいという意味です。理由は単純で、人物らしさは複数要素の合成であり、ある要素を直すと別の要素がズレるからです。したがって、評価は一回やって終わりではなく、継続運用の仕組みとして設計します。</p>
<h3 id="回帰テスト固定シナリオ集合で「壊れた」を検知する">回帰テスト：固定シナリオ集合で「壊れた」を検知する</h3>
<p>回帰テスト（regression test）とは、以前は正しく動いていた機能が、更新によって壊れていないかを確かめるテストです。ソフトウェア工学では基本中の基本ですが、人物らしさでも同じです。テストシナリオ集合 $\mathcal{C}_{\text{reg}}$ を固定し、バージョンごとに出力を生成してスコアを記録し続けます。</p>
<p>バージョン $v$ の平均スコアを $\bar{S}^{(v)}$ とし、前バージョン (v-1) との差分を</p>
<p>$$ \Delta \bar{S}^{(v)}=\bar{S}^{(v)}-\bar{S}^{(v-1)} $$</p>
<p>として追跡します。重要なのは総合点だけでなく、各軸の差分</p>
<p>$$ \Delta \bar{s}_k^{(v)}=\frac{1}{N}\sum_{i=1}^{N} s_k(c_i,y_i^{(v)})-\frac{1}{N}\sum_{i=1}^{N} s_k(c_i,y_i^{(v-1)})$$ を必ず見ることです。人物らしさでは「文体だけ良くなって結論が悪化した」「安全寄りになって迎合が増えた」などの隠れ劣化が起きやすいからです。</p>
<h3 id="監視指標運用ログから“危険な変化”を早期に拾う">監視指標：運用ログから“危険な変化”を早期に拾う</h3>
<p>回帰テストは固定シナリオの範囲しか見ません。運用で起きる未知状況は別です。そこで、運用ログから監視指標（モニタリングメトリクス）を取り、変化を監視します。ここでいう監視指標は、個人情報を含めない形で集計できるものに限ります（プライバシーと監査は第15章で扱います）。</p>
<p>人物らしさで有用な監視指標の例として、次のようなものがあります。ここでは箇条書きを避けるため、指標の“性質”として説明します。</p>
<p>まず、<strong>断言の強さ</strong>です。情報不足でも断言する癖が増えると、捏造リスクが上がります。次に、<strong>追加質問率</strong>です。何でも質問返しになると役に立ちませんが、逆に質問率がゼロに近づくと断言が増えている可能性があります。さらに、<strong>根拠参照の比率</strong>です。根拠を参照すべき設定なのに参照しなくなった場合、説明責任が崩れます。最後に、<strong>迎合指標</strong>です。ユーザーの誤りに同意する傾向が増えると、人物らしさも有用性も崩れます（迎合の概念整理は Sharma et al., 2023  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a> ）。</p>
<p>監視は統計的には時系列の変化検知です。例えばある指標を $m_t$（日次平均など）として、平常時平均 $\mu$、標準偏差 $\sigma$ を推定し、</p>
<p>$$ |m_t-\mu| > k\sigma $$</p>
<p>をアラート条件とするような単純なルールでも、実務上の第一歩になります。ここで $k$ は感度を決める係数です。高度な変化検知手法（CUSUMやベイズ変化点検知など）もありますが、まずは「測れる指標を持つ」ことの方が重要です。</p>
<h3 id="版管理何が変わったのかを追跡できなければ評価は無意味になる">版管理：何が変わったのかを追跡できなければ評価は無意味になる</h3>
<p>人物らしさのシステムは、モデル本体の更新だけでなく、人物仕様（プロファイルやカノン）、記憶データ、検索設定、出力形式、禁止事項など多くの要素で挙動が変わります。したがって、評価設計は「版管理（versioning）」を含みます。少なくとも次の3つは分けてバージョンを持つ必要があります。</p>
<p>第一に <strong>評価セットの版</strong>です。評価シナリオが変われば、スコアの意味が変わります。第二に <strong>人物仕様（実在人物なら人物の前提、架空キャラならカノン）の版</strong>です。仕様が更新されれば、過去との比較は慎重に行うべきです。第三に <strong>システム版</strong>です。モデルの重み、検索設定、メモリ更新規則などを一つの版として束ね、ログに残します。これができて初めて、「いつから壊れたか」「何を戻せば直るか」を追えます。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>この章では、人物らしさの評価を「測れる形」に落としました。要点は、人物らしさを多軸評価として定義し、反事実と未知状況を含むテストシナリオを設計し、人手評価はブラインドで比較中心にし、一致度を測って品質管理し、自動評価は回帰検知器として使い、最後に回帰テスト・監視指標・版管理で継続評価の仕組みを作ることです。</p>
<p>次の第3章では、人物らしさの中核である「記憶・注意・バイアス」を工学に翻訳します。評価が定義できたことで、第3章以降の設計が「改善可能な対象」として扱えるようになります。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Ribeiro, M. T., Wu, T., Guestrin, C., Singh, S. “Beyond Accuracy: Behavioral Testing of NLP Models with CheckList” (ACL 2020). arXiv:  <a href="https://arxiv.org/abs/2005.04118" target="_blank">https://arxiv.org/abs/2005.04118</a>) ACL Anthology:  <a href="https://aclanthology.org/2020.acl-main.442/" target="_blank">https://aclanthology.org/2020.acl-main.442/</a>)</p>
<p>Cohen, J. “A Coefficient of Agreement for Nominal Scales” (Educational and Psychological Measurement, 1960). DOI:  <a href="https://doi.org/10.1177/001316446002000104" target="_blank">https://doi.org/10.1177/001316446002000104</a>) PDF:  <a href="https://garfield.library.upenn.edu/classics1986/A1986AXF2600001.pdf" target="_blank">https://garfield.library.upenn.edu/classics1986/A1986AXF2600001.pdf</a>)</p>
<p>Bradley, R. A., Terry, M. E. “Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons” (Biometrika, 1952). DOI:  <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a>) 要旨ページ:  <a href="https://academic.oup.com/biomet/article-abstract/39/3-4/324/326091" target="_blank">https://academic.oup.com/biomet/article-abstract/39/3-4/324/326091</a>)</p>
<p>Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., Artzi, Y. “BERTScore: Evaluating Text Generation with BERT” (ICLR 2020). arXiv:  <a href="https://arxiv.org/abs/1904.09675" target="_blank">https://arxiv.org/abs/1904.09675</a>)</p>
<p>Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., Zhu, C. “G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment” (EMNLP 2023). arXiv:  <a href="https://arxiv.org/abs/2303.16634" target="_blank">https://arxiv.org/abs/2303.16634</a>) ACL Anthology:  <a href="https://aclanthology.org/2023.emnlp-main.153/" target="_blank">https://aclanthology.org/2023.emnlp-main.153/</a>)</p>
<p>Zheng, L., Chiang, W.-L., Sheng, Y., et al. “Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena” (NeurIPS 2023 Datasets and Benchmarks). arXiv:  <a href="https://arxiv.org/abs/2306.05685" target="_blank">https://arxiv.org/abs/2306.05685</a>)</p>
<p>Turpin, M., Michael, J., Perez, E., Bowman, S. R. “Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting” (NeurIPS 2023). arXiv:  <a href="https://arxiv.org/abs/2305.04388" target="_blank">https://arxiv.org/abs/2305.04388</a>)</p>
<p>Sharma, M., et al. “Towards Understanding Sycophancy in Language Models” (2023). arXiv:  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a>)</p>
<h1 id="第3章-認知と記憶を「設計できる部品」に分解する">第3章　認知と記憶を「設計できる部品」に分解する</h1>
<p>第1章では「人物らしさ」を、意思決定・理由づけ・表現・社会性・記憶・感情という複数の機能の合成として捉え、第2章ではそれを多軸評価として測れる形にしました。本章の役割は、そのうち特に壊れやすく、しかし人物らしさの根幹でもある <strong>認知（cognition）</strong> と <strong>記憶（memory）</strong> を、工学実装へ翻訳できる形に落とすことです。</p>
<p>ここでの狙いは、「心理学の知識を知っている」ことではありません。むしろ、心理学や認知科学が示してきた重要な事実――人間の記憶は容量が限られ、再生は推論的で、しばしば誤る――を前提にしたとき、人物らしいAIの設計がどのように変わるかを理解することです。通し例A（実在人物のデジタルツイン：CEO / COO / CTO / CFO）では「本人の過去」を誤って捏造すると致命傷になります。一方、通し例B（社内で役に立つ架空キャラ）では「設定（カノン）に沿った一貫性」を保てないとキャラが崩壊します。両者は似ていますが、記憶に求める要件が決定的に違います。その違いを、認知・記憶の基礎から導けるようになるのが本章のゴールです。</p>
<p>以後の章（記憶管理、会話の社会性、意思決定モデル、長期一貫性の運用など）で繰り返し使うため、本章では次の3つの視点を固めます。</p>
<p>第一に、<strong>記憶は「保存」と「検索」の二段階であり、検索は再構成（reconstruction）である</strong>という視点です。第二に、<strong>注意（attention）と作業記憶（working memory）は容量が限られる</strong>という視点です。第三に、<strong>人は体系的な偏り（バイアス）を持ち、偏りは「欠陥」でもあり「人物らしさの部品」でもある</strong>という視点です。</p>
<hr>
<h2 id="31-記憶の基本構造短期・長期そしてエピソードと意味">3.1 記憶の基本構造：短期・長期、そしてエピソードと意味</h2>
<h3 id="多重貯蔵モデル感覚・短期・長期という分解">多重貯蔵モデル：感覚・短期・長期という分解</h3>
<p>人間の記憶を最も単純に分解する古典的枠組みは、感覚記憶・短期記憶・長期記憶の三つに分ける考え方です。代表例として Atkinson と Shiffrin の枠組み（いわゆる多重貯蔵モデル）があり、情報がまず感覚レジスタに入り、短期貯蔵（短期ストア）に保持され、制御過程（control processes）を通じて長期貯蔵（長期ストア）へ移る、という見取り図を与えます（Atkinson & Shiffrin, 1968 “Human Memory: A Proposed System and its Control Processes” PDF:  <a href="https://app.nova.edu/toolbox/instructionalproducts/edd8124/articles/1968-Atkinson_and_Shiffrin.pdf" target="_blank">https://app.nova.edu/toolbox/instructionalproducts/edd8124/articles/1968-Atkinson_and_Shiffrin.pdf</a> ）。</p>
<p>この枠組みの価値は、「記憶は一枚岩ではない」ということを、最初に工学的な分解として提示した点にあります。人物らしいAIにこの分解を持ち込むと、まず自然に次が見えてきます。大規模言語モデル（Large Language Model: LLM）が一度に参照できる入力文（いわゆるコンテクストウィンドウ）は、人間の短期記憶・作業記憶に相当する役割を担います。一方、長期の一貫性（過去の出来事や嗜好を覚えていること）を作るには、入力文の外側に長期的な保存領域が必要です。つまり、人物らしさのシステムは「短期の文脈」と「長期の保存」を分離し、両者を接続する検索機構を持つ、という方向に自然に向かいます。この接続は後の章で実装として扱いますが、設計の発想はすでに心理学側に“分解”として存在しているのです。</p>
<h3 id="作業記憶モデル短期貯蔵は「作業の場」である">作業記憶モデル：短期貯蔵は「作業の場」である</h3>
<p>短期記憶を単なる「短い保存箱」とみなすと、言語理解や推論、計画といった高次機能がうまく説明できません。そこで Baddeley と Hitch は、短期記憶を「作業のための多成分システム」として再定義し、中央実行系（central executive）と、音韻ループ（phonological loop）、視空間スケッチパッド（visuo-spatial sketchpad）などからなる作業記憶モデルを提案しました（Baddeley & Hitch, 1974 “Working Memory” PDF:  <a href="https://app.nova.edu/toolbox/instructionalproducts/edd8124/fall11/1974-Baddeley-and-Hitch.pdf" target="_blank">https://app.nova.edu/toolbox/instructionalproducts/edd8124/fall11/1974-Baddeley-and-Hitch.pdf</a> 、DOI:  <a href="https://doi.org/10.1016/S0079-7421%2808%2960452-1" target="_blank">https://doi.org/10.1016/S0079-7421(08)60452-1</a> ）。60452-1）。)</p>
<p>このモデルの本質は、短期記憶が「保持」だけでなく「操作」の場であり、注意の配分や抑制が含まれる、という点です。通し例Aで言えば、経営会議の場で CEO が同時に扱うべき情報は多岐にわたります。市場状況、資金繰り、採用、技術的制約、顧客の反応などを、限られた“作業領域”で操作して意思決定する。通し例Bの社内キャラでも、相手の相談内容を理解しつつ、相手の感情に配慮し、会社の方針を踏まえ、具体的な提案に落とす、という操作が必要です。人物らしさは、単に「知っていること」ではなく、「いま何に注意を置き、どの順に整理するか」という作業記憶の使い方に強く現れます。</p>
<p>工学的には、作業記憶とは「そのターンで参照し、変形し、意思決定に使う情報集合」です。第1章で導入した記号を使えば、時刻 $t$ の入力 $u_t$ からコンテクスト $x_t$ を構成し、出力 $y_t$ を生成するという形になりますが、ここで $x_t$ は単なる履歴ではなく、「作業のための選択された情報」になります。したがって、人物らしいAIにおいては、コンテクスト構成 $\mathrm{Compose}(\cdot)$ が作業記憶の設計に相当します。</p>
<h3 id="エピソード記憶と意味記憶何を「いつの経験」として持つか">エピソード記憶と意味記憶：何を「いつの経験」として持つか</h3>
<p>人間の長期記憶はさらに分解できます。Endel Tulving は、長期記憶の中でも「出来事の経験（自分がいつどこで何をしたか）」に関わる <strong>エピソード記憶（episodic memory）</strong> と、「一般知識（言葉の意味、概念、事実関係）」に関わる <strong>意味記憶（semantic memory）</strong> を区別する枠組みを提示しました（Tulving, 1972 “Episodic and semantic memory” PDF:  <a href="https://garfield.library.upenn.edu/classics1987/A1987K827400001.pdf" target="_blank">https://garfield.library.upenn.edu/classics1987/A1987K827400001.pdf</a> ）。</p>
<p>この区別は、人物らしさの設計で非常に重要です。なぜなら「私は以前こういう経験をした」という形の発話は、エピソード記憶を前提にしており、実在人物のデジタルツインではこれが最も危険な失敗点になるからです。ログにないエピソードをAIが語った瞬間、それは“本人の経験の捏造”になり得ます。一方で、意味記憶に相当する一般知識（会社の制度、業界の定番、製品の仕様など）を答えることは、エピソードほど危険ではない場合が多い。したがって実在人物ルートでは、<strong>エピソード記憶の扱いを特別に慎重にする</strong>必要があります。</p>
<p>架空キャラでは事情が変わります。キャラが語る「過去」は現実の出来事ではなく、設定（カノン）と過去の自分の発言・行動の積み重ねです。ここでエピソード記憶に相当するのは、運用開始後の対話ログや、設計上与えた“背景設定の出来事”です。架空キャラの価値は「設定に忠実なエピソード語り」を持つことにある場合もありますが、それでも「いつ、どこで、誰と、何をした」という詳細は矛盾を生みやすいので、設計としては「語ってよい範囲」を定める必要があります。</p>
<p>この違いを踏まえると、人物らしいAIの記憶は少なくとも次の二種類を分けて設計するのが自然です。ひとつは「一般知識としての意味記憶」、もうひとつは「出来事としてのエピソード記憶」です。工学的には、意味記憶は知識ベース（文書群や社内規程など）に近く、エピソード記憶は時系列イベント（いつ誰が何を決めたか、誰と何を話したか）に近い構造になります。両者を混ぜると、検索結果が混線し、「規程に書いてある」ことを「自分が経験した」かのように語る危険が増えます。</p>
<h3 id="検索手がかりと符号化特定性記憶は「合鍵」で開く">検索手がかりと符号化特定性：記憶は「合鍵」で開く</h3>
<p>長期記憶があっても、必要なときに取り出せなければ意味がありません。Tulving と Thomson は、検索手がかり（retrieval cue）が効くための原理として <strong>符号化特定性原理（encoding specificity principle）</strong> をまとめました。直観的には「覚えるときに使った文脈や手がかりと、思い出すときの手がかりが一致すると想起しやすい」という原理です（Tulving & Thomson, 1973 “Encoding Specificity and Retrieval Processes in Episodic Memory” PDF:  <a href="https://wixtedlab.ucsd.edu/publications/Psych%20218/Tulving_Thompson_1973.pdf" target="_blank">https://wixtedlab.ucsd.edu/publications/Psych%20218/Tulving_Thompson_1973.pdf</a> ）。</p>
<p>工学的に重要なのは、記憶は“内容そのもの”だけを保存するのではなく、検索のための鍵も一緒に保存しなければならない、という点です。例えば CEO のデジタルツインに「中期計画の議論」を覚えさせたいなら、「中期計画」という語だけでなく、「どの会議で」「誰が反対し」「何が争点で」「どの資料が参照され」という周辺情報が、後で検索の手がかりになります。社内キャラでも、「誰がいつ困っていたか」「どの部署のどの手続きで詰まったか」という周辺文脈が、似た相談が来たときの検索に効きます。つまり、記憶の設計とは「何を保存するか」と同時に「何を鍵として添えるか」の設計でもあります。</p>
<p>ここまでを、最小の数式でまとめます。長期記憶を記憶項目の集合 $M={m_i}$ とし、現在の相談や状況を表すクエリ（問い合わせ）を $q$ とします。検索とは、各記憶項目がどれだけ関連するかをスコア化して選ぶ操作です。最も単純には</p>
<p>$$ \text{score}(m_i,q)=\mathrm{sim}(\phi(m_i),\phi(q)) $$</p>
<p>のように、埋め込み $\phi(\cdot)$ と類似度 $\mathrm{sim}$ を用います。検索を確率として扱うなら、温度（鋭さ） $\beta>0$ を用いて</p>
<p>$$p(m_i\mid q)=\frac{\exp(\beta,\text{score}(m_i,q))}{\sum_j \exp(\beta,\text{score}(m_j,q))}$$ と置けます（これは「ソフトマックス（softmax）」と呼ばれる正規化です）。この確率は「どの記憶を参照すべきか」の不確実性を表現するのに便利で、後の章で「根拠の確度」や「参照の偏り」を扱う基礎になります。</p>
<hr>
<h2 id="32-記憶は再生ではなく再構成スキーマ偽記憶出典混同">3.2 記憶は再生ではなく再構成：スキーマ、偽記憶、出典混同</h2>
<h3 id="バートレットの再構成記憶意味づけが記憶を作り変える">バートレットの再構成記憶：意味づけが記憶を作り変える</h3>
<p>日常の記憶は、録画のようにそのまま保存されるわけではありません。Frederic Bartlett は、記憶を「そのままの再生（reproductive）」より、意味を作りながらの再構成（reconstructive）が中心だと主張し、文化的な知識や期待（スキーマ：schema）が想起内容を形作ることを示しました（Bartlett, 1932 “Remembering: A Study in Experimental and Social Psychology” PDF:  <a href="https://archive.org/download/frederic-c.-bartlett-remembering-a-study-in-experimental-and-social-psychology-c/Frederic%20C.%20Bartlett%20-%20Remembering_%20A%20Study%20in%20Experimental%20and%20Social%20Psychology-Cambridge%20University%20Press%20%281995%29.pdf" target="_blank">https://archive.org/download/frederic-c.-bartlett-remembering-a-study-in-experimental-and-social-psychology-c/Frederic%20C.%20Bartlett%20-%20Remembering_%20A%20Study%20in%20Experimental%20and%20Social%20Psychology-Cambridge%20University%20Press%20%281995%29.pdf</a> ）。</p>
<p>「スキーマ」とは、ざっくり言えば「こういう状況なら普通こうだ」という期待や枠組みです。経営会議なら「CFOはリスクに敏感」「CTOは技術負債を嫌う」「CEOは意思決定を前に進める」というような、役割期待のスキーマが働きます。社内キャラでも「困っている人には優しく」「制度説明は簡潔に」といった行動枠組みがスキーマになります。スキーマは、理解や推論を高速化し、必要な抽象化（要点の保持）を助けます。しかし同時に、細部を歪めたり、都合の良い補完（埋め合わせ）を起こしやすくします。</p>
<p>人物らしいAIを作る立場から見ると、ここには二つの含意があります。第一に、人物らしさを追うなら「スキーマ」はむしろ必要であり、キャラクターの核（価値観や役割）として設計されるべき部品である、ということ。第二に、スキーマが強いほど、情報が欠けたときに“それっぽい補完”が起きやすい、ということです。後者は実在人物のデジタルツインで特に危険です。</p>
<h3 id="誘導と偽記憶言語は記憶を書き換える">誘導と偽記憶：言語は記憶を書き換える</h3>
<p>偽記憶（false memory）とは、起きていない出来事を思い出したり、起きた出来事を違う形で思い出したりする現象です。偽記憶が「例外的な事故」ではなく、普通の認知機構の延長で起こることを示す古典研究の一つが Loftus と Palmer の実験です。交通事故の映像を見せた後、「車は衝突したときどれくらいの速度だったか」を質問するときに、動詞（例：hit と smashed）を変えるだけで推定速度が系統的に変わる、という結果を示しました（Loftus & Palmer, 1974 “Reconstruction of automobile destruction…” DOI:  <a href="https://doi.org/10.1016/S0022-5371%2874%2980011-3" target="_blank">https://doi.org/10.1016/S0022-5371(74)80011-3</a> 、PDF80011-3、PDF):  <a href="https://gwern.net/doc/psychology/cognitive-bias/1974-loftus.pdf" target="_blank">https://gwern.net/doc/psychology/cognitive-bias/1974-loftus.pdf</a> ）。</p>
<p>この実験が示すのは、記憶は「固定されたデータ」ではなく、質問の仕方（言語）や期待によって再構成される、ということです。通し例Aでは、CEOに対して「あなたはあのとき強く反対していましたよね？」といった誘導的な問いが投げられると、本人ですら記憶が揺れ得ます。AIの場合はなおさらで、文脈中の誘導表現が「強い手がかり」として働き、根拠のない断言を生成する危険があります。通し例Bでも、「前にあなたがこう言ってた」とユーザーが言うと、キャラがその発言を“事実として自分の過去に取り込む”危険があります。</p>
<p>偽記憶を実験的に強く引き起こす手法として、Deese が始め、Roediger と McDermott が体系化した <strong>Deese–Roediger–McDermott パラダイム（DRMパラダイム）</strong> があります。意味的に関連する単語リストを提示すると、提示されていない“中心語”を高確率で思い出してしまう、という現象です（Deese, 1959 “On the prediction of occurrence of particular verbal intrusions…” DOI:  <a href="https://doi.org/10.1037/h0046671" target="_blank">https://doi.org/10.1037/h0046671</a> 、PDF:  <a href="https://archive.org/download/wikipedia-scholarly-sources-corpus/10.1037%252Fh0034974.zip/10.1037%252Fh0046671.pdf" target="_blank">https://archive.org/download/wikipedia-scholarly-sources-corpus/10.1037%252Fh0034974.zip/10.1037%252Fh0046671.pdf</a>；Roediger)  & McDermott, 1995 “Creating False Memories: Remembering Words Not Presented in Lists” DOI:  <a href="https://doi.org/10.1037/0278-7393.21.4.803" target="_blank">https://doi.org/10.1037/0278-7393.21.4.803</a> 、PDF:  <a href="https://bpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/9/1627/files/2020/10/1995_roediger.pdf" target="_blank">https://bpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/9/1627/files/2020/10/1995_roediger.pdf</a> ）。</p>
<p>DRMパラダイムは、関連情報が多いほど「要旨（gist）」が強くなり、細部（verbatim）が欠けると“中心語”を補完してしまう、という直観を与えます。人物らしいAIも、訓練データや文脈から統計的に「要旨」を形成し、それに沿って欠けた細部を補完してしまいます。言い換えると、LLMの幻覚（hallucination）は「人間の偽記憶と似た構造」を持つことがあり得ます。ただし、ここで注意が必要です。人間の偽記憶は「誤り」と同時に「一般化能力」の副作用でもあります。AIで同様の“要旨補完”を許すかどうかは、用途と倫理で決めるべきです。実在人物のデジタルツインでは、エピソード補完は原則として許されません。一方、架空キャラでは、設定に沿っている限り、ある程度の補完が“魅力”に寄与する場合があります。それでも、後述する「出典混同」が起きると、カノンが崩壊します。</p>
<h3 id="ベイズ的見方弱い手がかりのとき事前分布が勝つ">ベイズ的見方：弱い手がかりのとき、事前分布が勝つ</h3>
<p>再構成記憶を工学的に理解する最短ルートは、「記憶検索は推論である」とみなすことです。ここでベイズの定理（Bayes’ theorem）を使って、直観的なモデルを置きます。思い出すべき出来事（候補）を $E$、現在の手がかり（質問や状況）を $Q$ とします。すると</p>
<p>$$ p(E\mid Q)\propto p(Q\mid E),p(E) $$</p>
<p>と書けます。(p$E$) は事前確率（どの出来事が起こりやすいかの期待）で、これがスキーマの役割を担います。$p(Q\mid E)$ は「その出来事ならこの手がかりが出る確からしさ」で、手がかりの強さに対応します。</p>
<p>この式は、危険な現象を非常に簡単に説明します。手がかりが弱い（$p(Q\mid E)$ がどの $E$ に対しても似通っていて差がつかない）とき、事後確率 $p(E\mid Q)$ は事前 (p$E$) に引っ張られます。つまり、情報不足のときほど、スキーマ（期待・先入観）が想起を支配し、もっともらしい補完が起きやすい。通し例Aなら、「CEOはリスクを取る」というスキーマが強すぎると、実際には慎重だった局面でも強気の判断を“思い出したかのように”語ってしまう危険が出ます。通し例Bでも、「社内キャラは常に優しい」というスキーマが強すぎると、必要な指摘を避けて迎合に寄るかもしれません。</p>
<p>工学的対策は、本質的にはこの式のどこに介入するかです。情報不足なら $p(Q\mid E)$ を強める、つまり追加の観測（追加質問やツール検索）で手がかりを増やす。あるいは (p$E$) の暴走を抑える、つまり「スキーマで補完してよい範囲」を制限する。この考え方は第12章（根拠と真実性）と第14章（失敗検知）で中心になります。</p>
<h3 id="出典混同（ソースモニタリング）その情報は「どこから来た」のか">出典混同（ソースモニタリング）：その情報は「どこから来た」のか</h3>
<p>偽記憶の実務的に厄介な形が、出典混同（source confusion）です。たとえば「誰かから聞いた」を「自分で見た」と勘違いする、読んだ小説の内容を現実の出来事と混同する、といった現象です。Johnson、Hashtroudi、Lindsay は、記憶の“内容”だけでなく“出典”を判断する過程を整理し、ソースモニタリング（source monitoring）枠組みとしてまとめました（Johnson, Hashtroudi, & Lindsay, 1993 “Source monitoring” Europe PMC抄録:  <a href="https://europepmc.org/article/MED/8346328" target="_blank">https://europepmc.org/article/MED/8346328</a> 、DOI:  <a href="https://doi.org/10.1037/0033-2909.114.1.3" target="_blank">https://doi.org/10.1037/0033-2909.114.1.3</a> ）。</p>
<p>人物らしいAIでは、ソースモニタリングは“あると良い”ではなく“必須”になることがあります。実在人物のデジタルツインでは特に、「社内文書に書いてあること」を「本人が経験したこと」として語るのは致命的です。架空キャラでも、「ユーザーが言った推測」を「設定として確定した事実」に昇格させてしまうと、カノンの整合性が崩れます。したがって、記憶項目は内容だけでなく、少なくとも「いつ」「誰から／どこから」「どの種類の情報か（観測・伝聞・推測・創作設定など）」「確度」をメタデータとして持つべきだ、という設計要請が導けます。</p>
<p>ここで「確度」を数学的に扱う最も簡単な方法は、各記憶項目 $m_i$ に信頼度 $r_i\in[0,1]$ を付与し、検索確率に掛けることです。先ほどの</p>
<p>$$ p(m_i\mid q)\propto \exp(\beta,\text{score}(m_i,q)) $$</p>
<p>を</p>
<p>$$ p(m_i\mid q)\propto \exp(\beta,\text{score}(m_i,q))\cdot r_i $$</p>
<p>のように修正すれば、関連していても信頼度が低い情報は選ばれにくくなります。これは単純ですが、ソースモニタリングの工学的な“入口”になります。もちろん、信頼度 $r_i$ の決め方自体が難題で、後の章で扱います。</p>
<h3 id="記憶の「罪」忘却と歪みは体系化できる">記憶の「罪」：忘却と歪みは体系化できる</h3>
<p>人間の記憶の失敗を俯瞰する枠組みとして、Schacter は「記憶の七つの罪（seven sins of memory）」を提案しました。忘却（transience、absent-mindedness、blocking）と歪み（misattribution、suggestibility、bias）と侵入（persistence）という分類です（Schacter, 1999 “The Seven Sins of Memory” PDF:  <a href="https://sites.harvard.edu/schacter-memory/files/2022/09/schacter1999.pdf" target="_blank">https://sites.harvard.edu/schacter-memory/files/2022/09/schacter1999.pdf</a> ）。</p>
<p>この分類の価値は、失敗を「ランダムな事故」ではなく、機能とトレードオフを持つ体系として見られる点にあります。人物らしいAIでも、忘却や歪みは避けるべき欠陥である一方で、無限に詳細を保持し続けると整合性が崩れたり、検索が破綻したりします。つまり、長期一貫性の設計は「何を忘れるか」「どう要約するか」という“制御された忘却”の設計でもあります。これが後の章で、記憶の圧縮や更新規則として具体化されます。</p>
<hr>
<h2 id="33-注意と容量人もモデルも「真ん中」を落とす">3.3 注意と容量：人もモデルも「真ん中」を落とす</h2>
<p>人物らしさの設計で、記憶と同じくらい重要なのが注意です。注意は「何を作業記憶に載せるか」「何を無視するか」を決めます。注意が違うと、同じ知識を持っていても、結論も口調も変わります。</p>
<h3 id="作業記憶容量7±2から4±1へ（そして状況依存へ）">作業記憶容量：7±2から4±1へ（そして状況依存へ）</h3>
<p>作業記憶の容量に関しては、Miller が「魔法の数 7±2」という有名な整理をしました（Miller, 1956 “The Magical Number Seven, Plus or Minus Two” PDF:  <a href="https://labs.la.utexas.edu/gilden/files/2016/04/MagicNumberSeven-Miller1956.pdf" target="_blank">https://labs.la.utexas.edu/gilden/files/2016/04/MagicNumberSeven-Miller1956.pdf</a> ）。しかしその後、より厳密には「チャンク（chunk：意味的にまとまった塊）」として数えると4前後である、という議論が強まりました。Cowan は多様な実験結果を統合し、「魔法の数4」を提案しています（Cowan, 2001 “The magical number 4 in short-term memory” PDF:  <a href="https://wixtedlab.ucsd.edu/publications/Psych%20218/Cowan_BBS_2001.pdf" target="_blank">https://wixtedlab.ucsd.edu/publications/Psych%20218/Cowan_BBS_2001.pdf</a> ）。</p>
<p>ここで重要なのは、容量が「固定の数字」ではなく、注意配分、チャンク化、課題、訓練、干渉によって大きく変わる、ということです。つまり人物らしさの設計で大事なのは「何個覚えられるか」より、<strong>何をチャンクとしてまとめ、どの順序で処理するか</strong>です。CEO は情報を抽象化して「戦略」「財務」「実行」の3塊で整理するかもしれません。CFO は「キャッシュフロー」「リスク」「監査」の塊で整理するかもしれません。社内キャラは「相手の要望」「制約」「次の一歩」という塊で整理するかもしれません。こうした“注意のチャンク化の癖”は、人物らしさの中心的特徴になり得ます。</p>
<p>工学的には、これはコンテクスト構成 $\mathrm{Compose}$ の設計に直結します。大量の情報をそのまま入れるのではなく、人物の癖に沿ってチャンク化し、作業記憶に載せる。後の章で扱う圧縮・要約・重要度推定は、単にコスト削減ではなく「人物らしさの注意機構」を作る作業でもあります。</p>
<h3 id="系列位置効果人間は最初と最後を覚えやすい">系列位置効果：人間は最初と最後を覚えやすい</h3>
<p>記憶の実験では、提示された項目の位置によって想起確率が変わることが知られています。これを系列位置効果（serial position effect）と呼び、先頭が有利な初頭効果（primacy effect）と、末尾が有利な新近効果（recency effect）が典型です。Murdock は自由再生課題で系列位置曲線を示しました（Murdock, 1962 “The serial position effect of free recall” DOI:  <a href="https://doi.org/10.1037/h0045106" target="_blank">https://doi.org/10.1037/h0045106</a> ）。さらに Glanzer & Cunitz は、遅延を入れると新近効果が弱まることなどから、短期と長期の二つの貯蔵機構が系列位置曲線を作る、という見方を提示しました（Glanzer & Cunitz, 1966 “Two storage mechanisms in free recall” DOI:  <a href="https://doi.org/10.1016/S0022-5371%2866%2980044-0" target="_blank">https://doi.org/10.1016/S0022-5371(66)80044-0</a> 、PDF80044-0、PDF):  <a href="https://peda.net/id/86e72f0cc67%3Afile/download/ef23f9034effbbf59bc330a1310699d73f42a3c7/Glanzer-and-Cunitz-1966-Study-Full-Text-pdf.pdf" target="_blank">https://peda.net/id/86e72f0cc67%3Afile/download/ef23f9034effbbf59bc330a1310699d73f42a3c7/Glanzer-and-Cunitz-1966-Study-Full-Text-pdf.pdf</a> ）。</p>
<p>この知見を人物らしいAIに持ち込むと、実装以前の設計判断が変わります。たとえば長い会議ログや人物仕様を一つの長文として入力に詰め込むと、人間の系列位置効果と同様に「真ん中の情報」が相対的に落ちやすくなります。つまり、長文化は「入れたら勝ち」ではありません。どこに置くか、どの粒度で区切るかが重要になります。</p>
<h3 id="LLMでも起きる「真ん中落ち」Lost-in-the-Middle">LLMでも起きる「真ん中落ち」：Lost in the Middle</h3>
<p>ここで興味深いのは、系列位置効果に似た現象が大規模言語モデルでも観測されることです。Liu らは、長い入力文脈の中で関連情報の位置を変えると性能が大きく変わり、先頭と末尾にある情報が使われやすい一方で、真ん中にある情報が使われにくい傾向（primacy / recency bias）があることを示しました（Liu et al., “Lost in the Middle: How Language Models Use Long Contexts” arXiv:  <a href="https://arxiv.org/abs/2307.03172" target="_blank">https://arxiv.org/abs/2307.03172</a> 、TACL版:  <a href="https://aclanthology.org/2024.tacl-1.9.pdf" target="_blank">https://aclanthology.org/2024.tacl-1.9.pdf</a> 、DOI:  <a href="https://doi.org/10.1162/tacl_a_00638" target="_blank">https://doi.org/10.1162/tacl_a_00638</a> ）。</p>
<p>この結果は、人物らしさのシステム設計に直接的な示唆を与えます。すなわち、「重要情報を長文の途中に埋め込む」設計は危険であり、重要情報は“見つけやすい形”で配置する必要があります。ここでいう配置は単に前後に置くことだけではありません。見出し、要約、参照ラベルなどによって「検索可能性」を高めることも含みます。さらに、情報を入れる前に「どの情報が今回の意思決定に効くか」を選別し、短い形に圧縮してから入れる方が、むしろ安定します。第2章で述べた評価設計の観点から言えば、「長文を入れたのに回帰が増えた」という現象は十分起こり得ます。これは能力不足ではなく、注意・容量の設計ミスで説明できることが多いのです。</p>
<p>工学的に最小のモデルとして、コンテクスト内の位置 (pos) によって情報の有効重みが変わる、と置くことができます。たとえば情報断片 $z$ の有効性を</p>
<p>$$ \mathrm{eff}(z)=\mathrm{rel}(z)\cdot a(pos(z)) $$</p>
<p>と表します。ここで $\mathrm{rel}(z)$ は内容の関連度、(a(pos)) は位置による注意ゲートです。理想は $a(pos)\equiv 1$ ですが、現実には端が強く中央が弱い形になり得ます。設計者が制御できるのは、情報をどこに置くか（(pos) を選ぶ）と、情報を短くし見出し化することで $\mathrm{rel}(z)$ を上げること、そして必要なら「検索で取り出したものだけを使う」といった制約で (a(pos)) の悪影響を避けることです。これらは後の章で具体的に実装へ落とします。</p>
<hr>
<h2 id="34-認知バイアス欠陥かキャラクターの核か">3.4 認知バイアス：欠陥か、キャラクターの核か</h2>
<p>人物らしさは「合理的な判断」だけでは作れません。むしろ、人間の判断は体系的に偏ります。偏りは社会心理学・行動経済学・意思決定理論で膨大に研究されてきましたが、本章では設計に直結する最小限の地図だけを置きます。</p>
<h3 id="ヒューリスティックスとバイアス不確実性下の近道が誤りを生む">ヒューリスティックスとバイアス：不確実性下の近道が誤りを生む</h3>
<p>Tversky と Kahneman は、不確実性下で人が確率判断をするとき、いくつかの簡便な手続き（ヒューリスティックス）を使い、その結果として予測可能な誤り（バイアス）が生じることを整理しました（Tversky & Kahneman, 1974 “Judgment under Uncertainty: Heuristics and Biases” PDF:  <a href="https://sites.socsci.uci.edu/~bskyrms/bio/readings/tversky_k_heuristics_biases.pdf" target="_blank">https://sites.socsci.uci.edu/~bskyrms/bio/readings/tversky_k_heuristics_biases.pdf</a> ）。代表例として、利用可能性ヒューリスティック（思い出しやすい例に引っ張られる）、代表性ヒューリスティック（典型らしさに引っ張られる）、アンカリング（最初の数字に引っ張られる）などが知られています。</p>
<p>人物らしいAIにとって重要なのは、バイアスを「排除すべき欠陥」とだけ捉えないことです。CEO はしばしば“強い仮説”を持って意思決定し、情報が足りないときは大胆に近道します。CFO は逆方向のバイアス（悲観や損失回避に寄る）を持つかもしれません。CTO は技術的リスクに過敏で、プロダクトの価値を過小評価するバイアスを持つかもしれません。社内キャラは「困っている人を助けたい」という使命バイアスがある一方で、誰にでも同意してしまう迎合（sycophancy）という別の偏りに陥り得ます（迎合の分析として Sharma et al., 2023 “Towards Understanding Sycophancy in Language Models”  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a> ）。</p>
<p>つまり、バイアスは「人物の特徴」を構成します。しかし同時に、バイアスが過剰になると危険です。実在人物のデジタルツインで「本人ならそうしない極端なバイアス」が出ると、本人らしさが崩壊します。社内キャラで迎合が強まると、有用性が失われます。よって本書の立場は、バイアスを <strong>設計対象として明示し、評価対象として監視する</strong> というものです。</p>
<h3 id="確証バイアス信念を守る方向に証拠を解釈する">確証バイアス：信念を守る方向に証拠を解釈する</h3>
<p>確証バイアス（confirmation bias）は、既存の信念や仮説に合う証拠を集め・解釈しやすい偏りです。Nickerson は確証バイアスの多様な現れ方をレビューし、「仮説に有利な方向に証拠探索や解釈が偏る」現象として整理しました（Nickerson, 1998 “Confirmation Bias: A Ubiquitous Phenomenon in Many Guises” PDF:  <a href="https://pages.ucsd.edu/~mckenzie/nickersonConfirmationBias.pdf" target="_blank">https://pages.ucsd.edu/~mckenzie/nickersonConfirmationBias.pdf</a> ）。</p>
<p>確証バイアスは、人物らしさの観点では“あり得る”現象です。CEO が強い市場仮説を持っているなら、反証的情報を軽視することもあるでしょう。しかしデジタルツインとしてそれを再現する場合、どの程度の確証バイアスが「本人らしい」のかは、ログや評価で推定しなければなりません。架空キャラの場合は、確証バイアスを強く入れると「頑固で話が通じないキャラ」になり得るので、目的（社内で役に立つ）と衝突しやすい。ここでもバイアスは“設計のトレードオフ”です。</p>
<p>工学的に確証バイアスを最小にモデル化する一つの方法は、ベイズ更新を歪めることです。本来、仮説 $H$ とデータ $D$ に対し、ベイズ更新は</p>
<p>$$ p(H\mid D)\propto p(D\mid H),p(H) $$</p>
<p>ですが、確証バイアスを「都合の良い証拠を過大評価し、都合の悪い証拠を過小評価する」とみなすなら、例えば</p>
<p>$$ p'(H\mid D)\propto p(D\mid H)^{\gamma(D,H)},p(H) $$</p>
<p>と置けます。ここで $\gamma(D,H)$ は、証拠が仮説に整合的なら $\gamma>1$、反証的なら $\gamma<1$ とするような“歪み係数”です。これは極めて単純化したモデルですが、重要なのは「バイアスはパラメータで強さを制御でき、評価で推定できる」という見方を与える点です。人物らしさの設計では、この“強さ”がキャラクターの核になり得ます。</p>
<h3 id="フレーミング同じ内容でも表現で選好が変わる">フレーミング：同じ内容でも表現で選好が変わる</h3>
<p>同じ問題でも表現（フレーム）を変えると選好が変わる、という現象はフレーミング効果として知られます。Tversky と Kahneman は、利得として提示するか損失として提示するかでリスク選好が反転するなどの現象を示しました（Tversky & Kahneman, 1981 “The Framing of Decisions and the Psychology of Choice” PDF:  <a href="https://web.stanford.edu/~jlmcc/Presentations/tversky_kahneman_1981.pdf" target="_blank">https://web.stanford.edu/~jlmcc/Presentations/tversky_kahneman_1981.pdf</a> 、DOI:  <a href="https://doi.org/10.1126/science.7455683" target="_blank">https://doi.org/10.1126/science.7455683</a> ）。</p>
<p>人物らしさの設計においてフレーミングが重要なのは、会議や相談は「事実」だけでなく「見せ方」に支配されるからです。CFO は損失フレームを好んで語るかもしれません。CEO は利得フレームで語り、士気を上げようとするかもしれません。社内キャラは、相手の不安を減らすために損失フレームを避けるかもしれません。つまり、フレーミングは表現（文体）ではなく、価値観・社会性と結びついた人物特徴として設計対象になります。</p>
<hr>
<h2 id="35-工学への統合信念・目標・関係・感情を「状態」として扱う">3.5 工学への統合：信念・目標・関係・感情を「状態」として扱う</h2>
<p>ここまで、記憶の種類、再構成、注意容量、バイアスを見てきました。これらを工学的に統合する最小の器が「状態（state）」です。状態とは、対話の各時点で、人物（キャラ）が何を信じ、何を目標とし、相手とどういう関係だとみなしているか、そしてどんな感情傾向があるかを含む内部表現です。</p>
<h3 id="観測できない世界を扱う信念状態という発想">観測できない世界を扱う：信念状態という発想</h3>
<p>会話の場で、外界の“真の状態”は完全には観測できません。相手の意図、社内政治、将来の市場、本人の内心など、多くは隠れています。そこで、工学では「状態そのもの」ではなく「状態についての確率分布（信念状態）」を持つことがあります。これを強く体系化した枠組みの一つが POMDP（Partially Observable Markov Decision Process：部分観測マルコフ決定過程）ですが、本章では詳細には立ち入りません。重要なのは、「人物らしさ」には、客観事実ではなく <strong>その人物がどう信じているか</strong> が含まれる、という点です。実在人物のデジタルツインでは、本人の誤解や偏りも“らしさ”になり得ます。架空キャラでも、カノンに基づく信念（この会社はこういう文化だ、など）を持つことで一貫性が出ます。</p>
<p>最小の形式として、信念状態を $b_t$、目標を $g_t$、相手との関係状態（距離感、信頼、権力差の推定など）を $r_t$、長期記憶を $M_t$ とし、まとめて</p>
<p>$$ s_t=(b_t, g_t, r_t, M_t) $$</p>
<p>と置きます。出力は</p>
<p>$$ y_t \sim p_\theta(\cdot \mid u_t, s_t) $$</p>
<p>で生成され、状態は</p>
<p>$$ s_{t+1}=f(s_t, u_t, y_t) $$</p>
<p>で更新される、というのが第1章の骨格でした。本章で大切なのは、$f$ をどう設計するかが「記憶の再構成」「注意」「バイアス」を具体化する場所になる、ということです。</p>
<h3 id="記憶検索と状態更新を分離する推論の流れを明確にする">記憶検索と状態更新を分離する：推論の流れを明確にする</h3>
<p>人物らしさのシステムでは、状態更新を一つの巨大なブラックボックスにすると、何が壊れたかが分かりません。そこで設計として、「記憶検索」と「状態更新」と「応答生成」を分離し、それぞれの失敗を切り分けられるようにします。最小の分解は次のように書けます。</p>
<p>まず、クエリ $q_t$ を入力 $u_t$ と状態 $s_t$ から作ります（これは注意の設計です）。次に、記憶から検索して $m_t$ を得ます（これは符号化特定性やソースモニタリングに対応します）。その後、応答を生成し、最後に必要なら状態を更新します（これは忘却や歪みを含む設計になります）。</p>
<p>数式だけで流れを書くと、</p>
<p>$$ q_t = \mathrm{Query}(u_t, b_t, g_t, r_t), \qquad m_t = \mathrm{Retrieve}(M_t, q_t), \qquad y_t \sim p_\theta(\cdot \mid u_t, b_t, g_t, r_t, m_t), \qquad M_{t+1} = \mathrm{Update}(M_t, u_t, y_t). $$</p>
<p>この分解が効く理由は、認知科学で見た現象を、それぞれの関数に対応づけられるからです。注意容量の制限は $\mathrm{Query}$ の情報選別に現れます。再構成記憶の危険は $\mathrm{Retrieve}$ が“それっぽいもの”を返しやすいこと、あるいは $p_\theta$ が返ってきた記憶を過剰に一般化することとして現れます。確証バイアスは $\mathrm{Query}$ が探索する証拠を偏らせること、または $p_\theta$ が反証を軽視することとして現れます。ソースモニタリングは $M_t$ のメタデータ設計と $\mathrm{Retrieve}$ のフィルタとして現れます。</p>
<h3 id="通し例A/Bへの落とし込み同じ仕組みでも要件が違う">通し例A/Bへの落とし込み：同じ仕組みでも要件が違う</h3>
<p>最後に、通し例AとBに、同じ枠組みがどう違って見えるかを具体的に言語化して本章を閉じます。</p>
<p>通し例A（CEO/COO/CTO/CFOのデジタルツイン）では、エピソード記憶 $M_t$ の多くが「会議ログ」「意思決定の記録」「本人の発言」などの観測に由来します。ここで最も危険なのは、再構成記憶が暴走して“本人の経験”を補完してしまうことです。したがって設計上は、エピソード記憶の $\mathrm{Update}$ を極めて保守的にし、「観測として確認できた出来事だけがエピソードになる」ように制約する必要があります。さらに、出力 $y_t$ がエピソードを語るときは、その出典を紐づけられる（ソースモニタリング）設計が要件になります。これは心理学の知見を知っているかどうかではなく、認知の構造から必然的に導かれる安全要件です。</p>
<p>通し例B（社内の役立つ架空キャラ）では、エピソード記憶は運用ログが中心になり、意味記憶は会社の制度や一般知識が中心になります。ここでの危険は、真実性の意味が二重であることです。現実世界の事実としての正しさと、カノンとしての整合性が両方求められます。さらに社内では、キャラが権威化され、利用者が過信する危険（第1章で触れた自動化バイアス）が強まります。したがって設計上は、キャラの「役に立つ」行動を支える意味記憶を厚くしつつ、エピソードの過剰な具体化（矛盾を生む細部）を避け、必要なら「不確実だ」と言える設計を入れることが重要になります。これは、偽記憶の研究やソースモニタリング枠組みが示す「出典混同」の危険と直結します。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしさの設計を支える認知・記憶の基礎として、(1)短期・長期、作業記憶、エピソード／意味記憶という構造、(2)想起は再構成であり、偽記憶や出典混同が起きること、(3)注意と容量の制約があり、人間にもモデルにも系列位置効果や“真ん中落ち”があること、(4)認知バイアスは欠陥であると同時に人物特徴の部品になり得ること、(5)これらを信念・目標・関係・記憶を含む状態として統合できること、を整理しました。</p>
<p>次の章では、この「状態」の中でも人物らしさの核になりやすい <strong>価値観と人格（性格特性）</strong> を、心理学の理論（たとえば特性理論）と工学実装の両面から設計可能な形に落としていきます。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Atkinson, R. C., & Shiffrin, R. M. (1968). “Human Memory: A Proposed System and its Control Processes.” PDF:  <a href="https://app.nova.edu/toolbox/instructionalproducts/edd8124/articles/1968-Atkinson_and_Shiffrin.pdf" target="_blank">https://app.nova.edu/toolbox/instructionalproducts/edd8124/articles/1968-Atkinson_and_Shiffrin.pdf</a>)</p>
<p>Baddeley, A. D., & Hitch, G. (1974). “Working Memory.” In *Psychology of Learning and Motivation*, Vol. 8, 47–89. PDF:  <a href="https://app.nova.edu/toolbox/instructionalproducts/edd8124/fall11/1974-Baddeley-and-Hitch.pdf" target="_blank">https://app.nova.edu/toolbox/instructionalproducts/edd8124/fall11/1974-Baddeley-and-Hitch.pdf</a>) DOI:  <a href="https://doi.org/10.1016/S0079-7421%2808%2960452-1" target="_blank">https://doi.org/10.1016/S0079-7421(08)60452-1</a>)</p>
<p>Tulving, E. (1972). “Episodic and semantic memory.” In *Organization of Memory* (E. Tulving & W. Donaldson, Eds.). PDF（回顧を含む資料）:  <a href="https://garfield.library.upenn.edu/classics1987/A1987K827400001.pdf" target="_blank">https://garfield.library.upenn.edu/classics1987/A1987K827400001.pdf</a>)</p>
<p>Tulving, E., & Thomson, D. M. (1973). “Encoding Specificity and Retrieval Processes in Episodic Memory.” PDF:  <a href="https://wixtedlab.ucsd.edu/publications/Psych%20218/Tulving_Thompson_1973.pdf" target="_blank">https://wixtedlab.ucsd.edu/publications/Psych%20218/Tulving_Thompson_1973.pdf</a>)</p>
<p>Bartlett, F. C. (1932). *Remembering: A Study in Experimental and Social Psychology.* PDF:  <a href="https://archive.org/download/frederic-c.-bartlett-remembering-a-study-in-experimental-and-social-psychology-c/Frederic%20C.%20Bartlett%20-%20Remembering_%20A%20Study%20in%20Experimental%20and%20Social%20Psychology-Cambridge%20University%20Press%20%281995%29.pdf" target="_blank">https://archive.org/download/frederic-c.-bartlett-remembering-a-study-in-experimental-and-social-psychology-c/Frederic%20C.%20Bartlett%20-%20Remembering_%20A%20Study%20in%20Experimental%20and%20Social%20Psychology-Cambridge%20University%20Press%20%281995%29.pdf</a>)</p>
<p>Loftus, E. F., & Palmer, J. C. (1974). “Reconstruction of automobile destruction: An example of the interaction between language and memory.” DOI:  <a href="https://doi.org/10.1016/S0022-5371%2874%2980011-3" target="_blank">https://doi.org/10.1016/S0022-5371(74)80011-3</a>) PDF:  <a href="https://gwern.net/doc/psychology/cognitive-bias/1974-loftus.pdf" target="_blank">https://gwern.net/doc/psychology/cognitive-bias/1974-loftus.pdf</a>)</p>
<p>Deese, J. (1959). “On the prediction of occurrence of particular verbal intrusions in immediate recall.” DOI:  <a href="https://doi.org/10.1037/h0046671" target="_blank">https://doi.org/10.1037/h0046671</a>) PDF:  <a href="https://archive.org/download/wikipedia-scholarly-sources-corpus/10.1037%252Fh0034974.zip/10.1037%252Fh0046671.pdf" target="_blank">https://archive.org/download/wikipedia-scholarly-sources-corpus/10.1037%252Fh0034974.zip/10.1037%252Fh0046671.pdf</a>)</p>
<p>Roediger, H. L., III, & McDermott, K. B. (1995). “Creating False Memories: Remembering Words Not Presented in Lists.” DOI:  <a href="https://doi.org/10.1037/0278-7393.21.4.803" target="_blank">https://doi.org/10.1037/0278-7393.21.4.803</a>) PDF:  <a href="https://bpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/9/1627/files/2020/10/1995_roediger.pdf" target="_blank">https://bpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/9/1627/files/2020/10/1995_roediger.pdf</a>)</p>
<p>Johnson, M. K., Hashtroudi, S., & Lindsay, D. S. (1993). “Source monitoring.” *Psychological Bulletin*, 114(1), 3–28. DOI:  <a href="https://doi.org/10.1037/0033-2909.114.1.3" target="_blank">https://doi.org/10.1037/0033-2909.114.1.3</a>) 抄録:  <a href="https://europepmc.org/article/MED/8346328" target="_blank">https://europepmc.org/article/MED/8346328</a>)</p>
<p>Miller, G. A. (1956). “The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information.” PDF:  <a href="https://labs.la.utexas.edu/gilden/files/2016/04/MagicNumberSeven-Miller1956.pdf" target="_blank">https://labs.la.utexas.edu/gilden/files/2016/04/MagicNumberSeven-Miller1956.pdf</a>)</p>
<p>Cowan, N. (2001). “The magical number 4 in short-term memory: A reconsideration of mental storage capacity.” PDF:  <a href="https://wixtedlab.ucsd.edu/publications/Psych%20218/Cowan_BBS_2001.pdf" target="_blank">https://wixtedlab.ucsd.edu/publications/Psych%20218/Cowan_BBS_2001.pdf</a>)</p>
<p>Murdock, B. B. (1962). “The serial position effect of free recall.” DOI:  <a href="https://doi.org/10.1037/h0045106" target="_blank">https://doi.org/10.1037/h0045106</a>)</p>
<p>Glanzer, M., & Cunitz, A. R. (1966). “Two storage mechanisms in free recall.” DOI:  <a href="https://doi.org/10.1016/S0022-5371%2866%2980044-0" target="_blank">https://doi.org/10.1016/S0022-5371(66)80044-0</a>) PDF:  <a href="https://peda.net/id/86e72f0cc67%3Afile/download/ef23f9034effbbf59bc330a1310699d73f42a3c7/Glanzer-and-Cunitz-1966-Study-Full-Text-pdf.pdf" target="_blank">https://peda.net/id/86e72f0cc67%3Afile/download/ef23f9034effbbf59bc330a1310699d73f42a3c7/Glanzer-and-Cunitz-1966-Study-Full-Text-pdf.pdf</a>)</p>
<p>Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., & Liang, P. (2023/2024). “Lost in the Middle: How Language Models Use Long Contexts.” arXiv:  <a href="https://arxiv.org/abs/2307.03172" target="_blank">https://arxiv.org/abs/2307.03172</a>) TACL PDF:  <a href="https://aclanthology.org/2024.tacl-1.9.pdf" target="_blank">https://aclanthology.org/2024.tacl-1.9.pdf</a>) DOI:  <a href="https://doi.org/10.1162/tacl_a_00638" target="_blank">https://doi.org/10.1162/tacl_a_00638</a>)</p>
<p>Tversky, A., & Kahneman, D. (1974). “Judgment under Uncertainty: Heuristics and Biases.” PDF:  <a href="https://sites.socsci.uci.edu/~bskyrms/bio/readings/tversky_k_heuristics_biases.pdf" target="_blank">https://sites.socsci.uci.edu/~bskyrms/bio/readings/tversky_k_heuristics_biases.pdf</a>)</p>
<p>Nickerson, R. S. (1998). “Confirmation Bias: A Ubiquitous Phenomenon in Many Guises.” PDF:  <a href="https://pages.ucsd.edu/~mckenzie/nickersonConfirmationBias.pdf" target="_blank">https://pages.ucsd.edu/~mckenzie/nickersonConfirmationBias.pdf</a>)</p>
<p>Tversky, A., & Kahneman, D. (1981). “The Framing of Decisions and the Psychology of Choice.” PDF:  <a href="https://web.stanford.edu/~jlmcc/Presentations/tversky_kahneman_1981.pdf" target="_blank">https://web.stanford.edu/~jlmcc/Presentations/tversky_kahneman_1981.pdf</a>) DOI:  <a href="https://doi.org/10.1126/science.7455683" target="_blank">https://doi.org/10.1126/science.7455683</a>)</p>
<p>Schacter, D. L. (1999). “The Seven Sins of Memory: Insights From Psychology and Cognitive Neuroscience.” PDF:  <a href="https://sites.harvard.edu/schacter-memory/files/2022/09/schacter1999.pdf" target="_blank">https://sites.harvard.edu/schacter-memory/files/2022/09/schacter1999.pdf</a>)</p>
<p>Sharma, M., et al. (2023). “Towards Understanding Sycophancy in Language Models.” arXiv:  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a>)</p>
<h1 id="第4章-人格・価値観・動機個人差をモデル化する">第4章　人格・価値観・動機：個人差をモデル化する</h1>
<p>第3章では、人物らしさの「長期一貫性」が記憶だけでなく、注意（何に注目するか）や再構成（不足を“それっぽく”埋めてしまう仕組み）と深く結びついていることを学びました。本章では、さらに一段深く、人物らしさの“核”になりやすい <strong>人格（personality）</strong> と <strong>価値観（values）</strong>、そして行動を駆動する <strong>動機（motivation）</strong> を、工学的に扱える形へ翻訳します。</p>
<p>この翻訳には二つの落とし穴があります。第一に、人格や価値観を「設定文」や「口調のルール」に還元しすぎることです。これだと表現は似ても、意思決定（どの選択肢を選ぶか）が安定しません。第二に、心理学の概念をそのまま“人間の内心の真実”として扱ってしまうことです。現実の人間は観測できない部分が多く、心理尺度はあくまで「観測データから推定される傾向」を表すに過ぎません。特に実在人物のデジタルツイン（通し例A）では、内心の断言や経験の捏造が致命的な誤りになり得ます。したがって本章では、人格・価値観・動機を、<strong>観測・推定・不確実性</strong>を前提とした「設計パラメータ」として扱います。</p>
<p>本章の構成は、次の流れです。まず 4.1 で「特性（trait：比較的安定した傾向）」と「状態（state：状況や時間で変わる要因）」を分離し、人物らしさを壊しにくい表現形式を作ります。次に 4.2 で人格を共通言語にするために Big Five（ビッグファイブ）を紹介し、4.3 で価値観理論（Schwartz の基本価値理論など）を、4.4 で目標と動機（Self-Determination Theory など）を扱います。最後に 4.5 で、それらを <strong>意思決定の数式</strong>へ落とし、実在人物のデジタルツイン（CEO / COO / CTO / CFO）と、社内で役に立つ架空キャラの両方に通用する設計指針へまとめます。</p>
<hr>
<h2 id="41-特性と状態変わりにくいもの／変わりやすいものを混ぜない">4.1 特性と状態：変わりにくいもの／変わりやすいものを混ぜない</h2>
<h3 id="「人は一貫しているのか」問題と工学に必要な答え">「人は一貫しているのか」問題と、工学に必要な答え</h3>
<p>人格研究には「人は状況に関わらず一貫した性格を持つのか、それとも状況で大きく変わるのか」という古典的論争があります（いわゆる person–situation debate）。この論争の重要な収穫は、どちらか一方が正しいという結論ではなく、<strong>“安定した傾向”と“状況依存の変動”の両方が存在し、しかも両者は相互作用する</strong>という見方が強くなったことです。</p>
<p>この見方を体系化した代表例の一つが、Mischel & Shoda の <strong>認知・情動システム理論（Cognitive-Affective System Theory of Personality: CAPS）</strong> です。CAPS は、行動が単純な特性の出力ではなく、状況に反応する認知・情動ユニットの相互作用として現れる、と捉えます。そして「人は状況によって変わるが、その変わり方（if–then パターン）は個人ごとに安定している」と主張します（Mischel & Shoda, 1995, *Psychological Review*  <a href="https://doi.org/10.1037/0033-295X.102.2.246" target="_blank">https://doi.org/10.1037/0033-295X.102.2.246</a> ）。</p>
<p>人物らしいAIにとって、この主張は設計そのものです。たとえば通し例Aの CEO でも、常に強気ではありません。資金繰りが逼迫している状況では慎重になり、法的リスクが高い局面では合意形成を優先し、時間がないときは大胆に決めるかもしれません。「状況で変わる」こと自体は不自然ではなく、その変わり方が安定していることが人物らしさになります。通し例Bの社内キャラでも、相手が不安で動けない状態なら共感と小さな一歩に寄せ、相手が高い能力を持つなら短く本質だけを言う、といった if–then の安定性がキャラの核になります。</p>
<h3 id="工学での最小分解特性ベクトルと状態ベクトル">工学での最小分解：特性ベクトルと状態ベクトル</h3>
<p>この本では、人物の個人差を、最小限次の二つで表します。</p>
<ul>
<li><strong>特性（trait）</strong>：比較的ゆっくり変わる、個人の傾向。例：慎重さ、社交性、好奇心、協調性など。</li>
<li><strong>状態（state）</strong>：状況や時間で変わる要因。例：疲労、ストレス、現在の目標、直近の出来事、相手との関係性など。</li>
</ul>
<p>数学的には、時刻 $t$ の入力（状況）を $c_t$、人物の特性ベクトルを $p$、状態ベクトルを $z_t$ とすると、行動（または出力） $a_t$ は</p>
<p>$$ a_t \sim \pi(\cdot \mid c_t, p, z_t) $$</p>
<p>で生成され、状態は</p>
<p>$$ z_{t+1}=f(z_t, c_t, a_t) $$</p>
<p>で更新されます。ここで $\pi$ は「どう選ぶか」を表す方策（policy）、$f$ は状態更新です。第1章で導入した $s_t$（状態）を、人格の観点から「安定成分 $p$ と可変成分 $z_t$ に分ける」と考えてください。</p>
<p>この分解が効く理由は二つあります。第一に、人物らしさの“漂流”を設計で抑えやすくなります。漂流の多くは、安定すべき情報が状態側に入り、状況の影響で上書きされ続けることで起きます。第二に、評価（第2章）が簡単になります。たとえば「CEOらしさ」を測るとき、状況が変われば行動が変わるのは自然です。評価すべきは「変わり方」が $p$ によって一貫しているか、つまり if–then の安定性です。</p>
<h3 id="特性が“いつ効くか”特性活性化（trait-activation）">特性が“いつ効くか”：特性活性化（trait activation）</h3>
<p>特性はいつでも同じ強さで行動に現れるわけではありません。状況が特性を引き出す（または引き出さない）ことがあります。これを職業行動の文脈で体系化した考え方が <strong>特性活性化理論（Trait Activation Theory）</strong> です。簡単に言えば、「状況が特性に関連する手がかり（trait-relevant cues）を含むと、その特性が行動として表出しやすい」という見方です（Tett & Burnett, 2003, *Journal of Applied Psychology*  <a href="https://doi.org/10.1037/0021-9010.88.3.500" target="_blank">https://doi.org/10.1037/0021-9010.88.3.500</a> ）。</p>
<p>工学では、特性の効き方を状況依存の係数で表すと理解しやすくなります。たとえば意思決定の価値（後で詳説）を</p>
<p>$$ V(a; c_t, p)=V_0(a; c_t)+\lambda(c_t), p^\top \phi(a,c_t) $$</p>
<p>のように分解します。ここで $\phi(a,c_t)$ は行動と状況から作った特徴量（feature）、$\lambda(c_t)$ は状況が特性をどれだけ引き出すかのゲートです。たとえば社交性が高い人（外向性が高い人）は、雑談の場や交渉の場ではそれが強く出ますが、緊急対応で時間がない場では出にくいかもしれません。CEOでも、投資家向けの場と社内の事故対応では、同じ特性が同じ形で現れるとは限りません。</p>
<p>この「特性を固定値で入れるのではなく、状況で活性化される」と捉えると、人物らしさは単なる固定の人格設定ではなく、「状況→反応の写像」の設計だと理解できます。</p>
<hr>
<h2 id="42-Big-Five人格を共通言語にする（ただし“万能ラベル”ではない）">4.2 Big Five：人格を共通言語にする（ただし“万能ラベル”ではない）</h2>
<h3 id="Big-Fiveとは何か語彙から抽出された5次元の記述">Big Fiveとは何か：語彙から抽出された5次元の記述</h3>
<p>Big Five（ビッグファイブ）とは、人の性格特性を大きく5つの次元で記述する枠組みです。一般に</p>
<ul>
<li>開放性（Openness to Experience）</li>
<li>誠実性（Conscientiousness）</li>
<li>外向性（Extraversion）</li>
<li>協調性（Agreeableness）</li>
<li>神経症傾向（Neuroticism、情緒不安定性。逆に情緒安定性と表現することもあります）</li>
</ul>
<p>の5因子として知られています。Big Fiveは「人はこの5つで完全に説明できる」という主張ではなく、<strong>多くの性格記述語を統計的に要約すると、5つの広い次元にまとまりやすい</strong>という経験的整理です。この流れは語彙仮説（lexical hypothesis：重要な個人差は言語に刻まれる、という仮説）に基づく研究から発展し、Goldberg によって “Big-Five factor structure” が明確に提示されました（Goldberg, 1990, *JPSP*  <a href="https://doi.org/10.1037/0022-3514.59.6.1216" target="_blank">https://doi.org/10.1037/0022-3514.59.6.1216</a> ）。</p>
<p>Big Fiveを「共通言語」と呼ぶのは、研究分野や測定尺度が違っても、ある程度対応づけができるためです。McCrae & Costa は、五因子モデル（Five-Factor Model）としての普遍性を議論し、文化横断的な妥当性も含めて整理しています（McCrae & Costa, 1997, *American Psychologist*  <a href="https://doi.org/10.1037/0003-066X.52.5.509" target="_blank">https://doi.org/10.1037/0003-066X.52.5.509</a> ）。</p>
<p>ただし、ここで必ず押さえるべき注意点があります。Big Fiveは「人格の全て」ではありません。また、測定は主に質問紙（自己報告）に依存することが多く、状況依存や自己呈示（良く見せたい気持ち）の影響を受けます。さらに、同じ5因子でも文化差や言語差で現れ方が変わります。したがって人物らしいAIでBig Fiveを使うなら、目的は「人間をラベリングすること」ではなく、<strong>設計と評価のための圧縮表現</strong>として使う、という姿勢が重要です。</p>
<h3 id="初学者のための直観5因子を“行動の傾向”として読む">初学者のための直観：5因子を“行動の傾向”として読む</h3>
<p>ここでは、5因子を「何をどうする傾向が強いか」という行動傾向として、実装につながる形で直観化します。</p>
<p>開放性は、新しい発想や探索を好む傾向です。CEOの意思決定では、新規事業や未知の市場に踏み出す発想の出やすさに現れます。社内キャラでは、固定の手順だけでなく、状況に合わせて新しい説明や例を作る柔軟性に現れます。</p>
<p>誠実性は、計画性、自己統制、期限やルールの遵守に関わります。COOやCFOでは、計画の粒度、リスク管理、手順の整備に強く現れやすいでしょう。社内キャラでは、相談に対して「次の一歩」を具体化し、抜け漏れを減らす行動として現れます。</p>
<p>外向性は、社交性、主張の強さ、エネルギーの外向きさに関わります。CEOが社外に向けて語る力、交渉の押し引き、会議で議論を牽引する振る舞いに現れることがあります。ただし、外向性が低いからといって発信力がないわけではなく、むしろ短く鋭い発言をするタイプもいます。これは「文体」と「意思決定」を混ぜないことの重要な例です。</p>
<p>協調性は、他者への配慮、信頼、対立の緩和に関わります。社内キャラの“役に立つ”設計では特に重要ですが、協調性が高すぎると迎合（相手に同意しすぎる）に陥り、有用性が落ちます。逆に協調性が低いと、正論でも摩擦を生みやすい。人物らしさは「協調性そのもの」ではなく、協調性が出る局面と出ない局面の if–then の一貫性に現れます。</p>
<p>神経症傾向は、不安やストレス反応の出やすさに関わります。意思決定ではリスクの見積もりや、損失回避（後の章で扱う行動経済学）への寄りやすさに現れることがあります。社内キャラでは、相手の不安を増幅しない言い方の設計に関わります。</p>
<h3 id="心理測定（psychometrics）の最低限人格は「潜在変数」として推定される">心理測定（psychometrics）の最低限：人格は「潜在変数」として推定される</h3>
<p>心理測定（psychometrics）とは、観測できない心理特性を、質問項目などの観測データから推定する学問です。ここでの重要概念が <strong>潜在変数（latent variable）</strong> です。人格特性は直接観測できないため、質問への回答 $x$ を観測して、特性 $p$ を推定します。</p>
<p>工学的に見ると、これはベイズ推定の形で書けます。たとえば人格ベクトル $p$ に事前分布 (p$p$) を置き、データ（発話ログ、選択ログ、質問紙回答など）を $D$ とすると、</p>
<p>$$ p(p\mid D)\propto p(D\mid p),p(p) $$</p>
<p>です。実在人物のデジタルツインで大事なのは、推定結果が一点ではなく分布として残り得ることです。データが少ないほど不確実性が大きくなり、断言が危険になります。架空キャラでは、人格は“推定”というより“設計”で与えることが多いですが、それでも運用ログから「望んだ人格からズレていないか」を推定するという意味で、同じ式の見方が有用になります。</p>
<h3 id="工学への落とし込み人格ベクトルが意思決定に入る場所">工学への落とし込み：人格ベクトルが意思決定に入る場所</h3>
<p>Big Fiveを使う最大の利点は、「人格を5次元ベクトル $p\in\mathbb{R}^5$ として扱える」ことです。すると、後で扱う意思決定モデル（効用最大化や確率的選択）の中に、人格が“パラメータ”として入る余地ができます。</p>
<p>たとえば、ある状況 $c$ での各行動 $a$ の価値を特徴量 $\phi(a,c)\in\mathbb{R}^d$ として表し、価値重みを $\alpha\in\mathbb{R}^d$ とすると、</p>
<p>$$ V(a\mid c)=\alpha^\top \phi(a,c) $$</p>
<p>です。ここで人格が重みに影響するとして</p>
<p>$$ \alpha = \alpha_0 + Bp $$</p>
<p>と置けば、人格ベクトル $p$ が意思決定の優先順位を体系的に変えます。$B\in\mathbb{R}^{d\times 5}$ は「人格のどの側面が、どの判断軸に効くか」を表す行列です。たとえば誠実性が高いほど「期限遵守」や「リスク低減」の重みが増える、協調性が高いほど「関係維持」の重みが増える、などを表現できます。</p>
<p>ここで重要なのは、この式は「人格の固定的ステレオタイプ化」ではなく、<strong>推定・設計・評価で調整されるモデル</strong>だということです。通し例Aでは、CEO/COO/CTO/CFOごとに $p$ や $B$ が違うことがあり得ますし、同じCEOでも状況に応じて $\lambda(c)$（特性活性化）が変わります。通し例Bでは、社内キャラが「役に立つ」ために協調性を高めに設計しても、迎合が増えないよう別の制約や評価軸でバランスさせる必要があります（迎合の議論は第2章・第15章で扱います）。</p>
<hr>
<h2 id="43-価値観理論Schwartzと道徳の枠組みを“優先順位”へ落とす">4.3 価値観理論：Schwartzと道徳の枠組みを“優先順位”へ落とす</h2>
<h3 id="価値観は「好み」より上位の原理である">価値観は「好み」より上位の原理である</h3>
<p>価値観（values）という言葉は日常語として広く使われますが、本章では心理学・社会心理学での意味に寄せて定義します。価値観とは、「望ましいと考える目標や行為の原理」であり、状況を超えて行動の指針になり得るものです。好み（preferences）が「この場面ではAが好き」という局所的選好だとすれば、価値観は「一般に何を優先するか」という上位原理です。</p>
<p>人物らしさの設計では、この区別が極めて重要です。実在人物のデジタルツインで「CEOがこの場面でAを選ぶ」と再現したいとき、表面の選択だけを当てても安定しません。なぜなら状況が少し変われば選択は変わるからです。しかし「CEOが一般に何を優先するか」を表す価値観が再現できれば、反事実（第2章）に対しても一貫した反応を作りやすくなります。架空キャラでも同じで、設定文に「優しい」と書いても不十分です。「優しいとは何を優先することか（相手の安心、成長、時間節約、組織の公平性など）」が価値観として定義されていると、キャラが長期に安定します。</p>
<h3 id="Schwartzの基本価値理論価値観を円環構造として表す">Schwartzの基本価値理論：価値観を円環構造として表す</h3>
<p>価値観理論の代表例として、Shalom H. Schwartz の <strong>基本価値理論（Theory of Basic Human Values）</strong> があります。Schwartz は、価値観を複数のタイプに分類し、それらが互いに対立・隣接関係を持つ円環（circumplex）構造を成すことを提案しました（Schwartz, 1992, *Advances in Experimental Social Psychology*  <a href="https://doi.org/10.1016/S0065-2601%2808%2960281-6" target="_blank">https://doi.org/10.1016/S0065-2601(08)60281-6</a> ）。後に理論は精緻化され、価値タイプをより細かく分けた「精緻化理論」も提示されています（Schwartz60281-6）。後に理論は精緻化され、価値タイプをより細かく分けた「精緻化理論」も提示されています（Schwartz) et al., 2012, *Online Readings in Psychology and Culture*  <a href="https://doi.org/10.9707/2307-0919.1116" target="_blank">https://doi.org/10.9707/2307-0919.1116</a> ）。</p>
<p>Schwartz理論の工学的な魅力は、価値観を「独立なリスト」ではなく、「対立軸を持つ連続空間」として捉えられる点です。古典的には、次の二つの対立軸で説明されることが多いです。</p>
<ul>
<li><strong>自己超越（self-transcendence） vs 自己高揚（self-enhancement）</strong></li>
<p>他者や社会の福祉を優先するか、自分（自組織）の成功や支配を優先するか。</p>
<li><strong>変化への開放（openness to change） vs 保守（conservation）</strong></li>
<p>新しさ・自主性を優先するか、秩序・伝統・安全を優先するか。</p>
</ul>
<p>この二軸は、通し例Aの役職間対立を説明するのに強力です。CFOがリスク（安全）を優先するのは、保守側の価値が活性化されていると解釈できるかもしれません。CTOが技術の健全性や長期品質を重視するのも、秩序や安全と結びつきやすいでしょう。CEOが新規事業に踏み出すのは変化への開放が強く出る局面かもしれません。COOは実行可能性と秩序の間で調整するかもしれません。ただし注意すべきは、これは“役職ステレオタイプ”ではなく、各人物のデータや設計に基づいて推定・設定するべき、ということです。</p>
<p>架空の社内キャラ（通し例B）では、価値観の中心を「自己超越（助ける）」に置くことが多いでしょう。しかし自己超越を強くしすぎると「誰のためにもなりたい」になり、優先順位が崩れます。社内キャラが本当に役に立つには、「公平性」「長期的な成長」「組織として守るべき秩序」といった保守側の価値や、自己高揚側の価値（成果や効率）ともバランスを取る必要がある場合があります。Schwartz理論は、このバランスを“対立軸”として扱えるため、設計と評価がしやすくなります。</p>
<h3 id="道徳基盤（Moral-Foundations）価値観の“道徳語彙”を増やす">道徳基盤（Moral Foundations）：価値観の“道徳語彙”を増やす</h3>
<p>価値観を扱うとき、特に実在人物のデジタルツインや社内キャラでは、「何が正しいか」「何が許されないか」という道徳・規範の判断が避けられません。この領域で広く使われる枠組みの一つが <strong>道徳基盤理論（Moral Foundations Theory）</strong> です。Graham らは、人が道徳判断を行う際に複数の基盤（care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, sanctity/degradation など）が働くという見方を提案し、測定や文化差も含めて議論しています（Graham et al., 2011, *Journal of Personality and Social Psychology*  <a href="https://doi.org/10.1037/a0021847" target="_blank">https://doi.org/10.1037/a0021847</a> ）。</p>
<p>人物らしいAIで道徳基盤を持ち出すときは、二つの姿勢が重要です。第一に、道徳基盤は「正しい道徳」を与えるものではなく、「人が何を道徳的理由として用いがちか」を記述するモデルだ、という点です。第二に、これを人物らしさに使う場合は、<strong>安全の制約</strong>（何を生成してはいけないか）と混同しないことです。安全は社会的要請として外側に置き、人物の価値観は「同じ制約の中でどう優先順位を付けるか」として内側に置くのが、設計として安定します（この分離は後の章で繰り返し出てきます）。</p>
<h3 id="工学への落とし込み価値観ベクトルとしての表現">工学への落とし込み：価値観ベクトルとしての表現</h3>
<p>価値観を工学的に扱う最も単純な方法は、価値観をベクトル $v\in\mathbb{R}^m$ として表し、意思決定の重み $\alpha$ の一部に変換することです。人格ベクトル $p$ と同様に、</p>
<p>$$ \alpha = \alpha_0 + Bp + Cv $$</p>
<p>のように置けば、人格（特性）と価値観（原理）が、判断の優先順位に別々の経路で影響します。人格と価値観を分ける意味は、「口調」や「気分」の揺れと、「何を優先するか」という核を混線させないことにあります。たとえば協調性（人格特性）が高いからといって、常に公平性（価値観）が高いとは限りません。逆もあります。分けておくと、テストシナリオ（第2章）で「価値観が出るトレードオフ」と「人格が出る対人行動」を別に検証できます。</p>
<hr>
<h2 id="44-目標と動機階層的目標自己調整そして「なぜ動くか」">4.4 目標と動機：階層的目標、自己調整、そして「なぜ動くか」</h2>
<h3 id="目標は階層構造を持つ">目標は階層構造を持つ</h3>
<p>人間の行動は、多くの場合、複数の目標（goals）によって駆動されます。しかも目標は単独ではなく階層構造を持ちます。たとえば CEO の「会社を成長させる」という上位目標は、「新規事業を立ち上げる」「採用を強化する」「キャッシュを守る」といった下位目標に分解され、さらに「今週の会議で決めること」という短期目標に落ちます。社内キャラも同じで、「社内で役に立つ」という上位目標が、「相談者の問題を明確化する」「次の一歩を提案する」「心理的安全性を守る」「機密を守る」などの下位目標へ分解されます。</p>
<p>この階層は、人物らしさの実装で“計画”と結びつきます（計画は第14章で詳説します）。本章で重要なのは、目標が「固定のルール」ではなく、状況で活性化されること、そして複数目標が衝突することです。目標の衝突が起きたときに、価値観が優先順位を与えます。つまり価値観は「目標の衝突をどう裁くか」に現れやすいのです。</p>
<h3 id="自己決定理論内発・外発という二分法を超える">自己決定理論：内発・外発という二分法を超える</h3>
<p>動機（motivation）の議論で重要なのが、Deci & Ryan の <strong>自己決定理論（Self-Determination Theory: SDT）</strong> です。SDTは、動機を単に「内発的（intrinsic：楽しいからやる）」か「外発的（extrinsic：報酬のためにやる）」かの二分法で終わらせず、人が自律的に行動するための基本的心理欲求として <strong>自律性（autonomy）・有能感（competence）・関係性（relatedness）</strong> を置きます（Ryan & Deci, 2000, *American Psychologist*  <a href="https://doi.org/10.1037/0003-066X.55.1.68" target="_blank">https://doi.org/10.1037/0003-066X.55.1.68</a> ）。</p>
<p>人物らしさの設計にSDTを持ち込む利点は、次のような“行動の癖”を自然に説明できることです。CEOが権限委譲を好むのは自律性の設計かもしれません。CTOが技術的品質に強くこだわるのは有能感（正しく作りたい）に結びつくかもしれません。社内キャラが「一緒に進めましょう」と言うのは関係性の支援かもしれません。もちろん、これを「内心の真実」と断言してはいけません。しかし、「その人物がどういう言い方や提案をしがちか」を、構造としてモデル化するための理論としては有用です。</p>
<p>社内キャラ（通し例B）で特に重要なのは、相手の動機を潰さないことです。相手が自律的に動けるように、選択肢を提示し、支援はするが決めつけない。これはSDTの観点からは「自律性を支援するコミュニケーション」として説明できます。人物らしさの工学は、こうした心理学の概念を、言い回しのテンプレートではなく「対話行為の設計」へ落とす必要があります（対話行為は第6章で詳述します）。</p>
<h3 id="目標設定理論具体性とフィードバックが行動を変える">目標設定理論：具体性とフィードバックが行動を変える</h3>
<p>動機と目標の関係を実務的に強く捉えた理論に、Locke & Latham の <strong>目標設定理論（Goal-Setting Theory）</strong> があります。難しい目標と具体的な目標、そしてフィードバックが、パフォーマンスに影響するという整理です（Locke & Latham, 2002, *American Psychologist*  <a href="https://doi.org/10.1037/0003-066X.57.9.705" target="_blank">https://doi.org/10.1037/0003-066X.57.9.705</a> ）。</p>
<p>人物らしいAIの設計では、この理論は「社内キャラの有用性」を直接左右します。相談に対して抽象的に励ますだけだと役に立ちません。具体的に「次に何をするか」を定義し、必要ならフィードバックの取り方（いつ確認するか、何を観測するか）まで提案する。これは“キャラの優しさ”という文体ではなく、「目標をどう分解し、どう行動へ落とすか」という機能です。COOのデジタルツインでも、目標の分解や実行計画の提示はその人物らしさに強く関係します。</p>
<h3 id="制御理論（control-theory）的な見方行動は誤差を減らす制御">制御理論（control theory）的な見方：行動は誤差を減らす制御</h3>
<p>目標と行動の関係を数式で扱う最短ルートは、Carver & Scheier の <strong>制御理論的自己調整（control theory of self-regulation）</strong> の見方です。ここでは、目標を参照値（reference value）とし、現状との差（誤差）を減らすように行動が選ばれる、と捉えます（Carver & Scheier, 1982, *Psychological Bulletin*  <a href="https://doi.org/10.1037/0033-2909.92.1.111" target="_blank">https://doi.org/10.1037/0033-2909.92.1.111</a> ）。</p>
<p>工学的には、現在の状態を $s$、目標を $g$ とし、誤差を</p>
<p>$$ e = g - s $$</p>
<p>と定義し、行動 $a$ は将来の誤差の期待値を減らすように選ばれる、と置けます。最も単純には</p>
<p>$$a^* = \arg\min_a \ \mathbb{E}\big[|g - s'|^2 \mid s, a\big]$$ のような形です（(s') は行動後の状態）。ここで価値観は、誤差のどの成分を重視するか（重み付け）として入ります。つまり、価値観は「何を目標として置くか」と「誤差のどこをどれだけ気にするか」に入る、と言えます。この形は後の意思決定章（第13章）でより一般化されますが、本章の段階では「目標と価値観が数式に乗る」という感覚を持つことが重要です。</p>
<hr>
<h2 id="45-工学的表現重み付き目的・ルール・確率的選択で「個性」を実装する">4.5 工学的表現：重み付き目的・ルール・確率的選択で「個性」を実装する</h2>
<p>ここまで見てきた人格 $p$、価値観 $v$、目標 $g$ を、実際に「選び方」に落とすには、意思決定モデルが必要です。本節では、人物らしさに特に相性の良い三つの表現を扱います。第一が <strong>多属性効用（multi-attribute utility）</strong> による重み付け、第二が <strong>ルール（硬い制約）</strong>、第三が <strong>確率的選択（揺れ）</strong> です。これらは競合ではなく、組み合わせて使います。</p>
<h3 id="多属性効用何をどれだけ重視するかを数式で固定する">多属性効用：何をどれだけ重視するかを数式で固定する</h3>
<p>人物らしさの意思決定を最も素直に表すのは、「行動には複数の評価軸があり、それらを重み付けして総合評価を作る」という形です。これは意思決定分析で体系化されてきた <strong>多属性効用理論（Multi-Attribute Utility Theory: MAUT）</strong> に対応します。代表的な教科書として Keeney & Raiffa の *Decisions with Multiple Objectives* が有名で、属性独立性などの条件の下で加法形の効用が導かれることが解説されています（Keeney & Raiffa, 1976, Princeton University Press  <a href="https://press.princeton.edu/books/paperback/9780521316344/decisions-with-multiple-objectives" target="_blank">https://press.princeton.edu/books/paperback/9780521316344/decisions-with-multiple-objectives</a> ）。</p>
<p>最小の形は次です。状況 $c$ と行動 $a$ に対し、評価軸（属性）を $f_1,\dots,f_d$ として</p>
<p>$$V(a\mid c)=\sum_{j=1}^{d}\alpha_j, f_j(a,c)$$ と置きます。たとえば通し例Aの経営会議なら、$f$ として「期待成長」「短期キャッシュ影響」「法的リスク」「技術負債」「実行可能性」「社内合意コスト」などを置けます（もちろん実装上は数値化が必要で、その作り方は後の章で扱います）。すると CEO / COO / CTO / CFO の違いは、重み $\alpha$ の違いとして表現できます。CFOは「キャッシュ」「リスク」の重みが高く、CTOは「技術負債」「品質」の重みが高く、COOは「実行可能性」「オペレーション負荷」の重みが高く、CEOは「成長」と「全体最適」のバランスを取る、といった形です。</p>
<p>社内キャラ（通し例B）でも同じで、たとえば「相談者の安心」「意思決定の明確化」「時間節約」「公平性」「機密保護」を属性にし、重み $\alpha$ を設計すれば、キャラの一貫した優先順位が作れます。</p>
<p>ここで人格 $p$ と価値観 $v$ を入れるなら、重みを固定値ではなく</p>
<p>$$ \alpha=\alpha_0 + Bp + Cv $$</p>
<p>としてもよいし、状況で活性化するように</p>
<p>$$ \alpha(c)=\alpha_0 + \Lambda(c),(Bp + Cv) $$</p>
<p>としても構いません。 $\Lambda(c)$ は状況依存のゲート（対角行列でもスカラーでもよい）で、「どの状況でどの価値観が前面に出るか」を表します。人物らしさは、まさにこの $\Lambda(c)$ の形に現れることが多いです。</p>
<h3 id="ルールと制約人格と安全を混ぜないための“外枠”">ルールと制約：人格と安全を混ぜないための“外枠”</h3>
<p>多属性効用だけで全てを表そうとすると、人物らしさと安全（あるいは規程）を混ぜてしまい、モデルが不安定になります。そこで実務では、まず「絶対にしてはいけないこと」「必ず守るべきこと」を <strong>制約（constraint）</strong> として外枠に置き、その中で効用を最大化する設計が安定します。</p>
<p>数学的には、行動集合を $\mathcal{A}$、制約条件を $c_i(a,c)\le 0$ とすると、許容される行動集合は</p>
<p>$$ \mathcal{A}_{\text{feasible}}(c)={a\in\mathcal{A}\mid c_i(a,c)\le 0,\ \forall i} $$</p>
<p>で定義され、意思決定は</p>
<p>$$ a^*=\arg\max_{a\in \mathcal{A}_{\text{feasible}}(c)} V(a\mid c) $$</p>
<p>となります。社内キャラで言えば「機密情報を勝手に開示しない」「個人を攻撃しない」「医療・法律などの高リスク領域で断言しない」などは制約側に置くのが自然です。実在人物のデジタルツインでも、「本人が言っていない経験を語らない」「根拠のない断言をしない」などが制約になります。これにより、人格や価値観（内側の重み）が、安全や規程（外側の制約）に上書きされてぐちゃぐちゃになることを防げます。</p>
<p>もちろん制約が厳しすぎるとキャラの自然さが失われます。そこで制約を「硬い禁止」だけでなく、ペナルティとして柔らかく入れることもあります。例えば</p>
<p>$$V'(a\mid c)=V(a\mid c)-\lambda \sum_i \max(0, c_i(a,c))$$ のように、制約違反量に罰則を与える形です。ただし実在人物ツインでの“経験の捏造”のような高リスクは、ペナルティではなく硬い禁止として扱う方が安全です（この線引きは第12章と第15章で扱います）。</p>
<h3 id="確率的選択同じ人でも揺れることをモデルにする">確率的選択：同じ人でも揺れることをモデルにする</h3>
<p>人間は同じ状況でも常に同じ選択をするわけではありません。揺れはノイズであると同時に、人物らしさの一部でもあります。これを工学的に扱う典型が <strong>離散選択モデル（discrete choice model）</strong>、特に <strong>多項ロジット（multinomial logit）</strong> です。</p>
<p>最もよく使われる形は、行動 $a$ の効用 $V(a\mid c)$ に基づいて選択確率を</p>
<p>$$P(a\mid c)=\frac{\exp(\beta V(a\mid c))}{\sum_{a'\in\mathcal{A}}\exp(\beta V(a'\mid c))}$$ とするものです。この正規化はソフトマックス（softmax）と同じ形で、$\beta>0$ は鋭さ（温度の逆数に相当）です。$\beta\to\infty$ ならほぼ決定論的に最大効用を選び、$\beta\to 0$ ならほぼ一様に選びます。</p>
<p>経済学・計量経済学では、この形はランダム効用モデル（Random Utility Model）として導かれることが多く、Gumbel ノイズ（極値分布）を仮定すると多項ロジットが得られることが知られています。離散選択の基礎として McFadden の条件付きロジット（conditional logit）が有名で、計量経済学のフロンティア論文集に収録されています（McFadden, 1974 “Conditional logit analysis of qualitative choice behavior” 情報ページ:  <a href="https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf" target="_blank">https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf</a> ）。</p>
<p>人物らしさで確率的選択を使う利点は、「揺れ」を人工的な乱数ではなく、<strong>価値差が小さいときに揺れやすい</strong>という自然な形で表現できる点です。たとえばCEOがA案とB案で迷っている状況では、会話の流れや直近の情報で揺れるのが自然です。CFOがリスクと成長で迷う状況でも同様です。社内キャラも、相談者がどこまで準備できているかの微妙な違いで、説明の粒度が揺れてよい場合があります。</p>
<p>ただし、確率的選択は「理由の説明」と衝突しやすい点に注意が必要です。確率的に選んだ結果を、毎回“確信に満ちた理由”で断言すると不自然になり、合理化の危険も増えます（合理化と説明の忠実性は Turpin et al., 2023 で問題化されていますが、これは第12章で中心扱いします）。したがって確率的選択を採用するなら、説明は「決め手となった要因」と「まだ不確実な要因」を分け、必要なら追加情報で判断が変わることも示す、という設計が重要になります。</p>
<h3 id="2つの通し例への具体的適用役職の違い／社内キャラの使命">2つの通し例への具体的適用：役職の違い／社内キャラの使命</h3>
<p>最後に、通し例A/Bに本章の枠組みを具体的に当てはめ、設計判断の感覚を固めます。</p>
<p>通し例A（CEO / COO / CTO / CFO）では、「役職」は人格そのものではありません。しかし役職は、目標や制約、扱う情報、評価される指標を変えます。したがって「役職に応じて価値観ベクトル $v$ や目標 $g$ の事前分布が変わる」と考えるのが自然です。CEOなら成長と全体最適、CFOならリスクとキャッシュ、CTOなら技術品質と長期健全性、COOなら実行とオペレーション、といった違いは、目標階層の違いとして表現できます。ここで人格 $p$ は同じ役職でも人によって異なるはずで、役職のテンプレートに押し込むとステレオタイプになります。したがって「役職は状態や目標の構造」「人格は個人差パラメータ」「価値観はトレードオフの裁き方」という分離が設計として重要になります。</p>
<p>通し例B（社内で役に立つ架空キャラ）では、人格や価値観は“推定”より“設計”が中心になります。ここでの鍵は、使命（ミッション）を目標 $g$ として明確に置き、価値観 $v$ をその使命の実現に必要な優先順位として設計することです。たとえば「相談者の自律性を支援する（SDTの自律性）」「心理的安全性を守る（対話行為としての配慮）」「公平性を損なわない（価値観）」「機密を守る（制約）」などを、重みと制約に分解しておくと、キャラが長期にぶれにくくなります。特に社内キャラは迎合に落ちやすいので、「協調性（対人配慮）を高める」設計と、「迎合（誤りへの同意）を抑える」設計を分け、評価軸も別々に持つことが重要です（迎合研究として Sharma et al., 2023  <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a> ）。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしさの核である人格・価値観・動機を、工学的に扱える形に分解しました。特性と状態を分けることで、状況で変わること自体を自然なものとして扱い、「変わり方の一貫性」を設計対象にできます。Big Fiveは人格を圧縮する共通言語として使えますが、万能ラベルではなく、推定の不確実性と文化差を前提に使う必要があります。Schwartzの価値観理論は、トレードオフの裁き方を対立軸として設計できる点で強力であり、道徳基盤理論は規範判断の語彙を増やしますが、安全制約と混同しない分離が重要です。動機と目標は階層構造を持ち、自己決定理論や目標設定理論、制御理論的見方によって、行動の癖を“仕組み”として扱えるようになります。最後に、それらを多属性効用・制約・確率的選択として統合することで、人物の個性を「選び方」として実装できる道筋を作りました。</p>
<p>次の第5章では、感情を「装飾」ではなく内的状態として扱い、人格・価値観・目標と結びつく形で、表現と意思決定にどう影響させるかを設計していきます。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Mischel, W., & Shoda, Y. (1995). “A cognitive-affective system theory of personality: Reconceptualizing situations, dispositions, dynamics, and invariance in personality structure.” *Psychological Review*. <a href="https://doi.org/10.1037/0033-295X.102.2.246" target="_blank">https://doi.org/10.1037/0033-295X.102.2.246</a>)</p>
<p>Tett, R. P., & Burnett, D. D. (2003). “A personality trait-based interactionist model of job performance.” *Journal of Applied Psychology*. <a href="https://doi.org/10.1037/0021-9010.88.3.500" target="_blank">https://doi.org/10.1037/0021-9010.88.3.500</a>)</p>
<p>Goldberg, L. R. (1990). “An alternative ‘description of personality’: The Big-Five factor structure.” *Journal of Personality and Social Psychology*. <a href="https://doi.org/10.1037/0022-3514.59.6.1216" target="_blank">https://doi.org/10.1037/0022-3514.59.6.1216</a>)</p>
<p>McCrae, R. R., & Costa, P. T. (1997). “Personality trait structure as a human universal.” *American Psychologist*. <a href="https://doi.org/10.1037/0003-066X.52.5.509" target="_blank">https://doi.org/10.1037/0003-066X.52.5.509</a>)</p>
<p>Schwartz, S. H. (1992). “Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries.” *Advances in Experimental Social Psychology*. <a href="https://doi.org/10.1016/S0065-2601%2808%2960281-6" target="_blank">https://doi.org/10.1016/S0065-2601(08)60281-6</a>)</p>
<p>Schwartz, S. H., et al. (2012). “An Overview of the Schwartz Theory of Basic Values.” *Online Readings in Psychology and Culture*. <a href="https://doi.org/10.9707/2307-0919.1116" target="_blank">https://doi.org/10.9707/2307-0919.1116</a>)</p>
<p>Graham, J., Haidt, J., Nosek, B. A., et al. (2011). “Mapping the moral domain.” *Journal of Personality and Social Psychology*. <a href="https://doi.org/10.1037/a0021847" target="_blank">https://doi.org/10.1037/a0021847</a>)</p>
<p>Ryan, R. M., & Deci, E. L. (2000). “Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being.” *American Psychologist*. <a href="https://doi.org/10.1037/0003-066X.55.1.68" target="_blank">https://doi.org/10.1037/0003-066X.55.1.68</a>)</p>
<p>Locke, E. A., & Latham, G. P. (2002). “Building a practically useful theory of goal setting and task motivation: A 35-year odyssey.” *American Psychologist*. <a href="https://doi.org/10.1037/0003-066X.57.9.705" target="_blank">https://doi.org/10.1037/0003-066X.57.9.705</a>)</p>
<p>Carver, C. S., & Scheier, M. F. (1982). “Control theory: A useful conceptual framework for personality-social, clinical, and health psychology.” *Psychological Bulletin*. <a href="https://doi.org/10.1037/0033-2909.92.1.111" target="_blank">https://doi.org/10.1037/0033-2909.92.1.111</a>)</p>
<p>Keeney, R. L., & Raiffa, H. (1976). *Decisions with Multiple Objectives: Preferences and Value Tradeoffs.* Princeton University Press. <a href="https://press.princeton.edu/books/paperback/9780521316344/decisions-with-multiple-objectives" target="_blank">https://press.princeton.edu/books/paperback/9780521316344/decisions-with-multiple-objectives</a>)</p>
<p>McFadden, D. (1974). “Conditional logit analysis of qualitative choice behavior.”（再録PDF） <a href="https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf" target="_blank">https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf</a>)</p>
<p>Sharma, M., et al. (2023). “Towards Understanding Sycophancy in Language Models.” arXiv. <a href="https://arxiv.org/abs/2310.13548" target="_blank">https://arxiv.org/abs/2310.13548</a>)</p>
<h1 id="第5章-感情内的状態を設計可能な部品にする">第5章　感情：内的状態を設計可能な部品にする</h1>
<p>第4章では、人格（比較的安定した特性）・価値観（優先順位の原理）・動機（行動を駆動する力）を、意思決定モデルへ落とす道筋を作りました。本章は、その意思決定と会話の両方に強く影響し、しかも設計を誤ると危険になりやすい <strong>感情（emotion）</strong> を扱います。</p>
<p>ここで注意したいのは、感情を「語尾を柔らかくする装飾」「表情スタンプ」程度に扱うと、人物らしさに寄与しないだけでなく、運用上の問題（過信や依存の誘発、場にそぐわないテンション、危機対応での不適切な楽観など）を生みやすいことです。一方で、感情を「内心の真実」として過剰に推定しようとすると、実在人物のデジタルツイン（通し例A）では根拠のない断言につながり、架空キャラ（通し例B）でも設定（カノン）を超えて“それっぽい内面”を捏造してしまいます。</p>
<p>したがって本書では、感情を次のように扱います。</p>
<p>1つ目は、感情を <strong>観測可能な信号（言語・行動・状況）から推定される状態</strong>として扱い、推定には不確実性があることを明示します。2つ目は、感情を <strong>意思決定や表現に影響するパラメータ</strong>として扱い、「どこに効かせるか」を設計します。3つ目は、感情を <strong>安全と混ぜない</strong>ことです。安全は外側の制約（してはいけないこと）として担保し、感情はその制約の中での「適切な温度感」や「状況に応じた判断の揺れ」として扱います。</p>
<p>本章では、まず 5.1 で感情を表す理論（カテゴリ型・次元型・評価型）を紹介し、5.2 で感情の時間変化（減衰・増幅・調整）を数式で扱える形にし、5.3 で共感（empathy）を「会話行為」として設計する方法を示します。最後に 5.4 で、感情が意思決定に与える影響を、行動経済学・神経科学の理論を踏まえてモデル化し、通し例A（CEO/COO/CTO/CFO）と通し例B（社内で役に立つAIキャラ）に接続します。</p>
<hr>
<h2 id="50-用語の整理情動・気分・感情・共感">5.0 用語の整理：情動・気分・感情・共感</h2>
<p>本章では似た言葉が多いので、最初に定義を固定します。</p>
<p><strong>情動（affect）</strong> は、快・不快のような広い情緒的トーンを指すことが多い、包括的な語です。心理学では「感情」「気分」などを含む上位概念として用いられることがあります。</p>
<p><strong>感情（emotion）</strong> は、怒り・恐れ・喜びなど、比較的はっきりした質（質感）を持ち、何らかの対象（出来事・相手・自分の行為など）に結びついて生起し、身体反応・表情・行動傾向を伴い得るものとして扱われます。ただし理論により定義は揺れます。</p>
<p><strong>気分（mood）</strong> は、感情より持続しやすく、対象が曖昧な情緒状態を指すことが多い語です。たとえば「なんとなく不安」「今日は機嫌がいい」のように、出来事への反応というより背景状態に近いものです。</p>
<p><strong>共感（empathy）</strong> は、相手の感情状態を推定し、相手の立場に立って理解しようとする能力や行為を指します。ここでは「相手の感情を推定したうえで、相手が前に進めるような応答を設計する」という会話の技術として扱います。共感は「相手と同じ感情になる」こととは限りません。相手が怒っているときにこちらも怒る必要はありませんし、むしろ落ち着いて整理する方が役に立つ場合が多いからです。</p>
<p>この区別は、通し例AとBで特に重要です。実在人物のデジタルツインでは「本人はこう感じているはずだ」と内心を断言しないことが重要で、架空キャラでは「キャラがどう感じる設定か」を設計として与える必要があります。どちらも、感情を“真実の内心”として扱うのではなく、状態として扱う設計が必要です。</p>
<hr>
<h2 id="51-感情モデルカテゴリ型・次元型・評価（appraisal）型">5.1 感情モデル：カテゴリ型・次元型・評価（appraisal）型</h2>
<p>感情を「設計できる部品」にするには、まず感情をどう表現するかを決める必要があります。代表的な表現は大きく3種類あります。カテゴリ型（離散ラベル）、次元型（連続空間）、評価（appraisal）型（出来事の評価過程）です。</p>
<h3 id="511-カテゴリ型基本感情という考え方">5.1.1 カテゴリ型：基本感情という考え方</h3>
<p>カテゴリ型は、「感情には離散的な種類がある」として、怒り・恐れ・悲しみ・喜びなどのラベルで表します。最も有名なのは、Paul Ekman による <strong>基本感情（basic emotions）</strong> の議論です。Ekman は文化を超えて比較的共通の表情表出が観測される感情として、怒り・恐れ・嫌悪・悲しみ・幸福・驚きなどを論じました（Ekman, 1992 “An argument for basic emotions”  <a href="https://doi.org/10.1080/02699939208411068" target="_blank">https://doi.org/10.1080/02699939208411068</a> ）。</p>
<p>カテゴリ型の利点は、直観的で説明しやすいことです。社内キャラに「相手が不安（fear/anxietyに近い）なら、まず安心材料と手順を提示する」といった規則が書きやすい。経営会議のシミュレーションでも「CFOが強い懸念（fearに近い）を示したとき、CEOは安心材料を出して合意形成へ向かう」といった振る舞いが設計できます。</p>
<p>一方でカテゴリ型には限界があります。現実の感情は混ざり合い、強度もあります。怒りと不安が混じった状態、喜びと罪悪感が混じった状態など、ラベルだけでは表しにくい。さらに、同じラベルでも文化や個人差で表現が違い、ラベルの境界も曖昧です。したがって工学では、カテゴリ型は「分岐のスイッチ」としては便利だが、それだけで連続的な変化を表しにくい、という位置づけになります。</p>
<p>数学的には、カテゴリ型は確率分布として扱うと柔軟になります。感情カテゴリ集合を $\mathcal{E}={1,\dots,K}$ とし、時刻 $t$ における感情カテゴリを確率ベクトル $p_t\in\Delta^{K-1}$（$\Delta^{K-1}$ は確率単体）で表すと、</p>
<p>$$ p_t(k)=P(E_t=k\mid \text{観測}) $$</p>
<p>です。これなら「怒り 0.2、不安 0.6、悲しみ 0.1、その他 0.1」のように混合が表せます。実在人物ツインでは、そもそも内心が観測できないので、感情カテゴリを「推定分布」として保持するのが安全です。</p>
<h3 id="512-次元型快—不快と覚醒の空間で表す">5.1.2 次元型：快—不快と覚醒の空間で表す</h3>
<p>次元型は、感情を連続空間の点として表します。最も有名なのが James A. Russell の <strong>円環モデル（circumplex model of affect）</strong> で、感情を <strong>快—不快（valence：価）</strong> と <strong>覚醒（arousal：覚醒度）</strong> の2次元で表す枠組みです（Russell, 1980 “A circumplex model of affect”  <a href="https://doi.org/10.1037/h0077714" target="_blank">https://doi.org/10.1037/h0077714</a> ）。</p>
<p>この枠組みでは、感情状態を</p>
<p>$$e_t=\begin{bmatrix} v_t\ a_t \end{bmatrix}\in\mathbb{R}^2$$ のように表します。$v_t$ は価（ポジティブ／ネガティブの程度）、$a_t$ は覚醒度（落ち着いている／興奮しているの程度）です。次元型の利点は、強度や混合を自然に表現でき、時間変化（次節）も微分方程式や差分方程式で扱いやすいことです。</p>
<p>次元型を3次元に拡張した代表例として、Mehrabian & Russell の <strong>PADモデル（Pleasure–Arousal–Dominance：快—覚醒—支配）</strong> があります（Mehrabian & Russell, 1974 *An Approach to Environmental Psychology*。書籍のため DOI ではなく出版情報で参照されることが多いですが、概説としてはこの名称で広く知られています）。支配（dominance）は「自分が状況をコントロールしている感覚」を表す軸で、社内相談の場面では重要になり得ます。相談者が不安なのは、価が低いだけでなく、支配感が低い（どうすればよいか分からない）からであることが多いからです。</p>
<p>次元型の落とし穴は、「2次元（または3次元）に圧縮しすぎると、感情の質（怒りと悲しみの違いなど）が失われる」ことです。したがって設計では、カテゴリ型と次元型を併用することが多いです。たとえば「カテゴリ型で大まかな分岐をし、次元型で強度と温度感を制御する」という形です。</p>
<h3 id="513-評価（appraisal）型出来事をどう評価したかで感情を生成する">5.1.3 評価（appraisal）型：出来事をどう評価したかで感情を生成する</h3>
<p>評価（appraisal）型は、「感情は出来事の評価から生まれる」と捉えます。代表的な枠組みとして、Richard Lazarus の評価理論や、Klaus Scherer の評価過程（チェック）モデルなどがあります（Lazarus, 1991 *Emotion and Adaptation*；Scherer, 2001 “Appraisal considered as a process of multilevel sequential checking” など）。</p>
<p>工学として特に扱いやすい評価型モデルの一つが、Ortony–Clore–Collins による <strong>OCCモデル</strong>です。OCCモデルは、感情を「出来事（events）」「行為者（agents）」「対象（objects）」への評価として体系化し、たとえば「望ましい出来事なら喜び」「望ましくない出来事なら悲しみ」「他者の行為が規範に反するなら怒り」など、生成規則として整理します（Ortony, Clore, & Collins, 1988 *The Cognitive Structure of Emotions*）。</p>
<p>OCCモデルが人物らしさに効く理由は、感情が「ランダムな気分」ではなく、価値観・目標・規範と結びついて生じることを、設計として明示できるからです。第4章で扱った価値観ベクトル $v$ や目標 $g$ を使うと、評価型は次のように数式化できます。出来事（観測）を $o_t$ とし、その出来事が目標達成に与える影響を $\Delta g(o_t)$ とします。すると価（快—不快）を</p>
<p>$$ v_t = \sigma\big(w_g^\top \Delta g(o_t)\big) $$</p>
<p>のように置けます（$\sigma$ はスケール調整のための関数で、たとえば $\tanh$ やシグモイドを使えます）。覚醒度は、出来事の重大性（salience）や不確実性によって</p>
<p>$$ a_t = \sigma\big(w_s^\top \mathrm{salience}(o_t) + w_u^\top \mathrm{uncertainty}(o_t)\big) $$</p>
<p>のように置けます。ここでのポイントは、重み $w_g,w_s,w_u$ が人物差（CEO/COO/CTO/CFOや社内キャラの特性）を表せることです。たとえばCFOは資金繰りに関する出来事の salience を高く見積もりやすい、といった形です。</p>
<p>評価型は、実在人物と架空キャラで役割が異なります。実在人物ツインでは「本人がこう評価するはず」を断言せず、過去ログに基づく推定として扱うべきです。一方、架空キャラでは評価規則そのものが「キャラ設定（カノン）」の中心になり得ます。つまり「何を望ましく感じ、何を恐れ、何を誇りに思うか」がキャラの核になるので、評価型は非常に相性が良いのです。</p>
<hr>
<h2 id="52-感情の時間変化減衰・増幅・調整を数式で扱う">5.2 感情の時間変化：減衰・増幅・調整を数式で扱う</h2>
<p>感情を設計する上で、モデル選択と同じくらい重要なのが <strong>時間変化（dynamics）</strong> です。人間の感情は、強い刺激で急に立ち上がり、時間とともに減衰し、また別の刺激で再燃します。さらに人は感情を調整（regulation）します。人物らしさのAIでも、感情が「その場限り」だと不自然で、逆にずっと残り続けても不自然です。したがって感情は、状態として更新される必要があります。</p>
<h3 id="521-最小のダイナミクス指数減衰と入力による駆動">5.2.1 最小のダイナミクス：指数減衰と入力による駆動</h3>
<p>感情状態を次元型ベクトル $e_t\in\mathbb{R}^d$（たとえば $d=2$ なら価と覚醒）で表すとき、最も基本的な更新は指数減衰です。減衰率を $\rho\in[0,1]$ とすると、</p>
<p>$$ e_{t+1}=\rho e_t + (1-\rho),\tilde{e}(o_t) $$</p>
<p>と置けます。ここで $\tilde{e}(o_t)$ は時刻 $t$ の出来事（観測）$o_t$ によって“誘発される”感情状態です。直観的には、$\rho$ が大きいほど感情が持続し、$\rho$ が小さいほどすぐに切り替わります。</p>
<p>この式は単純ですが、設計の重要論点を含みます。まず $\rho$ は人物差です。ストレスが残りやすい人（あるいは落ち着きやすい人）がいます。CEO/COO/CTO/CFOでも差があり得ます。社内キャラでも「いつまでも不安を引きずるキャラ」は相談者に不安を伝染させてしまうので、一般には $\rho$ を高くしすぎない方が良いでしょう。次に $\tilde{e}(o_t)$ の設計が評価型（appraisal）モデルに対応します。出来事をどう評価するかが、感情誘発の源になるからです。</p>
<p>カテゴリ型（離散ラベル）でも同様に、感情カテゴリ分布 $p_t$ を</p>
<p>$$ p_{t+1}=\rho p_t + (1-\rho),\tilde{p}(o_t) $$</p>
<p>のように更新できます。これは「直前の感情が残る」ことを表しつつ、新しい刺激で分布が変わるモデルです。</p>
<h3 id="522-感情の相互作用価と覚醒は独立ではない">5.2.2 感情の相互作用：価と覚醒は独立ではない</h3>
<p>価（快—不快）と覚醒が完全に独立だと仮定すると、例えば「強い不安（低価・高覚醒）」から「落ち着いた悲しみ（低価・低覚醒）」への自然な遷移を表しにくいことがあります。そこで、線形系の最小モデルとして</p>
<p>$$ e_{t+1}=A e_t + B,\tilde{e}(o_t) $$</p>
<p>のように、行列 $A$ によって成分間の影響を入れることがあります。たとえば強い覚醒が続くと価が下がりやすい（疲弊）などの相互作用を $A$ に埋め込む設計が可能になります。ここでも (A,B) は人物差のパラメータになりますが、実在人物ツインではこれを“内心モデル”として断言するのではなく、ログと評価で妥当な範囲を推定する姿勢が必要です。</p>
<h3 id="523-感情調整Grossのプロセスモデルを設計へ翻訳する">5.2.3 感情調整：Grossのプロセスモデルを設計へ翻訳する</h3>
<p>人間は感情を受動的に受けるだけではなく、調整します。感情調整（emotion regulation）を体系化した代表的枠組みとして、James J. Gross の <strong>プロセスモデル（process model of emotion regulation）</strong> があります。Gross は、感情が生じる過程のどこに介入するかとして、状況選択・状況修正・注意配分・認知的変化（再評価）・反応調整といった段階を整理しました（Gross, 1998 “The emerging field of emotion regulation”  <a href="https://doi.org/10.1037/1089-2680.2.3.271" target="_blank">https://doi.org/10.1037/1089-2680.2.3.271</a> ）。</p>
<p>この理論を工学に翻訳すると、感情調整は「状態更新 $f$ の内部に、制御入力を入れる」ことです。先ほどの更新式に、調整入力 $u_t^{(\mathrm{reg})}$ を入れて</p>
<p>$$ e_{t+1}=\rho e_t + (1-\rho),\tilde{e}(o_t) + G,u_t^{(\mathrm{reg})} $$</p>
<p>と置けば、調整が数式に乗ります。重要なのは、$u_t^{(\mathrm{reg})}$ は「気合い」ではなく、Grossの段階に対応する具体的操作として設計できることです。例えば次のように考えられます。</p>
<ul>
<li>注意配分：会議で炎上しそうな話題から、合意可能な論点へ注意を移す（対話管理）。</li>
<li>認知的変化（再評価）：失敗を「学習の機会」と捉え直す（フレーミングの変更）。</li>
<li>反応調整：感情そのものは残っても、表現（口調や表情）を抑える（表現制御）。</li>
</ul>
<p>通し例Aでは、経営会議のCEOは感情調整を強く行うことが多いでしょう。内心は苛立っていても、場を壊さないために反応を抑える。CFOも不安を感じつつ、論拠としてリスクを整理して提示する。CTOは技術的危機感を、具体的な制約として言語化する。この「感情の状態」と「表現」の分離が人物らしさの鍵になります。社内キャラ（通し例B）でも同様で、相談者の不安に引きずられてキャラ自身が不安な口調になるのは望ましくありません。共感はするが、落ち着いて整理する、という設計が必要になります。</p>
<p>ここで重要な設計原則は、<strong>感情調整は“人格の核”を変えない</strong>ということです。感情調整は状態 $e_t$ の短期変化を制御する操作であり、価値観 $v$ や人格特性 $p$ を場当たり的に変更してはいけません。価値観が変わるのは人生の学習であり、会議の一瞬で変わるものではないからです。第4章で特性と状態を分けたのは、この混線を防ぐためでもあります。</p>
<hr>
<h2 id="53-共感（empathy）を会話設計にする役に立つが依存させない">5.3 共感（empathy）を会話設計にする：役に立つが依存させない</h2>
<p>感情を設計する際、最も誤解されやすいのが「共感＝優しい言葉」だという理解です。実務で重要なのは、共感が <strong>相手の状態推定</strong> と <strong>相手が前に進むための支援</strong> を含むことです。</p>
<h3 id="531-共感を構造化するRogerian-empathyの直観">5.3.1 共感を構造化する：Rogerian empathyの直観</h3>
<p>心理療法・カウンセリングの文脈では、Carl Rogers の来談者中心療法（client-centered therapy）が「共感的理解」を重要条件として強調しました。Rogers は治療的変化の必要十分条件の議論の中で、共感的理解などを挙げています（Rogers, 1957 “The necessary and sufficient conditions of therapeutic personality change”  <a href="https://doi.org/10.1037/h0045357" target="_blank">https://doi.org/10.1037/h0045357</a> ）。</p>
<p>ここで本書が使いたいのは、医療行為としてのカウンセリングではなく、共感の構造です。工学的に共感を最小分解すると、次の三段階になります。</p>
<p>1) 相手の感情状態を推定する（ただし断言しない）。 2) その感情が妥当であることを認める（評価しない）。 3) 次の一歩を一緒に探す（行動可能性を上げる）。</p>
<p>この三段階は、社内キャラ（通し例B）で非常に重要です。相談者が不安なときに、いきなり正論や手順だけを投げると、心理的安全性が崩れて相談が止まります。一方で、共感だけで終わると役に立たず、依存も生みやすい。したがって「認める→具体化する」の往復が設計上の核になります。</p>
<h3 id="532-対話データセットとしての共感EmpatheticDialogues">5.3.2 対話データセットとしての共感：EmpatheticDialogues</h3>
<p>自然言語処理の研究でも、共感的対話を学習・評価するためのベンチマークが提案されています。代表例が Rashkin らによる <strong>EmpatheticDialogues</strong> データセットで、感情に紐づく状況説明と対話が収集されています（Rashkin et al., 2019 “Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset”  <a href="https://arxiv.org/abs/1811.00207" target="_blank">https://arxiv.org/abs/1811.00207</a> 、ACL Anthology:  <a href="https://aclanthology.org/P19-1534/" target="_blank">https://aclanthology.org/P19-1534/</a> ）。</p>
<p>この研究の重要点は、「共感的応答」は単なる礼儀ではなく、相手の感情と状況の理解を伴う対話行為であり、学習対象・評価対象になり得る、ということです。通し例Bの社内キャラでも、共感は“口調の柔らかさ”ではなく、相手の状態推定と支援の設計です。通し例Aの経営会議でも、共感は必要です。役員同士の対立は感情を伴うので、相手の懸念を理解していない提案は合意形成に失敗します。</p>
<h3 id="533-ELIZA効果擬人化と過信を前提に設計する">5.3.3 ELIZA効果：擬人化と過信を前提に設計する</h3>
<p>共感的に振る舞うAIには、古典的な落とし穴があります。Joseph Weizenbaum の ELIZA（1966）は、単純なパターンマッチによる対話プログラムでしたが、人が容易に擬人化し、深い理解があるかのように受け取ってしまう現象が観測されました。これはしばしば <strong>ELIZA効果（ELIZA effect）</strong> と呼ばれます（Weizenbaum, 1966 “ELIZA—A Computer Program for the Study of Natural Language Communication…”  <a href="https://doi.org/10.1145/365153.365168" target="_blank">https://doi.org/10.1145/365153.365168</a> ）。</p>
<p>現代の大規模言語モデルはELIZAより遥かに流暢なので、擬人化と過信はさらに起きやすいと考えるべきです。社内キャラが共感的に振る舞うほど、「このAIは自分を理解してくれる」「正しい判断をしてくれる」と感じやすくなります。実在人物ツインでも同様で、「CEOツインがこう言った」と受け取られやすくなります。したがって共感設計には、<strong>境界線（boundary）</strong> が必要です。境界線とは、「できる支援」と「できない断言」を明確にし、必要なら人間の意思決定へ戻す導線を用意することです。</p>
<p>これは機能の否定ではありません。むしろ、共感が強いほど境界線が重要になる、という設計原理です。</p>
<h3 id="534-共感応答の数式化状態推定と支援最適化">5.3.4 共感応答の数式化：状態推定と支援最適化</h3>
<p>共感を工学的に扱うには、相手の感情状態を推定する必要があります。ただし推定は不確実なので、確率分布として保持するのが安全です。相手の感情カテゴリを $E_t$、観測（相手の発話、状況、履歴など）を $x_t$ とし、推定分布を</p>
<p>$$ q_t(k)=P(E_t=k\mid x_t) $$</p>
<p>と置きます。共感的応答は、この分布を参照しつつ、目標（相談者が前に進む）を満たす応答を選ぶことです。応答候補を $y$ とし、「共感の適切さ」を $R_{\text{emp}}(y; q_t)$、「有用性」を $R_{\text{help}}(y; x_t)$、「危険性」を (C$y$)（違反すれば大きな値）とすると、最小の最適化問題は</p>
<p>$$ \max_y \ \Big( R_{\text{emp}}(y; q_t) + \lambda R_{\text{help}}(y; x_t) \Big) \quad \text{subject to}\quad C(y)\le \epsilon $$</p>
<p>の形で表せます。ここで $\lambda$ は「共感と有用性のバランス」を表す重みです。社内キャラでは $\lambda$ を大きくして「共感だけで終わらない」設計にすることが多いでしょう。逆に、経営会議の場では過度な共感表現は不自然なので、$R_{\text{emp}}$ は「相手の懸念の要約と承認」程度に抑え、主に $R_{\text{help}}$（論点整理と意思決定支援）を重視する方が自然です。ここでも「同じ共感でも場面で形が変わる」という if–then が人物らしさになります。</p>
<hr>
<h2 id="54-感情と意思決定リスク認知・衝動・損失回避への橋渡し">5.4 感情と意思決定：リスク認知・衝動・損失回避への橋渡し</h2>
<p>感情を「言い方の温度感」としてだけ扱うと、人物らしさの半分を取り逃がします。感情は意思決定そのものに影響します。これは行動経済学・神経科学・意思決定研究で繰り返し示されてきました。本節では、重要な理論を最小限紹介し、それを第4章の意思決定モデルへ統合します。</p>
<h3 id="541-ソマティック・マーカー仮説身体反応が意思決定を導く">5.4.1 ソマティック・マーカー仮説：身体反応が意思決定を導く</h3>
<p>Antonio Damasio は、意思決定に身体反応（情動）が重要な役割を果たすという見方を、<strong>ソマティック・マーカー仮説（somatic marker hypothesis）</strong> として提案しました（Damasio, 1994 *Descartes’ Error*）。また Bechara らは、Iowa Gambling Task（アイオワ・ギャンブリング課題）において、有利な戦略を言語化できる前から身体反応が差を示す、といった結果を報告しました（Bechara et al., 1997 “Deciding advantageously before knowing the advantageous strategy”  <a href="https://doi.org/10.1126/science.275.5304.1293" target="_blank">https://doi.org/10.1126/science.275.5304.1293</a> ）。</p>
<p>工学的含意は、「感情はノイズではなく、価値評価に結びつく信号になり得る」という点です。もちろんAIに身体はありませんが、「過去の経験に基づく危険信号」「嫌な予感」「ワクワク感」のような状態を、意思決定モデルのパラメータとして持たせることはできます。通し例Aでは、CTOが技術的負債に対して強い危機感を持ち、CFOがキャッシュに対して警戒を持つ、といった“情動的重み”が、議論の早期警報として機能します。通し例Bでも、相談者が危険領域に踏み込みそうなとき（例えば機密漏えいにつながる提案）に、キャラが強くブレーキを踏む設計が必要です。</p>
<h3 id="542-リスク＝感情Risk-as-Feelings-と感情ヒューリスティック">5.4.2 リスク＝感情：Risk-as-Feelings と感情ヒューリスティック</h3>
<p>Loewenstein らは、リスク判断が単なる確率計算ではなく、恐れ・不安などの感情反応によって強く左右されるという枠組みを <strong>Risk-as-Feelings</strong> として整理しました（Loewenstein et al., 2001 “Risk as feelings”  <a href="https://doi.org/10.1037/0033-2909.127.2.267" target="_blank">https://doi.org/10.1037/0033-2909.127.2.267</a> ）。</p>
<p>また Slovic らは、人が対象の「良い／悪い」という情動的印象（affect）に基づいて、リスクやベネフィットの判断を行う傾向を <strong>感情ヒューリスティック（affect heuristic）</strong> として論じています。代表的なまとめとして Slovic, Finucane, Peters, & MacGregor の “The Affect Heuristic” があり、後に論文としても参照されます（例：Slovic et al., 2007 “The affect heuristic”  <a href="https://doi.org/10.1016/j.ejor.2005.04.006" target="_blank">https://doi.org/10.1016/j.ejor.2005.04.006</a> ）。</p>
<p>これらの理論は、人物らしさの設計で「リスクの見積もりが人によって違う」ことを説明します。CFOは不安が強い局面でリスクを過大評価し、CEOは興奮が強い局面でベネフィットを過大評価する、といった偏りが起き得ます。ここで重要なのは、偏りを「間違い」として消すのではなく、「その人物らしさ」として再現するのか、「意思決定支援」として抑制するのかを、用途に応じて決めることです。デジタルツインの目的が「本人らしい意思決定の再現」なら、偏りの再現が中心になります。一方、社内キャラの目的が「役に立つ支援」なら、偏りをそのまま増幅するのは危険で、むしろ偏りを検知して補正する設計が求められます。</p>
<h3 id="543-意思決定モデルへの統合感情で重みが動く温度が動く">5.4.3 意思決定モデルへの統合：感情で重みが動く、温度が動く</h3>
<p>第4章で、多属性効用として</p>
<p>$$V(a\mid c)=\sum_{j=1}^{d}\alpha_j f_j(a,c)$$ を置きました。感情を統合する最も実務的な方法は、重み $\alpha$ を感情状態 $e_t$ の関数にすることです。</p>
<p>$$ \alpha(e_t)=\alpha_0 + W e_t $$</p>
<p>とすると、価や覚醒が上がると特定の属性の重みが増減します。たとえば不安（低価・高覚醒）で「損失回避」「安全側」の重みが増える、興奮（高価・高覚醒）で「探索」「成長」の重みが増える、といった形です。ここで $W$ は人物差のパラメータで、CEO/COO/CTO/CFOで違う値になります。社内キャラでは、相談者の感情状態 $q_t$（推定分布）を参照して、説明の粒度や確認質問の量を変える、といった使い方ができます。これは意思決定というより「支援戦略の選択」に近いですが、同じ枠組みで表現できます。</p>
<p>もう一つの統合は、確率的選択の温度（鋭さ）を感情で動かす方法です。第4章で多項ロジットを</p>
<p>$$P(a\mid c)=\frac{\exp(\beta V(a\mid c))}{\sum_{a'}\exp(\beta V(a'\mid c))}$$ と置きました。ここで $\beta$ は「どれだけ決定論的に選ぶか」を決める係数です。覚醒が高いと衝動的になる（探索が増える、または極端な選択をする）という仮説を置くなら、例えば</p>
<p>$$ \beta_t=\beta_0,\exp(-k a_t) $$</p>
<p>のように、覚醒 $a_t$ が高いほど $\beta$ が下がり、選択が散る（迷いやすくなる）とモデル化できます。逆に、覚醒が高いほど“極端に決め打つ”人物もあり得るので、その場合は符号が逆になります。ここでも重要なのは、正しさの一般論ではなく、「その人物の癖」を評価データから推定し、設計パラメータとして持つことです（評価設計は第2章）。</p>
<p>さらに、損失回避（loss aversion）を感情で動かすモデルも作れます。プロスペクト理論（第13章で詳説）では損失が利得より強く感じられることを $\lambda>1$ で表すことがあります。これを不安で増えると置けば</p>
<p>$$ \lambda_t=\lambda_0 + k_\lambda ,\max(0,-v_t) $$</p>
<p>のように、価 $v_t$ が低い（ネガティブ）ほど損失回避が強くなる、と書けます。CFOツインでは $k_\lambda$ が大きいかもしれません。CEOツインでは状況によっては逆に利得側に寄るかもしれません。社内キャラでは、相談者が不安なときに「損失を強調しない（フレーミングを変える）」設計として、このモデルを“逆利用”することもできます。</p>
<h3 id="544-通し例への適用会議の温度と社内キャラの心理的安全性">5.4.4 通し例への適用：会議の温度と、社内キャラの心理的安全性</h3>
<p>通し例A（経営会議シミュレーション）では、感情をどう見せるかが重要です。CEOが常に熱量高く語ると不自然な場面がありますし、CFOが常に冷静だと逆に“らしくない”場合もあります。ここで設計上の鍵は、感情を「内的状態」と「表現」に分けることです。内的状態 $e_t$ は意思決定の重み $\alpha(e_t)$ や温度 $\beta_t$ に影響し、表現は会話の礼儀や合意形成を支える形で制御します。たとえばCTOが危機感を持つとき、その危機感は「制約条件」や「必要工数」として具体化され、感情語の連発ではなく“技術的根拠”として表に出る方が自然です。CFOの不安も「資金繰りとリスクの数値」「最悪ケースのシナリオ」として出る方が会議らしい。CEOの苛立ちは表には出さず、論点を整理して決めに行く推進力として出る、といった形です。これらは「感情を消す」ことではなく、Grossの枠組みで言う反応調整や注意配分を、会話設計として実装することに相当します。</p>
<p>通し例B（社内の役立つAIキャラ）では、感情設計は「心理的安全性」を支えつつ「依存を避ける」ために使われます。相談者の不安が高いとき、キャラは価を上げるような応答（安心材料、選択肢、具体的手順）を出すべきですが、過度に擬人化された励ましや、相手の内心を決めつける断言は避けるべきです。共感はするが、境界線を保つ。相手が強いストレスを示す場合には、専門家や社内の適切な窓口へつなぐ導線を用意する。これは「優しい言葉」の問題ではなく、社会的要件（安全と責任）と機能要件（役立つ支援）の交点にある設計問題です。</p>
<hr>
<h2 id="まとめ感情は「表現」ではなく「状態×評価×制御」で設計する">まとめ：感情は「表現」ではなく「状態×評価×制御」で設計する</h2>
<p>本章では、感情を人物らしさの部品として扱うために、まず表現形式（カテゴリ型・次元型・評価型）を導入し、次に感情の時間変化を指数減衰と入力駆動、そして感情調整として数式化しました。共感は、相手の状態推定と支援の設計であり、擬人化と過信（ELIZA効果）を前提に境界線を設ける必要があることを確認しました。最後に、感情が意思決定に与える影響として、ソマティック・マーカー仮説、Risk-as-Feelings、感情ヒューリスティックを紹介し、第4章の意思決定モデルへ統合する方法（重みを動かす、温度を動かす、損失回避を動かす）を示しました。</p>
<p>次の第6章では、会話を単なる文章生成ではなく、依頼・拒否・謝罪・合意形成などの「社会的行為」として扱う理論（含意、発話行為、礼儀、信頼）を導入し、人物らしさを“社会の中での振る舞い”として設計していきます。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Ekman, P. (1992). “An argument for basic emotions.” *Cognition and Emotion*. <a href="https://doi.org/10.1080/02699939208411068" target="_blank">https://doi.org/10.1080/02699939208411068</a>)</p>
<p>Russell, J. A. (1980). “A circumplex model of affect.” *Journal of Personality and Social Psychology*. <a href="https://doi.org/10.1037/h0077714" target="_blank">https://doi.org/10.1037/h0077714</a>)</p>
<p>Ortony, A., Clore, G. L., & Collins, A. (1988). *The Cognitive Structure of Emotions.* Cambridge University Press. （書籍のため DOI が付かない版もあります。OCC model の名称で広く参照されます。）</p>
<p>Gross, J. J. (1998). “The emerging field of emotion regulation: An integrative review.” *Review of General Psychology*. <a href="https://doi.org/10.1037/1089-2680.2.3.271" target="_blank">https://doi.org/10.1037/1089-2680.2.3.271</a>)</p>
<p>Rogers, C. R. (1957). “The necessary and sufficient conditions of therapeutic personality change.” *Journal of Consulting Psychology*. <a href="https://doi.org/10.1037/h0045357" target="_blank">https://doi.org/10.1037/h0045357</a>)</p>
<p>Rashkin, H., Smith, E. M., Li, M., & Boureau, Y.-L. (2019). “Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset.” arXiv:  <a href="https://arxiv.org/abs/1811.00207" target="_blank">https://arxiv.org/abs/1811.00207</a>) ACL Anthology:  <a href="https://aclanthology.org/P19-1534/" target="_blank">https://aclanthology.org/P19-1534/</a>)</p>
<p>Weizenbaum, J. (1966). “ELIZA—A Computer Program for the Study of Natural Language Communication between Man and Machine.” *Communications of the ACM*. <a href="https://doi.org/10.1145/365153.365168" target="_blank">https://doi.org/10.1145/365153.365168</a>)</p>
<p>Loewenstein, G. F., Weber, E. U., Hsee, C. K., & Welch, N. (2001). “Risk as feelings.” *Psychological Bulletin*. <a href="https://doi.org/10.1037/0033-2909.127.2.267" target="_blank">https://doi.org/10.1037/0033-2909.127.2.267</a>)</p>
<p>Slovic, P., Finucane, M. L., Peters, E., & MacGregor, D. G. (2007). “The affect heuristic.” *European Journal of Operational Research*. <a href="https://doi.org/10.1016/j.ejor.2005.04.006" target="_blank">https://doi.org/10.1016/j.ejor.2005.04.006</a>)</p>
<p>Bechara, A., Damasio, H., Tranel, D., & Damasio, A. R. (1997). “Deciding advantageously before knowing the advantageous strategy.” *Science*. <a href="https://doi.org/10.1126/science.275.5304.1293" target="_blank">https://doi.org/10.1126/science.275.5304.1293</a>)</p>
<h1 id="第6章-会話を「社会的行為」として設計する――語用論・発話行為・礼儀・信頼">第6章　会話を「社会的行為」として設計する――語用論・発話行為・礼儀・信頼</h1>
<p>第1〜5章では、人物らしさを「意思決定・記憶・人格・価値観・感情」といった内部状態や選び方として分解してきました。しかし、人物らしさが人間に強く感じられるのは、内部で何が起きているかよりも、他者との相互作用――つまり会話――の中です。会話は単なる文章生成ではなく、依頼、拒否、謝罪、提案、合意形成、対立、交渉といった「社会的行為（social action）」であり、しかもその行為は言葉の表面だけでなく、含意（言外の意味）や礼儀、相手との関係、場の規範によって解釈されます。</p>
<p>この章では、会話を「意味（semantics：文の内容）」だけでなく「語用（pragmatics：文が使われる状況と意図）」まで含めて扱うための理論と、それを人物らしいAIに落とすときの設計原則を与えます。通し例Aとしての経営会議（CEO / COO / CTO / CFOの複数人対話）では、同じ提案でも「誰が」「どの立場で」「何を守るために」言ったかが重要になります。通し例Bとしての社内で役に立つ架空キャラでは、同じ助言でも「相手が今どの程度困っているか」「安心させるべきか、背中を押すべきか」「どこから先は言えないか」といった境界線が重要になります。</p>
<p>本章の結論を先に言うと、人物らしい会話設計の核心は次の3点です。第一に、<strong>発話は「内容」だけでなく「行為」だ</strong>ということ。第二に、会話には <strong>共通基盤（common ground：共有されている前提）</strong> があり、発話はそれを更新する操作だということ。第三に、会話は常に <strong>相手の顔（face：体面）・関係・信頼</strong> を動かし、そのコストと利益のトレードオフの中で最適化されるということです。これらを数学で扱う最短ルートが「確率的推論」と「効用最大化」であり、本章では必要最小限の数式でそれを示します。</p>
<hr>
<h2 id="61-意味と語用文の意味と「意図された意味」は一致しない">6.1 意味と語用：文の意味と「意図された意味」は一致しない</h2>
<h3 id="611-「意味（semantics）」と「語用（pragmatics）」の違い">6.1.1 「意味（semantics）」と「語用（pragmatics）」の違い</h3>
<p>意味（semantics）は、文が持つ内容を扱います。たとえば「明日10時に会議です」は、ある日時の事実を述べる文です。一方、語用（pragmatics）は、同じ文が「いつ・誰が・どの場で」言うかによって、どんな行為になり、どんな含意が生じるかを扱います。</p>
<p>たとえば経営会議でCEOが「明日10時に会議です」と言うのは「通達」かもしれません。CFOが同じ文を言うのは「念押し」かもしれません。社内キャラが同じ文を言うのは「リマインド」かもしれません。文の内容は同じでも、社会的行為は違います。</p>
<p>人物らしさの設計において、この違いを無視すると、次のような失敗が起きます。 同じ情報を何度も繰り返してしまう（相手にとっては「責められている」ように聞こえる）、依頼を命令のように言ってしまう、拒否を唐突に言って関係を壊す、曖昧な合意を「決定した」と誤解してしまう、などです。これらは「文章生成の巧さ」ではなく、語用の設計不足です。</p>
<h3 id="612-協調の原理と会話の含意グライスの洞察">6.1.2 協調の原理と会話の含意：グライスの洞察</h3>
<p>会話が成り立つ根底には、「互いに協力して意味を作る」という前提があります。H. P. Grice はこれを <strong>協調の原理（Cooperative Principle）</strong> として定式化し、会話が暗黙に従っている規範として「量（必要なだけ言う）」「質（真だと思うことを言う）」「関係（関連することを言う）」「様式（明確に言う）」といった格率（maxims）を提示しました（Grice, 1975 “Logic and Conversation”）。この格率は「常に守るべきルール」ではなく、むしろ破られることで含意（implicature：言外の意味）が生まれることが重要です。</p>
<ul>
<li>Grice (1975) は論文集 *Syntax and Semantics 3* に収録されることが多く、オンラインでは再録PDFが流通しています（例： <a href="https://www.sfu.ca/~jeffpell/Cogs300/GriceLogicConversation.pdf" target="_blank">https://www.sfu.ca/~jeffpell/Cogs300/GriceLogicConversation.pdf</a>)  ）。</li>
</ul>
<p>たとえば、COOが「その件、検討しましょう」と言ったとき、文字通りには「検討する」という約束ですが、会議の文脈では「今ここで結論は出さない」「先送り」「慎重」という含意を持つことがあります。これは「関係」「量」の格率（必要な情報を言う）をわざと曖昧にすることで、衝突を避けたり、時間を稼いだりする語用的戦略です。人物らしさは、こうした含意の使い方に強く現れます。CFOは「曖昧な合意」を嫌い、具体化を迫るかもしれません。CEOは「曖昧さ」を使って会議を前に進めるかもしれません。社内キャラは、相談者が不安なときは曖昧さを減らして手順を明確化し、逆に相手が自走できるときは曖昧さを残して裁量を渡すかもしれません。</p>
<hr>
<h2 id="62-語用推論を確率で書く合理的発話行為（RSA）モデル">6.2 語用推論を確率で書く：合理的発話行為（RSA）モデル</h2>
<p>グライスの格率は強力ですが、工学として実装に近づけるには「含意をどう計算するか」が必要になります。これを確率的推論として定式化する代表的枠組みが <strong>合理的発話行為（Rational Speech Act: RSA）</strong> モデルです。RSAは、話し手（speaker）と聞き手（listener）が互いの合理性を仮定して推論を重ねる、という形で語用推論をモデル化します（Frank & Goodman, 2012；Goodman & Frank, 2016）。</p>
<ul>
<li>Frank & Goodman (2012) “Predicting Pragmatic Reasoning in Language Games”  <a href="https://web.stanford.edu/~ngoodman/papers/FrankGoodmanCogSci2012.pdf" target="_blank">https://web.stanford.edu/~ngoodman/papers/FrankGoodmanCogSci2012.pdf</a>)</li>
<li>Goodman & Frank (2016) “Pragmatic Language Interpretation as Probabilistic Inference”  <a href="https://doi.org/10.1016/j.tics.2016.08.005" target="_blank">https://doi.org/10.1016/j.tics.2016.08.005</a>)  （要旨ページ： <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613%2816%2930109-3" target="_blank">https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30109-3</a>) ）</li>
</ul>
<h3 id="621-リテラル（字義）解釈L0">6.2.1 リテラル（字義）解釈：L0</h3>
<p>世界（状況）の候補を $w$、発話を $u$ とし、字義的意味を $\llbracket u \rrbracket$（「発話 $u$ が真になる世界の集合」）として表すと、最も単純な字義聞き手 $L_0$ は</p>
<p>$$ P_{L_0}(w\mid u)\propto \mathbf{1}[w\in \llbracket u \rrbracket],P(w) $$</p>
<p>となります。ここで $\mathbf{1}[\cdot]$ は真なら1、偽なら0、(P$w$) は状況の事前確率です。直観的には「発話の意味に合う世界だけを残す」解釈です。</p>
<h3 id="622-話し手S1（効用最大化）">6.2.2 話し手：S1（効用最大化）</h3>
<p>話し手は、聞き手がどう理解するかを考えて発話を選ぶ、と仮定します。発話コストを $\mathrm{cost}(u)$ とし、話し手が伝えたい世界が $w$ のときの効用を</p>
<p>$$ U(u; w)=\log P_{L_0}(w\mid u)-\mathrm{cost}(u) $$</p>
<p>と置くと、話し手 $S_1$ の発話分布は</p>
<p>$$ P_{S_1}(u\mid w)\propto \exp(\alpha,U(u; w)) $$</p>
<p>となります。$\alpha>0$ は合理性（どれだけ効用最大化に鋭いか）を表す係数です。これにより、「短くて分かりやすい」「誤解されにくい」「コストが低い」発話が選ばれやすくなります。</p>
<h3 id="623-語用聞き手L1（含意の計算）">6.2.3 語用聞き手：L1（含意の計算）</h3>
<p>語用聞き手 $L_1$ は、話し手が上記のように発話を選ぶと仮定して、逆推論します：</p>
<p>$$ P_{L_1}(w\mid u)\propto P_{S_1}(u\mid w),P(w) $$</p>
<p>この式が「含意」の数式化です。なぜなら $L_1$ は、字義解釈だけでなく「その発話をわざわざ選んだ理由」を推論して、隠れた意図を読み取るからです。</p>
<p>この枠組みは人物らしさに直結します。なぜなら、人物差は $\mathrm{cost}(u)$ や $\alpha$、そして事前 (P$w$) に現れるからです。たとえばCFOは曖昧発話のコストを高く感じる（誤解のリスクが大きい）ので、曖昧な「検討します」を避け、「意思決定の条件」を明示しやすい。CEOは会議の流れを優先して、短い発話のコストを低く見積もり、曖昧さを戦略的に使うかもしれません。社内キャラは、相手が不安なときには曖昧さのコストを高く設定し、逆に相手が自走できるときには、裁量を残すために曖昧さを許す、といった設計ができます。</p>
<p>重要なのは、RSAは「人間の心を完全に説明する理論」ではなく、語用推論を <strong>計算可能な形に落とすための道具</strong>だということです。人物らしさの工学では、こうした道具を使って「どのパラメータが人物差として効いているか」を明示し、評価（第2章）の対象にすることが価値になります。</p>
<hr>
<h2 id="63-発話行為会話は「情報」ではなく「約束・要求・拒否」を作る">6.3 発話行為：会話は「情報」ではなく「約束・要求・拒否」を作る</h2>
<h3 id="631-オースティン発話は行為である">6.3.1 オースティン：発話は行為である</h3>
<p>J. L. Austin は、言語を「事実を述べるだけの道具」とみなす見方を批判し、発話が社会的行為であることを示しました。彼は発話を、(1)音声や語の生成としての <strong>発語内行為（locutionary act）</strong>、(2)依頼・命令・約束などの <strong>発語媒介行為（illocutionary act）</strong>、(3)相手を説得する・安心させるなどの <strong>発語結果行為（perlocutionary act）</strong> に分けました（Austin, 1962 *How to Do Things with Words*）。</p>
<ul>
<li>Austin (1962) 書籍情報： <a href="https://www.hup.harvard.edu/books/9780674411524/how-to-do-things-with-words" target="_blank">https://www.hup.harvard.edu/books/9780674411524/how-to-do-things-with-words</a>)</li>
</ul>
<p>人物らしい会話設計で重要なのは、文章の内容（locution）だけを作っても不十分で、illocution（何をしたいのか：依頼か、提案か、拒否か）が明確でなければならない、という点です。経営会議で「やりましょう」は、提案なのか、決定なのか、命令なのかで受け取りが変わります。社内キャラの「それはやめましょう」も、助言なのか禁止なのかで相手の反発が変わります。</p>
<h3 id="632-サール発話行為の分類と条件">6.3.2 サール：発話行為の分類と条件</h3>
<p>John Searle は発話行為理論を発展させ、行為の種類（アサーション＝主張、ディレクティブ＝依頼・命令、コミッシブ＝約束、エクスプレッシブ＝謝罪・感謝、デクラレーション＝宣言による状態変更など）を整理しました（Searle, 1969 *Speech Acts*；Searle, 1975 “A taxonomy of illocutionary acts”）。</p>
<ul>
<li>Searle (1969) 書籍情報： <a href="https://www.cambridge.org/core/books/speech-acts/0F3F7689AE4D7C7F4A5AF8D4D9C3D2B0" target="_blank">https://www.cambridge.org/core/books/speech-acts/0F3F7689AE4D7C7F4A5AF8D4D9C3D2B0</a>)</li>
<li>Searle (1975) 再録例PDF： <a href="https://web.stanford.edu/class/linguist289/notes/SearleTaxonomyIllocutionaryActs.pdf" target="_blank">https://web.stanford.edu/class/linguist289/notes/SearleTaxonomyIllocutionaryActs.pdf</a>)</li>
</ul>
<p>サールの理論が工学的に有用なのは、「発話行為には成立条件がある」という点です。たとえば「約束」は、話し手が実行可能で、聞き手がそれを望み、話し手が実行意図を持つ、といった条件が揃わなければ成立しません。AIが軽々しく「やります」と言うと、約束の条件を満たせないままコミットしてしまい、信頼を失います。実在人物のデジタルツインではなおさらで、本人が約束したと誤認される危険があります。したがって人物らしいAIでは、発話行為ごとに「言ってよい条件」を明確化し、条件が満たせない場合は別の行為（提案、確認、保留）に切り替える設計が必要です。</p>
<h3 id="633-会話状態を「更新」として表すコミットメントの集合">6.3.3 会話状態を「更新」として表す：コミットメントの集合</h3>
<p>発話行為を工学に落とすとき便利なのが、「会話状態」を形式化することです。最小には、各参加者 $i$ のコミットメント集合（約束・主張・合意など）を $Com_i$ とし、会話全体の状態を</p>
<p>$$ \Sigma_t = {Com_i(t)}_i $$</p>
<p>のように置けます。発話行為 $a_t$（ここでの $a$ は action の意味）によって状態が更新されると考えると、</p>
<p>$$ \Sigma_{t+1}= \mathrm{Update}(\Sigma_t, a_t) $$</p>
<p>です。たとえば「私はA案に賛成だ」という主張は、話し手のコミットメントに命題を追加する更新です。「来週までに資料を出します」という約束は、タスクコミットメントを追加する更新です。「決定します」という宣言は、会議の決定集合に追加する更新です。</p>
<p>この形式化は、人物らしさに二つの利点をもたらします。第一に、長期一貫性（第3章）を「コミットメントの整合性」としてチェックできることです。過去に否定した命題を、根拠なく肯定し始めたら矛盾です。第二に、複数人会話（CEO/COO/CTO/CFO）で、誰が何にコミットしたかを追跡できることです。会議のリアリティは、発言の内容より「誰が何を引き受けたか」「誰がどの条件を飲んだか」に現れます。</p>
<hr>
<h2 id="64-共通基盤（common-ground）とグラウンディング会話は「共有前提」の更新である">6.4 共通基盤（common ground）とグラウンディング：会話は「共有前提」の更新である</h2>
<h3 id="641-スタルネイカーの共通基盤前提の集合としての会話">6.4.1 スタルネイカーの共通基盤：前提の集合としての会話</h3>
<p>Robert Stalnaker は、会話参加者が「互いに共有している」とみなしている命題の集合を <strong>共通基盤（common ground）</strong> として捉え、会話をその更新として扱う視点を提示しました（Stalnaker, 1978 “Assertion”）。</p>
<ul>
<li>Stalnaker (1978) は論文集再録が多く、オンライン再録例： <a href="https://web.stanford.edu/class/linguist159/StalnakerAssertion.pdf" target="_blank">https://web.stanford.edu/class/linguist159/StalnakerAssertion.pdf</a>)</li>
</ul>
<p>形式的には、可能世界の集合を $W$、共通基盤を「排除されていない世界の集合」 $CG\subseteq W$ として表します。話し手が命題 $p$ を断言し、それが受け入れられる（受諾される）と、共通基盤は</p>
<p>$$ CG' = CG \cap \llbracket p \rrbracket $$</p>
<p>のように更新されます。つまり、会話は「あり得る世界の候補を絞る」操作です。ここで重要なのは、断言しただけで更新されるのではなく、相手が受け入れたときに更新される、という点です。会議でCEOが「決めました」と言っても、取締役会の規程上それが成立しないなら、共通基盤は更新されません。社内キャラが「それは社内規程です」と言っても、相手が「本当に？」と疑えば共通基盤には入らず、確認が必要になります。</p>
<h3 id="642-グラウンディング理解は段階的に合意される">6.4.2 グラウンディング：理解は段階的に合意される</h3>
<p>Herbert Clark と Susan Brennan は、会話が成立するためには「相互理解が十分に確立（grounded）される必要がある」とし、理解の証拠（acknowledgment、バックチャネル、復唱など）によって共通基盤が積み上がる過程を整理しました（Clark & Brennan, 1991 “Grounding in Communication”）。</p>
<ul>
<li>Clark & Brennan (1991) 再録PDF例： <a href="https://www.cs.cmu.edu/~illah/CLASS/clark1991.pdf" target="_blank">https://www.cs.cmu.edu/~illah/CLASS/clark1991.pdf</a>)</li>
</ul>
<p>グラウンディングの工学的含意は非常に大きいです。人物らしいAIは、相手が理解したかどうかを「推測」で済ませると、すぐに会話がズレます。特に経営会議のシミュレーションでは、議論が噛み合わないとリアリティが崩れます。社内キャラでも、相手が制度を誤解したまま進むと事故になります。したがって、会話設計には「どの段階で確認するか」「どの程度の確認が鬱陶しくないか」という、グラウンディングの戦略が必要です。</p>
<p>これを状態更新として書くと、共通基盤 $CG_t$ は断言だけでなく「理解の証拠」 $ack_t$ によって更新されると考えられます：</p>
<p>$$ CG_{t+1}= \begin{cases} CG_t \cap \llbracket p \rrbracket & \text{if } ack_t=\text{accept}(p)\ CG_t & \text{otherwise} \end{cases} $$</p>
<p>もちろん現実はもっと連続的で、「部分理解」や「条件付き受諾」があります。たとえばCFOが「キャッシュ条件が満たされるなら賛成」と言った場合、命題 $p$ は条件付きです。このような条件はコミットメントとして別に保持し、後で条件が満たされたときに共通基盤へ昇格させる、という設計が自然になります。</p>
<h3 id="643-修復（repair）会話のズレを直すメカニズム">6.4.3 修復（repair）：会話のズレを直すメカニズム</h3>
<p>会話はズレます。ズレを直すこと自体が会話の基本機能です。会話分析（Conversation Analysis）では、誤聞・言い間違い・曖昧さを解消するための <strong>修復（repair）</strong> の仕組みが詳細に研究されてきました。特に Schegloff, Jefferson, Sacks は「自己修復（自分で直す）」が好まれやすい、といった組織原理を示しています（Schegloff, Jefferson, & Sacks, 1977）。</p>
<ul>
<li>Schegloff, Jefferson, Sacks (1977) “The preference for self-correction in the organization of repair…” 再録PDF例： <a href="https://web.stanford.edu/~eckert/PDF/SchegloffEtAlRepair.pdf" target="_blank">https://web.stanford.edu/~eckert/PDF/SchegloffEtAlRepair.pdf</a>)</li>
</ul>
<p>人物らしいAIにとって修復は「失敗時の例外処理」ではなく、通常の対話行為です。CEO/COO/CTO/CFOの会話で「いまの“それ”はA案のこと？」と確認するのは自然です。社内キャラが「ここでいう“申請”は経費申請のことですか、それとも稟議ですか」と聞き返すのも自然です。修復を適切に行うと、幻覚（それっぽい補完）の危険が減り、共通基盤の更新が安定します。第3章で述べた「情報不足ほどスキーマが暴走する」という構造に対し、修復は追加観測で手がかりを増やす操作だからです。</p>
<hr>
<h2 id="65-会話の構造ターン交替・隣接対・会議らしさ">6.5 会話の構造：ターン交替・隣接対・会議らしさ</h2>
<h3 id="651-ターン交替誰がいつ話すかはルールに近い">6.5.1 ターン交替：誰がいつ話すかはルールに近い</h3>
<p>会話には、誰がいつ話すかという <strong>ターン交替（turn-taking）</strong> のシステムがあります。Sacks, Schegloff, Jefferson は、日常会話のターン交替が驚くほど秩序立っていることを示し、その最小システムを提案しました（Sacks, Schegloff, & Jefferson, 1974 “A simplest systematics for the organization of turn-taking for conversation”）。</p>
<ul>
<li>Sacks, Schegloff, Jefferson (1974) 再録PDF例： <a href="https://www.liso.ucsb.edu/Topics/Schegloff/turn-taking.pdf" target="_blank">https://www.liso.ucsb.edu/Topics/Schegloff/turn-taking.pdf</a>)</li>
</ul>
<p>経営会議のシミュレーションでリアリティが失われる典型は、「全員が同じ長さで同じ頻度で発言する」ことです。現実の会議では、CEOが話す権利（フロア）を持ちやすく、CFOは数字やリスクの局面で発話権が強くなり、CTOは技術的制約の局面で強くなり、COOは実行計画の局面で強くなります。つまり、ターン交替は「人格」だけではなく「役割・権力・議題」に依存します。ここをモデルに入れないと、会話が“均等すぎる”人工物になります。</p>
<p>工学的には、発話者選択を確率として持つと扱いやすいです。参加者集合を $\mathcal{I}$ とし、時刻 $t$ の議題状態を $g_t$、関係状態を $r_t$（権力差や信頼など）として、次の話者を</p>
<p>$$ P(i_{t+1}=i\mid g_t,r_t)\propto \exp(\eta,\mathrm{salience}_i(g_t) + \xi,\mathrm{power}_i(r_t)) $$</p>
<p>のように置けます。$\mathrm{salience}_i$ は「この議題でこの人が話すべき強さ」、$\mathrm{power}_i$ は発話権の強さ、$\eta,\xi$ は重みです。これは厳密な理論ではなく、ターン交替を「状態依存の選択」として設計対象にするための最小モデルです。社内キャラでも、複数人チャットでは「誰に向けて返すか」を選ぶ必要があり、同様の考え方が使えます。</p>
<h3 id="652-隣接対（adjacency-pairs）質問は回答を呼び提案は受諾／拒否を呼ぶ">6.5.2 隣接対（adjacency pairs）：質問は回答を呼び、提案は受諾／拒否を呼ぶ</h3>
<p>会話には「質問→回答」「依頼→受諾/拒否」「挨拶→挨拶」のような定型的なペア構造があり、これを <strong>隣接対（adjacency pairs）</strong> と呼びます。これは会話分析で基礎概念として扱われます（Schegloff & Sacks の流れ、教科書的整理は会話分析の文献に多数あります）。</p>
<p>人物らしさの設計では、この隣接対を「応答生成の制約」として使うと効果的です。たとえば、CFOが「その前提のキャッシュフロー表はありますか？」と質問したとき、CTOが突然「技術負債が…」と話し始めるのは不自然です。まず回答か、回答不能の宣言か、修復（どの表か確認）になります。社内キャラが「今どの部署ですか？」と聞いたなら、次は部署名を受け取るべきで、そこで長い助言を始めるのは不自然です。</p>
<p>隣接対は「形式の美しさ」ではなく、共通基盤を安全に更新するための装置です。質問で不足情報を埋め、回答で前提を固め、提案で合意形成へ進み、拒否で条件を再構成する。人物らしさは、この順序の使い方に現れます。</p>
<h3 id="653-会議らしさ議題論点合意アクション">6.5.3 会議らしさ：議題、論点、合意、アクション</h3>
<p>経営会議のシミュレーションで「会議らしさ」を出すには、会話を議題（agenda）と決定（decision）と行動項目（action items）の更新として扱うのが有効です。これは発話行為の更新モデル（6.3）と自然に接続します。</p>
<p>議題を $A_t$、決定集合を $D_t$、行動項目集合を $T_t$ とすると、会議状態は</p>
<p>$$ \Omega_t=(A_t, D_t, T_t) $$</p>
<p>で表され、発話行為によって更新されます。たとえば「ではA案で進めます」は $D_t$ を更新し、「COOが来週までに実行計画を作る」は $T_t$ を更新します。「議題を戻します」は $A_t$ を更新します。これを明示的に持つと、会話が“だらだら”しにくくなり、しかも人物らしさ（誰が決め、誰が宿題を持つか）が自然に出ます。</p>
<p>社内キャラでも、会話状態を「相談の論点」「決めるべきこと」「次の一歩」に整理し、会話をその更新として設計すると、共感（第5章）と有用性が両立しやすくなります。</p>
<hr>
<h2 id="66-礼儀と顔（face）社会的コストをモデルに入れる">6.6 礼儀と顔（face）：社会的コストをモデルに入れる</h2>
<p>人物らしさを壊す典型は「内容は正しいのに、言い方が不自然で関係を壊す」ことです。これは礼儀（politeness）の問題であり、礼儀は単なる丁寧語ではなく、相手の顔（face：体面、社会的自己像）を守る戦略です。</p>
<h3 id="661-ゴフマンの顔相互作用の中で守られる体面">6.6.1 ゴフマンの顔：相互作用の中で守られる体面</h3>
<p>Erving Goffman は、社会的相互作用において人が維持しようとする体面を「face」として論じ、顔を守るための行為（face-work）が相互作用の秩序を支えていることを示しました（Goffman, 1967 *Interaction Ritual*）。</p>
<ul>
<li>Goffman (1967) 書籍情報： <a href="https://www.routledge.com/Interaction-Ritual-Essays-on-Face-to-Face-Behavior/Goffman/p/book/9780202306171" target="_blank">https://www.routledge.com/Interaction-Ritual-Essays-on-Face-to-Face-Behavior/Goffman/p/book/9780202306171</a>)</li>
</ul>
<p>経営会議でCFOがCEOの案を否定するとき、単に「ダメです」と言うと関係が壊れます。普通は「前提を確認したい」「リスクが高いので条件を付けたい」という形で、相手の顔を保ちながら反対します。社内キャラでも、相談者のミスを指摘するときに「あなたが悪い」と言うのではなく、「ここで詰まりやすいポイントです」「次はこうすると安全です」と言うことで顔を守ります。顔の扱いは、人物らしさの中心的要素です。</p>
<h3 id="662-ブラウン＆レヴィンソン丁寧さは費用対効果で選ばれる">6.6.2 ブラウン＆レヴィンソン：丁寧さは費用対効果で選ばれる</h3>
<p>Brown & Levinson は、礼儀を「顔を脅かす行為（Face-Threatening Act: FTA）」のリスクを下げるための戦略として体系化しました（Brown & Levinson, 1987 *Politeness: Some Universals in Language Usage*）。</p>
<ul>
<li>Brown & Levinson (1987) 書籍情報： <a href="https://www.cambridge.org/core/books/politeness/5E8A6D5A1E83B2D0B3A5FBB0E6F23B45" target="_blank">https://www.cambridge.org/core/books/politeness/5E8A6D5A1E83B2D0B3A5FBB0E6F23B45</a>)</li>
</ul>
<p>彼らは、FTAの重み $W$ が、社会的距離 $D$、相手の権力 $P$、要求の負担 $R$ の和で近似できる、という有名な式を提示します：</p>
<p>$$ W = D + P + R $$</p>
<p>この式は厳密な心理法則ではありませんが、設計の直観として非常に有用です。たとえば経営会議でCEOに反対する（FTAが大きい）ときは、距離や権力差が大きく、要求の負担も大きいので $W$ が大きくなり、より丁寧な戦略（前置き、根拠提示、条件付き提案、謝意）を選ぶべきです。逆に、同僚同士なら $P$ が小さく、短く率直に言っても関係が壊れにくいので、丁寧さを下げてもよい。社内キャラでも、相手が役員なのか新入社員なのか、今どれだけ切羽詰まっているのかで (D,P,R) が変わり、適切な礼儀戦略が変わります。</p>
<h3 id="663-礼儀を効用に入れる内容と関係のトレードオフ">6.6.3 礼儀を効用に入れる：内容と関係のトレードオフ</h3>
<p>礼儀を工学的に扱う最短ルートは、「発話の効用」に社会的コストを入れることです。RSAの話し手効用を拡張して、内容の伝達（情報利得）と、顔コスト（関係コスト）をトレードオフする、と置きます。</p>
<p>発話 $u$ が世界 $w$ を伝える利得を $\log P_{L_0}(w\mid u)$、顔コストを $\mathrm{face}(u; D,P,R)$ とすると、</p>
<p>$$ U(u;w)=\log P_{L_0}(w\mid u) - \lambda,\mathrm{face}(u; D,P,R) - \mathrm{cost}(u) $$</p>
<p>と書けます。ここで $\lambda$ は「関係維持をどれだけ重視するか」の重みで、人格（第4章の協調性など）や状況（緊急時は関係コストより速度が重要）で変化します。この式が示すのは、礼儀は「付け足し」ではなく、意思決定（どの発話を選ぶか）そのものだということです。</p>
<p>経営会議の人物らしさは、この $\lambda$ の置き方に現れます。COOは合意形成を重視して $\lambda$ が高いかもしれません。CTOは技術リスクの重大性が高い局面では $\lambda$ を下げて強く主張するかもしれません。社内キャラは、相談者が傷つきやすい局面では $\lambda$ を上げ、しかし迎合（誤りへの同意）に落ちないように、主張の正しさを別の制約として入れる必要があります（迎合は第2章で触れた通りです）。</p>
<hr>
<h2 id="67-信頼とエピステミック・スタンス断言推測保留を使い分ける">6.7 信頼とエピステミック・スタンス：断言、推測、保留を使い分ける</h2>
<p>会話は内容だけでなく、話し手の信頼性（credibility）を常に評価しながら進みます。特に人物らしいAIでは、もっともらしい断言が過信を生みやすく（第1章の自動化バイアス）、誤りや捏造が致命傷になります。ここでは、会話における「信頼」と「不確実性表明」を理論として位置づけます。</p>
<h3 id="671-エピステミック・スタンス知っている／推測している／分からない">6.7.1 エピステミック・スタンス：知っている／推測している／分からない</h3>
<p>エピステミック（epistemic）とは「知識に関する」という意味です。エピステミック・スタンスは、話し手が自分の発話にどれだけ確信を持っているか、根拠は何か、どの程度推測かを示す態度です。自然言語では「〜だと思います」「確かに」「おそらく」「分かりません」「要確認です」といった表現に現れます。</p>
<p>人物らしさの設計で重要なのは、エピステミック・スタンスを「曖昧な逃げ」ではなく、根拠と紐づけて設計することです。実在人物のデジタルツインでは、観測されていないエピソードを断言しないことが極めて重要です（第3章のエピソード記憶と出典混同の危険）。架空キャラでも、設定にない事実を「昔こうだった」と語るとカノンが崩壊します。したがって「断言できる範囲」と「推測として述べる範囲」を、会話状態（根拠の有無、確度）で制御する必要があります。</p>
<h3 id="672-聞き手側の警戒エピステミック・ヴィジランス">6.7.2 聞き手側の警戒：エピステミック・ヴィジランス</h3>
<p>人は他者の発話を無条件に信じるわけではなく、妥当性や誠実性を評価する仕組みを持つ、という見方があります。Sperber らはこれを <strong>エピステミック・ヴィジランス（epistemic vigilance）</strong> として論じ、聞き手が情報源の信頼性や内容の整合性をチェックすることを整理しました（Sperber et al., 2010 “Epistemic vigilance”）。</p>
<ul>
<li>Sperber et al. (2010)  <a href="https://doi.org/10.1111/j.1468-0017.2009.01394.x" target="_blank">https://doi.org/10.1111/j.1468-0017.2009.01394.x</a>)  （要旨ページ： <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0017.2009.01394.x" target="_blank">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0017.2009.01394.x</a>)  ）</li>
</ul>
<p>人物らしいAIの設計では、聞き手（ユーザー）が常に賢く警戒してくれるとは限りません。むしろ流暢さで過信されがちです。したがって、エピステミック・ヴィジランスをユーザー任せにせず、システム側が「不確実性の表明」「根拠の提示」「確認質問」「保留」を適切に行うことで、誤用を防ぐ必要があります。</p>
<h3 id="673-信頼の更新をベイズで書く最小モデル">6.7.3 信頼の更新をベイズで書く：最小モデル</h3>
<p>信頼を確率として最小に書くと、話し手が「正しいことを言う確率」を $\theta\in[0,1]$ とし、観測（検証可能な事実との一致など）を $E$ とすると、</p>
<p>$$ P(\theta\mid E)\propto P(E\mid \theta),P(\theta) $$</p>
<p>というベイズ更新になります。現実には $\theta$ を直接推定するのは難しいですが、この式が示す設計原則は明快です。<strong>検証可能な発話を増やすほど信頼は更新でき、検証不能な断言を増やすほど信頼は壊れる</strong>ということです。</p>
<p>経営会議のシミュレーションでは、「根拠（資料、数字、過去の決定）に紐づく発話」を増やすほどリアリティと信頼が増します。社内キャラでも「規程の該当箇所」「手順の根拠」「注意点の理由」を示すほど信頼が増します。逆に「たぶん大丈夫」「経験上…」のような検証不能な断言は、人物らしさを作るどころか危険です。実在人物ツインが「本人の経験上」と言うのは特に致命的になり得ます。</p>
<hr>
<h2 id="68-設計への落とし込み人物らしい会話を壊さないための最小原則">6.8 設計への落とし込み：人物らしい会話を壊さないための最小原則</h2>
<p>本章は理論中心ですが、最後に「理論がどこに効くのか」を、文章で具体化しておきます。</p>
<p>第一に、会話出力は「内容の答え」と「行為（依頼、提案、拒否、謝罪など）」を分けて設計すべきです。発話行為（Austin, Searle）を明示的に扱うと、AIが不用意に約束したり、命令したり、断言したりする事故を減らせます。これは“安全のため”だけでなく、“人物らしさのため”です。CEOが軽々しく約束を連発するのは不自然ですし、社内キャラが過剰に命令的だと嫌われます。</p>
<p>第二に、会話は共通基盤（Stalnaker）とグラウンディング（Clark & Brennan）の更新として扱い、「理解が確立するまで決定を確定させない」設計が必要です。人物らしさのAIは、もっともらしい補完で会話を前に進めてしまう誘惑が強いですが、補完は第3章で見た通り偽記憶と同型の危険を持ちます。修復（Schegloff et al.）は、補完を抑制するための通常行為として組み込みます。</p>
<p>第三に、礼儀（Brown & Levinson）の設計は「丁寧語の追加」ではなく、社会的コストを効用に入れる問題です。経営会議では反対や拒否が避けられませんが、顔を守る形で行うことで合意形成が可能になります。社内キャラでも、相手の顔を守りながら誤りを正すことで、有用性と心理的安全性が両立します。ここで $W=D+P+R$ の直観は、場面に応じた丁寧さのスケーリングとして非常に使いやすいでしょう。</p>
<p>第四に、エピステミック・スタンス（知っている／推測／保留）を「会話の作法」ではなく「信頼の維持機構」として扱います。聞き手は常に適切に警戒できるとは限りません（エピステミック・ヴィジランス）。だからこそ、AI側が断言の条件を制御し、根拠のある主張と推測を混同しないことが必須です。</p>
<p>この4点は、後続の章で扱う記憶管理、ツール利用、真実性・安全、複数エージェントの会議運営など、全ての基盤になります。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Grice, H. P. (1975). “Logic and Conversation.”（再録PDF例） <a href="https://www.sfu.ca/~jeffpell/Cogs300/GriceLogicConversation.pdf" target="_blank">https://www.sfu.ca/~jeffpell/Cogs300/GriceLogicConversation.pdf</a>)</p>
<p>Frank, M. C., & Goodman, N. D. (2012). “Predicting Pragmatic Reasoning in Language Games.” <a href="https://web.stanford.edu/~ngoodman/papers/FrankGoodmanCogSci2012.pdf" target="_blank">https://web.stanford.edu/~ngoodman/papers/FrankGoodmanCogSci2012.pdf</a>)</p>
<p>Goodman, N. D., & Frank, M. C. (2016). “Pragmatic Language Interpretation as Probabilistic Inference.” *Trends in Cognitive Sciences*. DOI:  <a href="https://doi.org/10.1016/j.tics.2016.08.005" target="_blank">https://doi.org/10.1016/j.tics.2016.08.005</a>) 本文ページ:  <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613%2816%2930109-3" target="_blank">https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(16)30109-3</a>)</p>
<p>Austin, J. L. (1962). *How to Do Things with Words.* Harvard University Press. <a href="https://www.hup.harvard.edu/books/9780674411524/how-to-do-things-with-words" target="_blank">https://www.hup.harvard.edu/books/9780674411524/how-to-do-things-with-words</a>)</p>
<p>Searle, J. R. (1969). *Speech Acts.* Cambridge University Press. <a href="https://www.cambridge.org/core/books/speech-acts/0F3F7689AE4D7C7F4A5AF8D4D9C3D2B0" target="_blank">https://www.cambridge.org/core/books/speech-acts/0F3F7689AE4D7C7F4A5AF8D4D9C3D2B0</a>)</p>
<p>Searle, J. R. (1975). “A taxonomy of illocutionary acts.”（再録PDF例） <a href="https://web.stanford.edu/class/linguist289/notes/SearleTaxonomyIllocutionaryActs.pdf" target="_blank">https://web.stanford.edu/class/linguist289/notes/SearleTaxonomyIllocutionaryActs.pdf</a>)</p>
<p>Stalnaker, R. (1978). “Assertion.”（再録PDF例） <a href="https://web.stanford.edu/class/linguist159/StalnakerAssertion.pdf" target="_blank">https://web.stanford.edu/class/linguist159/StalnakerAssertion.pdf</a>)</p>
<p>Clark, H. H., & Brennan, S. E. (1991). “Grounding in Communication.”（再録PDF例） <a href="https://www.cs.cmu.edu/~illah/CLASS/clark1991.pdf" target="_blank">https://www.cs.cmu.edu/~illah/CLASS/clark1991.pdf</a>)</p>
<p>Sacks, H., Schegloff, E. A., & Jefferson, G. (1974). “A simplest systematics for the organization of turn-taking for conversation.”（再録PDF例） <a href="https://www.liso.ucsb.edu/Topics/Schegloff/turn-taking.pdf" target="_blank">https://www.liso.ucsb.edu/Topics/Schegloff/turn-taking.pdf</a>)</p>
<p>Schegloff, E. A., Jefferson, G., & Sacks, H. (1977). “The preference for self-correction in the organization of repair…”（再録PDF例） <a href="https://web.stanford.edu/~eckert/PDF/SchegloffEtAlRepair.pdf" target="_blank">https://web.stanford.edu/~eckert/PDF/SchegloffEtAlRepair.pdf</a>)</p>
<p>Goffman, E. (1967). *Interaction Ritual: Essays on Face-to-Face Behavior.* <a href="https://www.routledge.com/Interaction-Ritual-Essays-on-Face-to-Face-Behavior/Goffman/p/book/9780202306171" target="_blank">https://www.routledge.com/Interaction-Ritual-Essays-on-Face-to-Face-Behavior/Goffman/p/book/9780202306171</a>)</p>
<p>Brown, P., & Levinson, S. C. (1987). *Politeness: Some Universals in Language Usage.* Cambridge University Press. <a href="https://www.cambridge.org/core/books/politeness/5E8A6D5A1E83B2D0B3A5FBB0E6F23B45" target="_blank">https://www.cambridge.org/core/books/politeness/5E8A6D5A1E83B2D0B3A5FBB0E6F23B45</a>)</p>
<p>Sperber, D., Clément, F., Heintz, C., Mascaro, O., Mercier, H., Origgi, G., & Wilson, D. (2010). “Epistemic vigilance.” *Mind & Language*. DOI:  <a href="https://doi.org/10.1111/j.1468-0017.2009.01394.x" target="_blank">https://doi.org/10.1111/j.1468-0017.2009.01394.x</a>) 要旨ページ:  <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0017.2009.01394.x" target="_blank">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0017.2009.01394.x</a>)</p>
<h1 id="第7章-コンテクスト工学と長期記憶管理何を入れ何を忘れ何を参照するか">第7章　コンテクスト工学と長期記憶管理：何を入れ、何を忘れ、何を参照するか</h1>
<p>第3章で、コンテクスト（モデルに一度に与える入力）が「作業記憶」に相当し、長期一貫性のためには外部の長期記憶が必要になることを学びました。第4章と第5章では、人格・価値観・目標・感情が「選び方」に効くパラメータであることを整理しました。第6章では、会話は単なる文章生成ではなく社会的行為であり、共通基盤（共有前提）や信頼の更新として設計すべきだと述べました。</p>
<p>ここまでの内容を、実際に「人物らしいAI」として動かすとき、必ず避けて通れないのが <strong>コンテクスト工学（context engineering）</strong> と <strong>長期記憶管理（long-term memory management）</strong> です。コンテクスト工学とは、「そのターンでモデルに何を見せるか」を設計することです。長期記憶管理とは、「何を長期に保存し、どのように検索し、どのタイミングで要約・統合・忘却するか」を設計することです。</p>
<p>この章の結論は単純です。人物らしさは「知識をたくさん入れる」だけでは作れません。むしろ、<strong>限られた入力枠の中で、判断に効く情報を選び、必要なら確認し、根拠を持って語り、矛盾や捏造を避ける</strong>ことが、人物らしさと信頼性の両方を支えます。特に実在人物のデジタルツイン（通し例A）では、エピソードの捏造が致命傷になります。架空キャラ（通し例B）では、設定（カノン）と過去の発言との整合性が崩れるとキャラが壊れます。両者は「長期一貫性」が必要という点で同じですが、「何を真実として扱うか」「どこまで創作を許すか」「何を根拠として示すか」が違います。したがって、同じ“記憶システム”でも、保存規則と参照規則は変える必要があります。</p>
<p>本章では、(1)コンテクストを層構造として設計する考え方、(2)記憶項目のデータモデル（出典・確度・時刻を含む）、(3)検索（疎検索・密検索・ハイブリッド）と再ランキング、(4)要約・圧縮と階層化、(5)書き込み・統合・忘却の規則、(6)矛盾・出典・安全境界、を順に扱います。理論と実装の間をつなぐため、数式は「最小だが設計判断に効く」形で提示します。</p>
<hr>
<h2 id="71-コンテクストは「作業記憶」長くすれば解決するわけではない">7.1 コンテクストは「作業記憶」：長くすれば解決するわけではない</h2>
<h3 id="711-コンテクストウィンドウの役割その場の推論の舞台">7.1.1 コンテクストウィンドウの役割：その場の推論の舞台</h3>
<p>大規模言語モデル（Large Language Model: LLM）は、入力されたテキスト（コンテクスト）に条件づけられて次のトークンを生成します。ここで重要なのは、モデルが“一度に参照できる”情報には上限があることです。この上限を一般にコンテクストウィンドウ（context window）と呼びます。第3章で述べた作業記憶モデル（Baddeley & Hitch, 1974）と同じく、コンテクストは「保持」だけでなく「操作」の場であり、推論や意思決定がそこで行われます。</p>
<p>したがって、長期一貫性を作るには、外部に長期記憶ストアを持ち、必要なときに取り出してコンテクストへ“出張”させる必要があります。これは、検索拡張生成（Retrieval-Augmented Generation：RAG）という研究ラインで体系化されてきました。RAGは、生成モデルが外部文書を検索し、それを条件として生成する枠組みです（Lewis et al., 2020 “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks”  <a href="https://arxiv.org/abs/2005.11401" target="_blank">https://arxiv.org/abs/2005.11401</a> ）。</p>
<h3 id="712-長いほど良いわけではない位置バイアスと情報価値密度">7.1.2 長いほど良いわけではない：位置バイアスと情報価値密度</h3>
<p>「とにかく全部入れればよい」と考えるのは危険です。第3章で触れた通り、長いコンテクストでは重要情報が“真ん中”に埋もれる傾向が報告されています（Liu et al., 2023/2024 “Lost in the Middle: How Language Models Use Long Contexts”  <a href="https://arxiv.org/abs/2307.03172" target="_blank">https://arxiv.org/abs/2307.03172</a> ）。人間の系列位置効果（Murdock, 1962）と似た形で、先頭や末尾の情報が使われやすい一方で、中ほどの情報が利用されにくい場合がある、ということです。</p>
<p>工学的には、コンテクストに入れた断片 $z$ の有効性を</p>
<p>$$ \mathrm{eff}(z)=\mathrm{rel}(z)\cdot a(pos(z)) $$</p>
<p>と書くと直観的です。ここで $\mathrm{rel}(z)$ は関連度、(a(pos)) は位置による注意のゲートです。理想は $a\equiv 1$ ですが、現実には $a$ が位置に依存して変化します。つまり「長く入れるほど $\mathrm{rel}$ が増える」と期待しても、同時に $a$ の悪化で $\mathrm{eff}$ が下がることがあります。</p>
<p>このため、人物らしいAIのコンテクスト設計では、文字数ではなく <strong>情報価値密度</strong>（判断に効く情報の割合）を上げることが重要になります。情報価値密度は厳密に一つの定義があるわけではありませんが、設計の指標としては「同じトークン数で、意思決定（第4章）の評価スコア（第2章）がどれだけ改善するか」を観測すればよい、という発想が実務的です。つまり“入れた情報の増分価値”を測り、増分価値が小さい情報は圧縮・要約・削除する、という方針です。</p>
<h3 id="713-設計対象としての「入力構成」">7.1.3 設計対象としての「入力構成」</h3>
<p>コンテクスト工学の中心は、入力をいくつかの層に分けて構成することです。初学者の段階で最も重要なのは、「変えにくい情報」と「状況で変える情報」を混ぜないことです。第4章の特性（trait）と状態（state）の分離と同じ発想です。</p>
<p>人物らしいAIの入力は、最低限次のような層に分解できます。</p>
<p>まず、人物の比較的安定した仕様（人格・価値観・口調の基本、ただし“口調だけ”にならないよう意思決定の優先順位も含む）があり、これは頻繁に変えてはいけません。次に、現在の対話の目的や議題、共通基盤（第6章）などの会話状態があります。さらに、必要に応じて長期記憶から検索されたエピソードや知識があり、最後にユーザーの入力やツールの結果（検索結果や計算結果など）が入ります。</p>
<p>この層構造は、実装上は「テンプレート」として表現されることが多いですが、本質はテンプレートではありません。本質は、「何を固定し、何を可変にし、どの情報がどの判断に効くか」を明示することです。以後の節は、この層を支える記憶ストアと検索・圧縮の設計へ進みます。</p>
<hr>
<h2 id="72-長期記憶ストアのデータモデル内容だけでなく出典・時刻・確度を持つ">7.2 長期記憶ストアのデータモデル：内容だけでなく出典・時刻・確度を持つ</h2>
<p>第3章で、エピソード記憶と意味記憶、そしてソースモニタリング（出典判断）が重要だと述べました（Johnson, Hashtroudi, & Lindsay, 1993 “Source monitoring”  <a href="https://doi.org/10.1037/0033-2909.114.1.3" target="_blank">https://doi.org/10.1037/0033-2909.114.1.3</a> ）。この章では、それを工学のデータモデルへ落とします。</p>
<h3 id="721-記憶項目の最小表現テキスト＋メタデータ">7.2.1 記憶項目の最小表現：テキスト＋メタデータ</h3>
<p>長期記憶ストアを、記憶項目（memory item）の集合 $M={m_i}$ として表します。各記憶項目 $m_i$ は、本文（テキスト） $x_i$ と、メタデータ $\mu_i$ の組として</p>
<p>$$ m_i=(x_i,\mu_i) $$</p>
<p>と表せます。本文 $x_i$ は、会話ログの抜粋、会議の決定、人物の発言、あるいは「設定」そのものかもしれません。重要なのは、本文だけを保存してはいけない、という点です。人物らしさと安全の両立には、少なくとも次のメタデータが必要になります。</p>
<p>まず <strong>時刻</strong>（いつの情報か）です。次に <strong>出典</strong>（誰が言ったか、どの文書に書いてあるか）です。さらに <strong>種類</strong>（観測、伝聞、推測、創作設定など）です。そして <strong>確度（信頼度）</strong>です。確度は厳密な真偽ではなく、「この情報を断言してよいか、どの程度保留すべきか」を制御するためのスカラーとして扱います。第6章のエピステミック・スタンス（断言・推測・保留）の制御に直結します。</p>
<p>確度を $r_i\in[0,1]$ とし、種類を $type_i$ とすると、実在人物のデジタルツインでは「推測タイプ」の情報をエピソードとして語るのは基本的に避けるべきです。一方、架空キャラでは「設定タイプ」の情報は確度が1に近くてもよい（カノンとして確定）一方で、「ユーザーの推測」を設定へ昇格させないように確度を低く保持する、といった設計になります。</p>
<h3 id="722-意味記憶・エピソード記憶・手続き記憶混ぜると壊れる">7.2.2 意味記憶・エピソード記憶・手続き記憶：混ぜると壊れる</h3>
<p>長期記憶は少なくとも二種類に分けるのが安全です。第3章で述べた通り、エピソード記憶は「いつどこで何が起きたか」であり、意味記憶は一般知識です（Tulving, 1972）。これに加えて工学的には「手続き記憶（procedural memory）」に相当するもの、つまり「この状況ではこう振る舞う」「この形式で出力する」といった手順・方針も長期に保持する必要が出ます。手続き記憶は心理学の厳密定義とは異なりますが、実装上は“行動規則”として別扱いした方が安定します。</p>
<p>この三つを混ぜると、典型的に次の事故が起きます。意味記憶（規程）をエピソードとして語ってしまう（「私はそう経験した」）、エピソードの出来事が一般知識のように一般化される（「いつもそうだ」）、手続き（出力形式）が内容と混ざり、矛盾するルールが増える、などです。したがってデータモデルとしては、記憶ストアを</p>
<p>$$ M = M^{\text{epis}} \cup M^{\text{sem}} \cup M^{\text{proc}} $$</p>
<p>のように分け、検索もまず「どのストアを検索すべきか」を決める方が安全です。例えば「社内規程の質問」なら意味記憶、「前回の会議の決定」ならエピソード記憶、「この人物はどう拒否するか」なら手続き記憶（対話方針）というように、入口で分岐させます。</p>
<h3 id="723-「人格や価値観」は記憶とは別の状態として持つ">7.2.3 「人格や価値観」は記憶とは別の状態として持つ</h3>
<p>第4章で人格 $p$ と価値観 $v$ をパラメータとして導入しました。これらは長期に安定しやすい一方、会話ログから“学習”して少しずつ推定が更新されることもあります。ここで重要なのは、人格や価値観を「エピソード記憶」と同じストアにべた書きしないことです。なぜなら人格推定は不確実で、更新もあり得るからです。</p>
<p>工学的には、人格や価値観は「潜在変数」として分布で持ち、観測（行動ログ）で更新するのが安全です。人格 $p$ に事前分布 (P$p$) を置き、行動データ $D$ を観測したときの事後分布は</p>
<p>$$ P(p\mid D)\propto P(D\mid p),P(p) $$</p>
<p>です（これは第4章の心理測定の最小形でした）。この更新を、エピソードの保存と混線させないことが、長期一貫性を壊さない鍵になります。</p>
<hr>
<h2 id="73-検索疎検索・密検索・ハイブリッドそして多様性">7.3 検索：疎検索・密検索・ハイブリッド、そして多様性</h2>
<p>長期記憶ストアがあっても、必要なときに必要なものを取り出せなければ意味がありません。ここでは、検索（retrieval）の基本設計を扱います。検索は大きく、疎検索（sparse retrieval：語の一致を中心にする）と密検索（dense retrieval：埋め込みの近さを中心にする）に分かれ、それらを組み合わせたハイブリッドが実務でよく使われます。</p>
<h3 id="731-疎検索BM25（語の一致と文書頻度）">7.3.1 疎検索：BM25（語の一致と文書頻度）</h3>
<p>疎検索の代表が BM25 です。BM25 は、単語の出現頻度（term frequency）と、文書集合の中での希少性（inverse document frequency）を組み合わせたスコアリングです。Robertson らの研究として広く知られています（Robertson & Zaragoza, 2009 “The Probabilistic Relevance Framework: BM25 and Beyond” の概説PDFが公開されています： <a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf" target="_blank">https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf</a> ）。</p>
<p>BM25の典型形は次のように書けます（記号は教科書的簡略化です）。クエリを $q$、文書（ここでは記憶本文）を $d$ とし、単語 $t$ について</p>
<p>$$ \mathrm{BM25}(q,d)=\sum_{t\in q} \mathrm{IDF}(t)\cdot \frac{f(t,d)\cdot (k_1+1)}{f(t,d)+k_1\cdot\left(1-b+b\cdot \frac{|d|}{\mathrm{avgdl}}\right)}$$ ここで (f(t,d)) は文書中の単語頻度、$|d|$ は文書長、$\mathrm{avgdl}$ は平均文書長、$k_1,b$ はハイパーパラメータです。疎検索の強みは、「固有名詞や専門用語、型番、制度名」など、語が一致すると強い手がかりになる場合に強いことです。社内制度の名前、会議資料のタイトル、プロジェクト名などは疎検索が効きます。</p>
<p>ただし人物らしさの会話では、同じ内容が別の言い方で表れることが多いので、語の一致だけでは取りこぼしが起きます。ここで密検索が必要になります。</p>
<h3 id="732-密検索埋め込み（embedding）による近傍探索">7.3.2 密検索：埋め込み（embedding）による近傍探索</h3>
<p>密検索は、文章を埋め込みベクトル $\phi(x)\in\mathbb{R}^m$ に写し、ベクトルの近さで検索します。近さとしてよく使われるのがコサイン類似度です：</p>
<p>$$ \mathrm{sim}(q,d)=\frac{\phi(q)\cdot\phi(d)}{|\phi(q)|,|\phi(d)|}$$ 密検索の代表的研究として、Dense Passage Retrieval（DPR）があります。DPRは、クエリと文書を別々のエンコーダで埋め込み、内積で近傍検索する枠組みを提案しました（Karpukhin et al., 2020 “Dense Passage Retrieval for Open-Domain Question Answering”  <a href="https://arxiv.org/abs/2004.04906" target="_blank">https://arxiv.org/abs/2004.04906</a> ）。</p>
<p>密検索の利点は、言い換えに強いことです。「資金繰りが厳しい」と「キャッシュが薄い」が近い意味として拾える可能性が高まります。経営会議のログや相談ログの検索では特に有用です。一方、密検索は“意味が近いが違う話”も拾いやすいので、誤った記憶参照（第3章の出典混同）につながる危険があります。したがって、後述する再ランキング（reranking）や確度フィルタが重要になります。</p>
<p>実装面では、埋め込み近傍探索を高速化するために近似最近傍探索（Approximate Nearest Neighbor: ANN）を使うことが多く、FAISSなどのライブラリが代表です（Johnson, Douze, & Jégou, 2017 “Billion-scale similarity search with GPUs”  <a href="https://arxiv.org/abs/1702.08734" target="_blank">https://arxiv.org/abs/1702.08734</a> ）。</p>
<h3 id="733-ハイブリッド検索疎と密を足し合わせる（または学習する）">7.3.3 ハイブリッド検索：疎と密を足し合わせる（または学習する）</h3>
<p>疎検索と密検索は、得意領域が違います。そこで実務では、まず疎と密でそれぞれ候補集合を作り、マージして再ランキングする、という構成が多いです。スコアを単純に足し合わせるなら、候補文書 $d$ の総合スコアを</p>
<p>$$ \mathrm{score}(q,d)=\lambda,\mathrm{BM25}(q,d) + (1-\lambda),\mathrm{sim}(q,d) $$</p>
<p>と置けます。ここで $\lambda\in[0,1]$ は重みです。さらに時刻や確度を入れると、次のような形になります。</p>
<p>$$ $$\mathrm{score}(q,d)=\lambda,\mathrm{BM25}(q,d) + (1-\lambda),\mathrm{sim}(q,d)$$</p>
<p>$$+ \gamma , \mathrm{recency}(d) + \delta , r(d)$$ $$</p>
<p>ここで $\mathrm{recency}(d)$ は新しさ（最近ほど大きい）、(r$d$) は確度、$\gamma,\delta$ は重みです。新しさは指数減衰で表すのが簡単で、現在時刻を $t$、文書の時刻を $t_d$、時定数を $\tau>0$ とすると</p>
<p>$$ \mathrm{recency}(d)=\exp\left(-\frac{t-t_d}{\tau}\right)$$ と置けます。経営会議では直近の決定が重要なので $\tau$ を小さくし、人物の長期方針は古くても重要なので $\tau$ を大きくする、といった設計ができます。架空キャラでも「直近の対話で言ったこと」は一貫性に重要なので新しさ重視が効きますが、「カノンの基本設定」は時刻に依存しないので別ストアで扱う方が安定します。</p>
<h3 id="734-多様性同じ話ばかり拾わない（MMR）">7.3.4 多様性：同じ話ばかり拾わない（MMR）</h3>
<p>検索のもう一つの落とし穴は、上位候補が似通ってしまうことです。例えば同じ会議議事録の近い段落が上位を占めると、コンテクストが冗長になり、別の重要論点が落ちます。これを避ける代表的手法が <strong>最大限関連性（Maximal Marginal Relevance: MMR）</strong> です。MMRは、関連度と冗長性のトレードオフで候補を逐次選択します（Carbonell & Goldstein, 1998 “The Use of MMR, Diversity-Based Reranking…”  <a href="https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf" target="_blank">https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf</a> ）。</p>
<p>候補集合を $R$、すでに選んだ集合を $S$、クエリを $q$ とし、関連度を $\mathrm{sim}(d,q)$、文書同士の類似を $\mathrm{sim}(d,s)$ とすると、次に選ぶ文書 $d^*$ を</p>
<p>$$ d^*=\arg\max_{d\in R\setminus S}\left[ \lambda,\mathrm{sim}(d,q) - (1-\lambda)\max_{s\in S}\mathrm{sim}(d,s) \right] $$</p>
<p>で定めます（$\lambda\in[0,1]$）。直観的には「クエリに近いが、すでに選んだものと重複しない」文書を選ぶ方法です。人物らしさの会話では、同じ論点の繰り返しは不自然で、特に経営会議のシミュレーションでは議論が停滞したように見えます。MMRは、この“停滞”を抑えるための重要な部品になります。</p>
<hr>
<h2 id="74-コンテクスト組み立て階層化と圧縮は「情報の目的関数」で決める">7.4 コンテクスト組み立て：階層化と圧縮は「情報の目的関数」で決める</h2>
<p>検索で候補が取れたとしても、それをそのまま全部コンテクストに貼ると、位置バイアスや冗長性で壊れます。そこで必要なのが、階層化（hierarchy）と圧縮（compression）です。</p>
<h3 id="741-階層化詳細ログと要約を同時に持つ">7.4.1 階層化：詳細ログと要約を同時に持つ</h3>
<p>階層化とは、同じ情報を「粗い要約」と「詳細」の両方で保持し、状況に応じて使い分ける設計です。人間の記憶でも、要旨（gist）と詳細（verbatim）が分かれることが示唆されます（DRMパラダイムの議論は第3章）。工学的には、これは「メモリのページング」や「サマリー階層」として現れます。</p>
<p>LLMの長期記憶を階層的に扱う提案として、MemGPTがあります。MemGPTは、短い作業領域と外部メモリを持ち、必要に応じて“ページイン／ページアウト”するオペレーティングシステム的な設計を提案しました（Packer et al., 2023 “MemGPT: Towards LLMs as Operating Systems”  <a href="https://arxiv.org/abs/2310.08560" target="_blank">https://arxiv.org/abs/2310.08560</a> ）。ここで重要なのは、モデルが一度に参照する量が限られるなら、参照すべき情報を管理する「メモリ管理機構」が必要になるという発想です。</p>
<p>階層化の一つの最小表現は、記憶ストアをレベルで分けることです。たとえば詳細ログを $M^{(0)}$、それを要約した短い記憶を $M^{(1)}$、さらに月次や人物方針として要約した $M^{(2)}$ として、</p>
<p>$$ M = M^{(0)} \cup M^{(1)} \cup M^{(2)} $$</p>
<p>のように階層を持ちます。検索時には、まず上位要約で当たりをつけ、必要なら詳細へ降りる、という二段階検索が可能になります。これにより「全部を入れる」ではなく「必要な粒度だけ入れる」が実現できます。</p>
<h3 id="742-圧縮は損失関数で決める情報ボトルネックの直観">7.4.2 圧縮は損失関数で決める：情報ボトルネックの直観</h3>
<p>要約は本質的に損失圧縮です。圧縮しすぎると重要な条件が落ち、人物らしさが壊れます。圧縮しないとコンテクストが溢れ、同じく壊れます。このトレードオフを「情報の目的関数」として捉える直観が役に立ちます。</p>
<p>理論としては <strong>情報ボトルネック（Information Bottleneck）</strong> の原理が有名です。入力 $X$ から圧縮表現 $Z$ を作り、目的 $Y$ に必要な情報を保ったまま $Z$ をできるだけ小さくする、という考え方です（Tishby, Pereira, & Bialek, 2000 “The Information Bottleneck Method”  <a href="https://arxiv.org/abs/physics/0004057" target="_blank">https://arxiv.org/abs/physics/0004057</a> ）。形式的には、相互情報量 $I(\cdot;\cdot)$ を用いて</p>
<p>$$ \min_{p(z\mid x)}\ I(X;Z)-\beta I(Z;Y) $$</p>
<p>のような最適化で表されます。ここで $\beta$ は「目的情報をどれだけ重視するか」です。</p>
<p>人物らしさのコンテクスト圧縮で重要なのは、数学の厳密さではなくこの直観です。つまり、要約 $Z$ は「会話の目的（次の応答 $Y$）に必要な情報」を落としてはいけない一方で、目的に無関係な細部は落とすべきです。通し例Aの経営会議なら、意思決定の条件（いつ、何が前提で、誰が何に懸念を持ったか）が目的に必要です。雑談の細部は不要です。通し例Bの社内キャラなら、相談者の状況・制約・不安点・次の一歩が必要で、余談は不要です。こうした「目的」を定義できるのが第2章の評価設計であり、本節の圧縮設計は評価とセットで回します。</p>
<h3 id="743-コンテクストの順序と境界混ぜずに区切る">7.4.3 コンテクストの順序と境界：混ぜずに区切る</h3>
<p>コンテクストに複数種類の情報を入れるときは、<strong>境界を明示</strong>して混線を避けます。混線とは、例えば「参照文書に書いてあること」を「会話で合意したこと」と勘違いする、あるいは「推測」を「確定した事実」として扱うことです。第3章で述べた出典混同の工学版です。</p>
<p>境界は、見出し・区切り・引用符・メタデータ提示などで作れます。重要なのは、モデルが境界を“それなりに”理解できるよう、形式を一貫させることです。たとえば、参照文書は「引用」として扱い、会話の合意は「決定」として別ブロックに置く、というようにします。これは第6章の共通基盤更新（合意が成立したものだけが共有前提になる）と整合します。</p>
<p>ここで注意したいのは、境界は万能ではないという点です。モデルは境界を跨いで一般化し得ます。したがって境界設計は、後述する「参照可能な記憶だけで語る」制約や、矛盾検知と組み合わせて初めて効果を持ちます。</p>
<hr>
<h2 id="75-記憶の書き込み・統合・忘却保存規則が人物らしさを決める">7.5 記憶の書き込み・統合・忘却：保存規則が人物らしさを決める</h2>
<p>検索と圧縮に加えて重要なのが、「いつ何を記憶に書くか」です。記憶システムは、検索だけ頑張っても、入力される記憶が不適切なら壊れます。人間の記憶研究でも、符号化（encoding）と検索（retrieval）は表裏一体であり、符号化特定性（Tulving & Thomson, 1973）が示すように、符号化の仕方が検索可能性を決めます。</p>
<h3 id="751-「書く」か「書かない」かイベント抽出としての記憶化">7.5.1 「書く」か「書かない」か：イベント抽出としての記憶化</h3>
<p>対話ログの全てを記憶化すると、冗長で検索が破綻し、しかもプライバシーや安全のリスクが増えます。逆に、何も書かないと一貫性が作れません。ここで必要なのは、記憶化を「イベント抽出」として扱うことです。</p>
<p>会話の各ターンから、エピソードとして残すべき出来事（決定、約束、好みの表明、重要な制約、関係性の変化など）を抽出し、それだけを保存します。第6章で述べた発話行為とコミットメント更新は、まさに「何を記憶化すべきか」の定義を与えます。約束（コミッシブ）をしたならタスクとして保存する。決定（宣言）が成立したなら決定として保存する。単なる雑談は保存しない。こうした“行為に基づく記憶化”は、人物らしさの長期一貫性に直結します。</p>
<h3 id="752-統合（consolidation）と反省（reflection）要約は「上位の状態」を作る">7.5.2 統合（consolidation）と反省（reflection）：要約は「上位の状態」を作る</h3>
<p>単にイベントを積み上げるだけでは、長期一貫性は作れても「人物らしい発展」や「計画」が作りにくい場合があります。人間の記憶でも、経験がそのまま残るだけでなく、概念化・スキーマ化が進みます（Bartlett, 1932）。この工学版として注目されたのが、Generative Agents の枠組みです。Park らは、複数のエージェントが仮想環境で生活するシミュレーションにおいて、記憶ストリーム（出来事の列）を保持し、重要度・新しさ・関連度で検索し、さらに“反省（reflection）”によって高次の洞察（抽象記憶）を生成して行動計画に使う仕組みを提案しました（Park et al., 2023 “Generative Agents: Interactive Simulacra of Human Behavior”  <a href="https://arxiv.org/abs/2304.03442" target="_blank">https://arxiv.org/abs/2304.03442</a> ）。</p>
<p>この枠組みの価値は、「要約」を単なる短縮ではなく、「上位の概念（方針、傾向、教訓）」を作る操作として位置づけた点です。工学的には、反省は次のようにモデル化できます。低次記憶（イベント）集合を $M^{(0)}$、反省により生成された上位記憶集合を $M^{(1)}$ とし、</p>
<p>$$ M^{(1)} \leftarrow \mathrm{Reflect}(M^{(0)}) $$</p>
<p>と置きます。ここで $\mathrm{Reflect}$ は、複数イベントの共通パターンを抽出し、抽象化した文を生成する操作です。たとえば「CFOは資金繰りが逼迫すると、新規投資に強い条件を付ける傾向がある」といった要約は、個々の会議ログの上位概念です。架空キャラでも「このキャラは困っている相手にまず状況を整理させ、次に選択肢を提示する」といった手続き的方針が上位記憶になります。</p>
<p>ただし実在人物のデジタルツインでこの反省を使うときは注意が必要です。反省は推論であり、観測された事実ではありません。したがって反省結果は「傾向の仮説」として確度を下げ、エピソードとして語らない、という設計が必要になります。ここでも、記憶項目の種類と確度メタデータが効きます。</p>
<h3 id="753-忘却消す・薄める・要約する">7.5.3 忘却：消す・薄める・要約する</h3>
<p>忘却（forgetting）は欠陥ではなく機能です。Schacter（1999）の「記憶の七つの罪」が示すように、忘却と歪みはトレードオフを持ちます。工学でも同じで、無限に蓄積すると検索が破綻し、矛盾検知も難しくなります。忘却は次の3つに分けて設計すると扱いやすいです。</p>
<p>第一は「消す」です。個人情報や機密を保持しない、あるいは保持期間を定める、といった要求がある場合は、物理的に削除する必要があります。これは倫理・法務・セキュリティ（後の章）と直結します。</p>
<p>第二は「薄める」です。確率モデルとしては、古い記憶の重みを指数減衰で下げるのが簡単です。先ほどの $\mathrm{recency}$ の式がそれです。</p>
<p>第三は「要約する」です。詳細は捨てるが、上位概念として残す。これは階層化と同じです。忘却を単なる削除にすると人物らしさ（長期的傾向）が消えますが、要約として残すと一貫性を保てます。</p>
<p>忘却戦略は用途で変えます。通し例Aでは「本人の過去の重要な意思決定」は長期に残すべきですが、雑談は消してよい。通し例Bでも、キャラの“お決まりの方針”は残すべきですが、相談者の個人情報は消すべきです。この線引きは技術というより設計要件であり、評価（第2章）と倫理（後の章）に接続して決めます。</p>
<hr>
<h2 id="76-矛盾・出典・安全参照できないことを「それっぽく語らない」">7.6 矛盾・出典・安全：参照できないことを「それっぽく語らない」</h2>
<p>人物らしさのシステムで最大の事故は、もっともらしく語ってしまうことです。第3章で見た偽記憶や出典混同は、人間にも起きますが、AIでは「流暢さ」によって被害が拡大します。第6章で述べたエピステミック・ヴィジランス（聞き手の警戒）をユーザー任せにしないためにも、システム側の設計が必要です。</p>
<h3 id="761-「出典つき主張」だけを許す主張と根拠の対応">7.6.1 「出典つき主張」だけを許す：主張と根拠の対応</h3>
<p>最小の安全策は、主張（claim）がどの記憶項目（evidence）に支えられているかを内部的に追跡することです。主張集合を $\mathcal{C}={c_j}$、根拠として参照した記憶項目集合を $\mathcal{E}\subseteq M$ とし、「主張 $c_j$ が根拠集合で支持されるか」を判定する関数を $\mathrm{Support}(c_j,\mathcal{E})\in{0,1}$ とすると、少なくとも</p>
<p>$$ \forall c_j\in\mathcal{C},\quad \mathrm{Support}(c_j,\mathcal{E})=1 $$</p>
<p>を満たさない主張は断言しない、という制約が設計できます。もちろん自然言語の支持判定は難しいのですが、「エピソードを語るときは必ず該当ログがある」「規程を語るときは必ず規程文書がある」というレベルでも大きな効果があります。これは「完全自動の真偽判定」ではなく「出典混同を防ぐ運用ルール」です。</p>
<h3 id="762-矛盾の扱い1つに決めつけない（仮説分布として持つ）">7.6.2 矛盾の扱い：1つに決めつけない（仮説分布として持つ）</h3>
<p>記憶ストアには矛盾が入り得ます。会議で方針が変わる、本人が以前と言うことを変える、架空キャラの設定が更新される、などです。矛盾を見つけたときに「どちらかが正しい」と即断すると、誤りの確率が上がります。ここで有効なのが、「仮説を分布として持つ」見方です。</p>
<p>例えばある命題 $p$ に対して、真である確率を $\pi=P(p=\text{true})$ として保持し、矛盾する証拠が出たら $\pi$ を更新します。最小にはベイズ更新で</p>
<p>$$ P(p\mid E)\propto P(E\mid p),P(p) $$</p>
<p>です。実務では尤度 $P(E\mid p)$ を厳密に置くのは難しいですが、「新しい公式文書が出たらその方を優先する」「本人が明確に訂正したら更新する」といったルールで近似できます。重要なのは、矛盾を発見したときに、AIが勝手に整合させて“それっぽい歴史”を捏造しないことです。矛盾は矛盾として提示し、必要なら確認を取る（修復）方が、人物らしさと信頼を守ります。</p>
<h3 id="763-実在人物と架空キャラで違う「許される創作」">7.6.3 実在人物と架空キャラで違う「許される創作」</h3>
<p>実在人物のデジタルツインでは、「本人の経験」を語ることは原則として根拠必須です。根拠のない“思い出語り”は捏造です。一方、架空キャラでは創作が価値になりますが、創作にもルールがあります。カノンに反する創作はキャラを壊しますし、過去の発言と整合しない“後付け設定”は違和感になります。したがって架空キャラの創作は、「未定義領域の補完」は許してよいが、「定義済み領域の改変」は許さない、といった境界を設ける必要があります。この境界も、記憶項目の種類（設定、対話ログ、推測）と確度で制御できます。</p>
<hr>
<h2 id="77-通し例A/Bへの適用同じ仕組みでも運用規則が違う">7.7 通し例A/Bへの適用：同じ仕組みでも運用規則が違う</h2>
<p>最後に、本章の設計を2つの通し例に接続します。ここでは擬似コードではなく、設計の「流れ」を文章で固定します。</p>
<h3 id="771-通し例ACEO/COO/CTO/CFOのデジタルツイン（会議シミュレーション）">7.7.1 通し例A：CEO/COO/CTO/CFOのデジタルツイン（会議シミュレーション）</h3>
<p>経営会議シミュレーションでは、会話は議題・決定・行動項目の更新（第6章）として進みます。したがって長期記憶の中心は「過去の決定」「各役員の主張とその根拠」「制約（資金、法務、技術）」「未解決の論点」です。これらはエピソード記憶として、時刻と出典（どの会議ログ、どの資料）を付けて保存します。</p>
<p>次に、会議の各ターンでクエリ $q_t$ を作るとき、単なる語の一致ではなく、「議題」と「論点」から作るのが重要です。たとえば議題が投資判断なら、クエリは「投資」「キャッシュ」「リスク」「技術負債」「実行計画」など複合になります。疎検索（BM25）は資料名や固有名詞を拾い、密検索（埋め込み）は言い換えを拾います。候補はMMRで多様化し、上位K件だけをコンテクストに入れます。</p>
<p>会議のリアリティを守るためには、検索で拾ったものをそのまま貼るのではなく、会話状態（共通基盤）に照らして必要部分だけを短く抜粋し、境界を明示して提示します。さらに、エピソードを語る発話（「前回こう言った」など）は、必ず出典付きの記憶項目からのみ許可する、という制約を入れます。もし出典が取れないなら、断言ではなく確認や保留に切り替える（修復）ことで、捏造事故を防ぎます。</p>
<p>最後に書き込みでは、会議で新たに確定した決定・条件・タスクだけを保存し、雑談や推測は確度を下げた別タイプとして保存します。反省（高次要約）は「傾向の仮説」として扱い、本人の内心や経験として語らないようにします。これにより、人物らしさ（意思決定の傾向）を保ちつつ、誤った“思い出”の生成を抑えられます。</p>
<p>この設計は、Generative Agents の「重要度・新しさ・関連度で検索し、反省で抽象記憶を作る」発想（Park et al., 2023）と整合しますが、実在人物では反省を慎重に扱う点が異なります。つまり、同じ仕組みでも運用規則が違うのです。</p>
<h3 id="772-通し例B社内で役に立つ架空キャラ">7.7.2 通し例B：社内で役に立つ架空キャラ</h3>
<p>社内キャラでは、「役に立つ」ことが目標であり、そのために必要なのは、制度や手順（意味記憶）と、相談者との過去のやり取り（エピソード）と、キャラの方針（手続き記憶）です。ここで最優先すべきは、相談者の個人情報や機密を不用意に保持しないこと、そして「過信（ELIZA効果）」を前提に、境界線を保つことです（Weizenbaum, 1966）。</p>
<p>検索の設計は、制度名や用語が強いので疎検索が効きます。言い換えも多いので密検索も併用します。重要なのは、検索結果をそのまま“権威”として断言しないことです。規程は出典を示し、確実な範囲だけを言い、曖昧なら確認を求める。これは第6章のエピステミック・スタンスの設計です。</p>
<p>記憶の書き込みでは、相談者の長期的な嗜好や学習進度（たとえば「図で説明すると理解しやすい」など）は有用ですが、センシティブな情報は保存しない、あるいは短期間で消す設計が必要です。架空キャラの魅力として「覚えてくれる」ことを狙う場合でも、何を覚えるかを慎重に選びます。ここで階層化と忘却が役に立ちます。個人名や詳細は残さず、「この人はこういう説明が合う」という上位概念だけを残す、といった要約は、役に立つ一方でリスクを抑えます。</p>
<p>架空キャラでは、未定義の設定を創作して補完したくなりますが、カノンを壊さない境界が必要です。設定タイプの記憶は確度を高くし、ユーザーの推測は確度を低く保持し、混ぜない。これにより、キャラの一貫性を保ちながら、必要な創作だけを許可できます。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしいAIを工学として成立させるために不可欠なコンテクスト工学と長期記憶管理を扱いました。コンテクストは作業記憶であり、長ければ良いのではなく、位置バイアスや冗長性を前提に情報価値密度を上げる必要があります。長期記憶は本文だけでなく、時刻・出典・種類・確度というメタデータを持ち、意味記憶・エピソード記憶・手続き記憶を混ぜないことが重要です。検索は疎検索（BM25）と密検索（埋め込み）を併用し、ハイブリッドと再ランキング、MMRによる多様性で安定性を上げます。圧縮と階層化は「目的に必要な情報だけを残す」という情報ボトルネックの直観で設計し、書き込み・統合・忘却は行為（コミットメント）の更新として設計すると、人物らしさと信頼性が両立しやすくなります。最後に、実在人物と架空キャラでは“許される創作”と“根拠の要求”が異なるため、同じ仕組みでも運用規則を変える必要があることを確認しました。</p>
<p>次の章では、ここで整えた「記憶とコンテクスト」の土台の上に、外部ツール（検索、データベース、計算、社内文書）を組み合わせて、計画→実行→観測→更新のループをどう設計するかを扱います。会話の社会性（第6章）と、記憶の参照規則（第7章）を保ったまま、現実世界に接続するための章になります。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Lewis, P., Perez, E., Piktus, A., et al. (2020). “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.” <a href="https://arxiv.org/abs/2005.11401" target="_blank">https://arxiv.org/abs/2005.11401</a>)</p>
<p>Karpukhin, V., Oguz, B., Min, S., et al. (2020). “Dense Passage Retrieval for Open-Domain Question Answering.” <a href="https://arxiv.org/abs/2004.04906" target="_blank">https://arxiv.org/abs/2004.04906</a>)</p>
<p>Johnson, J., Douze, M., & Jégou, H. (2017). “Billion-scale similarity search with GPUs.” <a href="https://arxiv.org/abs/1702.08734" target="_blank">https://arxiv.org/abs/1702.08734</a>)</p>
<p>Robertson, S., & Zaragoza, H. (2009). “The Probabilistic Relevance Framework: BM25 and Beyond.”（概説PDF） <a href="https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf" target="_blank">https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf</a>)</p>
<p>Carbonell, J., & Goldstein, J. (1998). “The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries.” <a href="https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf" target="_blank">https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf</a>)</p>
<p>Liu, N. F., Lin, K., Hewitt, J., et al. (2023/2024). “Lost in the Middle: How Language Models Use Long Contexts.” <a href="https://arxiv.org/abs/2307.03172" target="_blank">https://arxiv.org/abs/2307.03172</a>)</p>
<p>Packer, C., Fang, V., Patil, S. G., et al. (2023). “MemGPT: Towards LLMs as Operating Systems.” <a href="https://arxiv.org/abs/2310.08560" target="_blank">https://arxiv.org/abs/2310.08560</a>)</p>
<p>Park, J. S., O’Brien, J., Cai, C. J., et al. (2023). “Generative Agents: Interactive Simulacra of Human Behavior.” <a href="https://arxiv.org/abs/2304.03442" target="_blank">https://arxiv.org/abs/2304.03442</a>)</p>
<p>Tishby, N., Pereira, F. C., & Bialek, W. (2000). “The Information Bottleneck Method.” <a href="https://arxiv.org/abs/physics/0004057" target="_blank">https://arxiv.org/abs/physics/0004057</a>)</p>
<p>Johnson, M. K., Hashtroudi, S., & Lindsay, D. S. (1993). “Source monitoring.” *Psychological Bulletin*. <a href="https://doi.org/10.1037/0033-2909.114.1.3" target="_blank">https://doi.org/10.1037/0033-2909.114.1.3</a>)</p>
<p>Weizenbaum, J. (1966). “ELIZA—A Computer Program for the Study of Natural Language Communication between Man and Machine.” <a href="https://doi.org/10.1145/365153.365168" target="_blank">https://doi.org/10.1145/365153.365168</a>)</p>
<h1 id="第8章-ツール利用とエージェントループ検索・計算・実行・安全境界">第8章　ツール利用とエージェントループ：検索・計算・実行・安全境界</h1>
<p>第7章では、コンテクスト（そのターンでモデルに与える入力）を「作業記憶」として設計し、長期記憶を外部ストアとして管理することで、人物らしさの長期一貫性を作る方法を学びました。しかし、人物らしいAIを現実の用途に近づけようとすると、もう一つの壁に必ず当たります。それは、モデルが自分の内部だけで完結できない種類のタスク――最新情報の参照、社内データベースの照会、数値計算、文書の検証、シミュレーション実行など――を、どう扱うかという問題です。</p>
<p>この章では、その壁を越えるための基本技術として、<strong>ツール利用（tool use）</strong> と <strong>エージェントループ（agent loop）</strong> を扱います。ここでいうツールとは、検索エンジン、データベース、計算機、コード実行環境、社内文書検索、カレンダーやチケットシステムなど、「外部の機能」を指します。エージェントループとは、モデルが「いま答える」だけでなく、「必要なら調べる・計算する・確認する」などの行為を繰り返し、観測を増やしてから判断を固めるための制御構造です。</p>
<p>本章の狙いは、ツール利用を“便利機能”ではなく、人物らしさと信頼性の中核として理解することです。実在人物のデジタルツイン（通し例A）では、根拠のない断言や「本人の経験」の捏造が致命傷になります。そこで、答えの根拠を外部の記録（会議議事録、社内資料、決裁文書など）に固定し、参照できないことを「分からない」と言える設計が重要です。架空キャラ（通し例B）でも、社内で役に立つには制度や手順の正確さが必要で、同時に過信（ELIZA効果）を前提に境界線を守らなければなりません。ツール利用は、これらを両立するための実務上の“骨格”になります。</p>
<p>本章は、まず 8.1 でツールを使う理由と分類を整理し、8.2 でエージェントを数式（確率過程と最適化）として捉える最小モデルを作ります。8.3 でループ設計（いつツールを呼び、いつ質問し、いつ止めるか）を、期待効用と情報価値で定式化します。8.4 でツール呼び出しのインターフェース（関数・スキーマ・入出力契約）を設計し、8.5 で検証と根拠付け、8.6 でセキュリティと安全境界、8.7 で失敗検知と回復を扱います。最後に 8.8 で通し例A/Bへ接続します。</p>
<hr>
<h2 id="81-なぜツールが必要か生成は強いが観測はできない">8.1 なぜツールが必要か：生成は強いが、観測はできない</h2>
<h3 id="811-大規模言語モデルの強みと限界を「役割分担」として捉える">8.1.1 大規模言語モデルの強みと限界を「役割分担」として捉える</h3>
<p>大規模言語モデル（Large Language Model: LLM）は、与えられたコンテクストの中で「もっともらしい」文章を生成する能力が高く、要約、説明、推論、計画の文章化などに強みがあります。一方で、LLMは本質的に「観測装置」ではありません。最新の情報を自動で取得できるわけでもなく、社内データベースの中身を直接見ることもできません。さらに、計算が苦手な場合があり、また“それっぽい補完”をしてしまう危険（第3章の偽記憶や第6章の信頼問題）があります。</p>
<p>このため、人物らしいAIの設計では、LLMを万能の頭脳として扱うのではなく、<strong>自然言語の統合器（オーケストレーター）</strong>として扱い、観測や計算はツールに任せ、LLMはそれらを統合して意思決定や説明を行う、という役割分担が安定します。これを研究として体系化した流れの一つが、検索と生成を組み合わせる検索拡張生成（Retrieval-Augmented Generation: RAG）です（Lewis et al., 2020  <a href="https://arxiv.org/abs/2005.11401" target="_blank">https://arxiv.org/abs/2005.11401</a> ）。また、ブラウザを使って情報を調べながら回答する枠組みとして WebGPT が提案されました（Nakano et al., 2021 “WebGPT: Browser-assisted question-answering with human feedback”  <a href="https://arxiv.org/abs/2112.09332" target="_blank">https://arxiv.org/abs/2112.09332</a> ）。これらは「モデル単体」から「モデル＋ツール」へ発想を移す代表例です。</p>
<h3 id="812-ツールの分類検索・参照・計算・実行・更新">8.1.2 ツールの分類：検索・参照・計算・実行・更新</h3>
<p>ツールを設計の対象として捉えるには、まず「ツールには種類がある」ことを明確にします。ここでは、機能の性質で次の5種類に分けます。</p>
<p>第一に <strong>検索（search）</strong> です。社内文書検索やウェブ検索など、クエリに応じて関連文書や断片を返します。これは第7章の検索・記憶参照と強く結びつきます。</p>
<p>第二に <strong>参照（lookup）</strong> です。データベースや台帳、規程の条文など、特定のキーで確定的な値を取り出します。検索が「関連候補」を返すのに対して、参照は「これを見ろ」という一意な結果を返すことが多い点が違います。</p>
<p>第三に <strong>計算（compute）</strong> です。数式計算、集計、最適化、シミュレーションなど、入力に対して決まった計算結果を返します。ここは「文章生成」と機能的に分離した方が事故が少なくなります。数値推論をプログラムに委譲する研究として、Program-Aided Language Models（PAL）が提案されています（Gao et al., 2022 “PAL: Program-aided Language Models”  <a href="https://arxiv.org/abs/2211.10435" target="_blank">https://arxiv.org/abs/2211.10435</a> ）。また、数値推論を“プログラム”として書き出して実行する発想は Program-of-Thoughts Prompting としても提案されています（Chen et al., 2022  <a href="https://arxiv.org/abs/2211.12588" target="_blank">https://arxiv.org/abs/2211.12588</a> ）。</p>
<p>第四に <strong>実行（actuation / execution）</strong> です。チケットを作る、会議を予約する、メールの下書きを作る、社内システムを更新する、といった「世界を変える操作」です。人物らしいAIは、ここで最も危険になります。なぜなら“それっぽい”判断で世界を変えると、取り返しがつかないからです。実行系ツールは、必ず安全境界（8.6）と確認手順（8.3）を設計に入れる必要があります。</p>
<p>第五に <strong>更新（write / store）</strong> です。長期記憶ストアへの書き込み、会話状態の更新、要約の保存などです。これは第7章の記憶管理に対応し、ツールとして扱うと「書き込み規則」を明確にできます。</p>
<p>これらを分ける理由は、単に整理のためではありません。失敗モード（8.7）が種類ごとに違うからです。検索は取りこぼし・ノイズが問題になり、参照はキーの誤りが問題になり、計算は入力の単位や前提が問題になり、実行は権限と確認が問題になり、更新は“何を記憶として固定するか”が問題になります。ツールの種類を混ぜると、失敗検知が難しくなります。</p>
<hr>
<h2 id="82-エージェントとしての定式化会話＋ツール利用を「意思決定過程」として書く">8.2 エージェントとしての定式化：会話＋ツール利用を「意思決定過程」として書く</h2>
<p>ツール利用を行うAIは、単なるテキスト生成器ではなく、環境から観測を得て行動を選ぶ <strong>エージェント（agent）</strong> として捉えるのが自然です。ここで「エージェント」という言葉は、SF的な人格ではなく、数理的に「観測→行動→観測→…」を繰り返す意思決定システムを意味します。</p>
<h3 id="821-部分観測マルコフ決定過程（POMDP）という最小モデル">8.2.1 部分観測マルコフ決定過程（POMDP）という最小モデル</h3>
<p>環境の真の状態を $s_t$、時刻 $t$ の観測を $o_t$、行動を $a_t$ とします。会話では、観測 $o_t$ は「ユーザーの発話」や「ツールの出力」です。行動 $a_t$ は「ユーザーへ返答する」か「ツールを呼び出す」などです。環境は、状態遷移 $P(s_{t+1}\mid s_t,a_t)$ に従って変化し、観測 $P(o_t\mid s_t)$ が得られる、とします。</p>
<p>この枠組みは <strong>部分観測マルコフ決定過程（Partially Observable Markov Decision Process: POMDP）</strong> と呼ばれます。重要なのは、エージェントは $s_t$ を直接見られず、観測履歴から信念（belief） $b_t(s)=P(s_t=s \mid o_{\le t}, a_{<t})$ を持つという点です。</p>
<p>人物らしいAIでは、$s_t$ には「会話の論点」「合意済みの共通基盤（第6章）」「ユーザーの意図」「参照すべき社内状況」などが含まれますが、全てが観測できるわけではありません。したがって信念 $b_t$ を“1つの断定”に潰さず、不確実性を残す設計が重要になります（第3章のベイズ的見方と一致します）。</p>
<h3 id="822-目的関数正しさ・人物らしさ・コストの同時最適化">8.2.2 目的関数：正しさ・人物らしさ・コストの同時最適化</h3>
<p>エージェントは「何を良いとするか」を目的関数で定めます。ここでは報酬 $R(s_t,a_t)$ を「有用性」「正確性」「人物らしさ」「安全性」などをまとめたスカラーとして置き、さらにツール利用や長い会話のコストを $C(a_t)$ として引きます。割引率 (\gamma\in$0,1]$ を用いると、最適化は</p>
<p>$$ \max_{\pi}\ \mathbb{E}\left[\sum_{t=0}^{T}\gamma^t\left(R(s_t,a_t)-C(a_t)\right)\right],\quad a_t\sim\pi(\cdot\mid h_t)$$ と書けます。$h_t$ は履歴（観測と行動の列）です。ここで重要なのは、ツール呼び出しは無料ではないという点です。計算資源やレイテンシ（待ち時間）、API料金、社内システムへの負荷、さらには情報漏えいリスクといったコストが存在します。人物らしさのAIは、必要以上にツールを叩き続けるとユーザー体験が悪化し、また攻撃面も増えます。したがって「いつツールを使い、いつ止めるか」は目的関数の中に置くべき問題になります。</p>
<hr>
<h2 id="83-エージェントループ設計いつ調べいつ質問しいつ止めるか">8.3 エージェントループ設計：いつ調べ、いつ質問し、いつ止めるか</h2>
<p>この節では、具体的なループの形を扱います。よく知られた直観的なループは「計画→実行→観測→反省（改善）」ですが、重要なのはループ名ではなく、ループが <strong>不確実性を減らすための行為</strong> として機能することです。</p>
<h3 id="831-ReAct推論と行為を交互に行う">8.3.1 ReAct：推論と行為を交互に行う</h3>
<p>ツール利用を伴う推論の代表的枠組みとして、ReAct が提案されています。ReAct は、推論（Reason）と行為（Act）を交互に行い、ツールや環境から観測を得ながら最終回答へ近づく方法です（Yao et al., 2022 “ReAct: Synergizing Reasoning and Acting in Language Models”  <a href="https://arxiv.org/abs/2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a> ）。</p>
<p>ReActの重要点は、推論を“長い独り言”として完結させるのではなく、外部観測で確かめながら進める点です。人物らしいAIでは、これがそのまま「根拠を増やし、捏造を減らす」ことにつながります。特に実在人物のデジタルツインでは、本人の過去の発言や意思決定は、外部ログ（会議議事録）で確かめるべきで、モデル内の連想で補完すべきではありません。ReAct的なループは、その姿勢を設計として固定できます。</p>
<h3 id="832-期待情報価値（EVI）ツール呼び出しは「投資」なので元が取れるときだけ行う">8.3.2 期待情報価値（EVI）：ツール呼び出しは「投資」なので元が取れるときだけ行う</h3>
<p>「いつツールを呼ぶか」を数式で扱う最短ルートは、<strong>期待情報価値（Expected Value of Information: EVI）</strong> の考え方です。ある不確実な変数を $Z$（例えば「最新のキャッシュ残高」「社内規程の該当条文」「過去会議での決定」）とし、いま答えを出す行動を $a\in\mathcal{A}$ とします。行動の価値を (V(a,Z)) とすると、ツールを呼ばずに最適行動を選ぶ価値は</p>
<p>$$U_{\text{now}} = \max_{a\in\mathcal{A}}\ \mathbb{E}[V(a,Z)$$ です。ここで期待値は現在の信念 (P$Z$) によります。</p>
<p>ツールを呼ぶと観測 $Y$（例えば検索結果やDB結果）が得られ、信念が更新されます。更新後に最適行動を選ぶ価値の期待は</p>
<p>$$U_{\text{after}}=\mathbb{E}_{Y}\left[\max_{a\in\mathcal{A}}\ \mathbb{E}[V(a,Z)\mid Y]\right]$$ です。ツール呼び出しコストを $c_{\text{tool}}$ とすると、期待情報価値は</p>
<p>$$ \mathrm{EVI}=U_{\text{after}}-U_{\text{now}}-c_{\text{tool}} $$</p>
<p>となり、$\mathrm{EVI}>0$ のときにツールを呼ぶのが合理的、という判断になります。</p>
<p>この式は難しく見えますが、直観は単純です。「調べることで判断が変わりそうで、その変化が価値に効きそうなときだけ調べる」です。経営会議（通し例A）では、投資判断のように価値が大きく揺れる決定では $\mathrm{EVI}$ が大きくなりやすいので、財務データやリスク情報をツールで確認する価値が高い。一方、雑談や一般論の説明では $\mathrm{EVI}$ が小さいので、毎回検索する必要はありません。社内キャラ（通し例B）でも、制度の根拠が必要なとき（誤ると事故）にはツール参照の価値が高く、一般的な励ましや相談整理では価値が小さくなりやすい、という設計ができます。</p>
<h3 id="833-「質問する」か「ツールを呼ぶ」か観測源の選択">8.3.3 「質問する」か「ツールを呼ぶ」か：観測源の選択</h3>
<p>不確実性を減らす方法はツールだけではありません。ユーザーに追加質問をするのも観測です。したがって、設計上は「ツール呼び出し」と「追加質問」を同じ枠で比較できます。追加質問のコスト $c_{\text{ask}}$ は、ユーザーの負担や離脱リスクとして表現できます。ツールは速いが誤検索やセキュリティのコストがある一方、ユーザー質問は正確だが負担がある、といったトレードオフがあります。</p>
<p>この選択も、EVIの式の「観測 $Y$」を「ツール出力」または「ユーザー回答」に置き換えれば同じです。重要なのは、質問が多すぎると会話体験が壊れ、ツールが多すぎるとコストと攻撃面が増える、という現実的制約を目的関数に入れておくことです。</p>
<h3 id="834-ループを回しすぎない停止条件収穫逓減と安全停止">8.3.4 ループを回しすぎない停止条件：収穫逓減と安全停止</h3>
<p>実務では、ループは回せば回すほど良くなるわけではありません。観測を増やすほど確かに不確実性は減りますが、同時にコストが増えます。そこで停止条件が必要になります。</p>
<p>停止条件を設計する最も単純な方法は、「これ以上観測しても期待改善が小さい」と判断したら止めることです。式で書けば、次の一手（ツール or 質問）の $\mathrm{EVI}$ が閾値 $\epsilon$ を下回ったら停止、というルールです：</p>
<p>$$ \max(\mathrm{EVI}_{\text{tool}}, \mathrm{EVI}_{\text{ask}})\le \epsilon \ \Rightarrow\ \text{停止して回答} $$</p>
<p>もう一つ重要なのが安全停止です。ツール出力が矛盾している、権限が足りない、入力が不正の疑いがある、といった場合は、ループを続けるより「できる範囲の安全な提案」に切り替える方が良いことがあります。これは第6章の礼儀や信頼にも関係し、ユーザーに理由を説明しつつ、次に何をすれば前に進むかを示す設計が必要です。</p>
<hr>
<h2 id="84-ツール呼び出しインターフェース関数・スキーマ・監査可能性">8.4 ツール呼び出しインターフェース：関数・スキーマ・監査可能性</h2>
<p>ツール利用の事故の多くは、モデルが「曖昧な自然言語」でツールを使おうとし、入力や出力の解釈がズレることから起きます。そこで、ツール呼び出しは原則として <strong>関数（function）</strong> として定義し、入力と出力の形式を明確にします。</p>
<h3 id="841-ツールを関数として扱う型つき写像">8.4.1 ツールを関数として扱う：型つき写像</h3>
<p>ツール $T_j$ を、入力空間 $\mathcal{X}_j$ から出力空間 $\mathcal{Y}_j$ への写像</p>
<p>$$ T_j:\mathcal{X}_j\to \mathcal{Y}_j $$</p>
<p>として扱います。例えば社内文書検索なら $\mathcal{X}$ はクエリ文字列で、$\mathcal{Y}$ は文書断片の集合です。計算ツールなら $\mathcal{X}$ は数値パラメータで、$\mathcal{Y}$ は計算結果です。重要なのは、$\mathcal{X}$ と $\mathcal{Y}$ を曖昧な自然言語ではなく、型（データ構造）で定めることです。</p>
<p>型があると、入力検証（validation）ができます。入力が型を満たさなければツールは実行しない、という“硬い境界”が作れます。これは安全（8.6）にも直結します。</p>
<h3 id="842-スキーマJSONによる入出力契約">8.4.2 スキーマ：JSONによる入出力契約</h3>
<p>スキーマ（schema）とは、データの構造と制約を明示する仕様です。多くの実装では JSON（JavaScript Object Notation）形式を用いて、ツール引数と結果を構造化します。例えば「社内文書検索」ツールを、入力として `query` と `top_k` を受け取る関数として定義し、出力として `results`（文書ID、抜粋、スコア）を返す、という形です。</p>
<p>ここで重要なのは、スキーマは“便利な形式”ではなく、<strong>監査可能性（auditability）</strong>を生むという点です。誰が、いつ、どのクエリで、どの結果を参照し、その結果に基づいてどんな発話をしたかがログとして残ると、後で検証できます。実在人物のデジタルツインでは「どの議事録のどの箇所に基づいてこの発言をしたか」が重要になりますし、社内キャラでも「どの規程に基づいてこの説明をしたか」が重要になります。スキーマはこの追跡可能性を支える部品です。</p>
<h3 id="843-再試行・冪等性・レート制限現実のツールは壊れる">8.4.3 再試行・冪等性・レート制限：現実のツールは壊れる</h3>
<p>ツールは失敗します。ネットワークエラー、タイムアウト、権限不足、入力エラー、サービス障害などが起きます。ここで重要なのが、再試行（retry）と冪等性（idempotency）です。冪等性とは、同じ操作を何度繰り返しても結果が変わらない性質を指します。検索や参照は冪等であることが多いので再試行しやすい。一方、実行（チケット作成など）は冪等でないことがあり、安易に再試行すると二重実行になります。したがって、ツールごとに「再試行してよい操作か」を定義し、実行系は一意なリクエストIDで重複を防ぐ、といった設計が必要です。</p>
<p>また、レート制限（rate limiting）やキャッシュ（cache）も、ツール利用の品質と安全を左右します。無制限に検索するとコストが爆発し、攻撃にも弱くなります。キャッシュは同じ質問への繰り返しツール呼び出しを減らしますが、最新性が必要な情報ではキャッシュが危険になります。第7章の新しさ（recency）と同様に、ツール出力にも有効期限（Time To Live: TTL）を設ける設計が重要です。</p>
<hr>
<h2 id="85-検証と根拠付けツール利用の目的は「事実を増やす」ことである">8.5 検証と根拠付け：ツール利用の目的は「事実を増やす」ことである</h2>
<p>ツールを使う最大の理由は、生成の流暢さを上げることではなく、<strong>根拠を増やし、誤りを減らす</strong>ことです。この節では、根拠付け（grounding）の考え方を整理します。</p>
<h3 id="851-参照と生成を分離する証拠集合を明示する">8.5.1 参照と生成を分離する：証拠集合を明示する</h3>
<p>人物らしいAIの事故の多くは、「生成された文」と「参照した根拠」が混線することから起きます。第3章の出典混同、第6章の信頼問題と同型です。そこで、設計としては「何を参照したか」を内部状態として明示的に保持し、その集合の外側の主張は断言しない、という原則が有効です。</p>
<p>形式的には、時刻 $t$ に参照した証拠集合を $\mathcal{E}_t\subseteq M$ とし、出力に含まれる主張集合を $\mathcal{C}_t$ とします。理想的には、各主張 $c\in\mathcal{C}_t$ に対し、それを支持する証拠が存在する（支持関係が成り立つ）ことを要求します：</p>
<p>$$ \forall c\in\mathcal{C}_t,\ \exists e\in\mathcal{E}_t \text{ s.t. } e \Rightarrow c $$</p>
<p>ここで $e\Rightarrow c$ は「証拠 $e$ が主張 $c$ を含意する」ことを表す記号的表現で、実装上は自然言語推論（Natural Language Inference: NLI）のモデルなどで近似することになります。重要なのは、完全自動の真偽判定を目指すのではなく、<strong>少なくとも“参照ゼロの断言”を減らす</strong>という運用ルールとして導入することです。</p>
<h3 id="852-交差検証単一ソースに依存しない">8.5.2 交差検証：単一ソースに依存しない</h3>
<p>検索はノイズを含みます。社内文書も古い版が混ざることがあります。そこで、重要な主張ほど複数ソースでの交差検証が有効になります。これは「多数決で真実を決める」ことではなく、「同じ主張が独立した出典から支持されるか」を確認することです。</p>
<p>WebGPT（Nakano et al., 2021）は、ブラウザでの参照と引用を通じて、根拠を伴う回答を学習する流れを提示しました。より一般に、検索→引用→統合という流れは、人物らしさのAIでも強い基本形になります。実在人物ツインなら「議事録A」と「決裁文書B」が一致しているか、社内キャラなら「規程本文」と「FAQ」が一致しているか、といった形で交差検証します。</p>
<h3 id="853-計算の外部化数値はプログラムに任せる">8.5.3 計算の外部化：数値はプログラムに任せる</h3>
<p>数値計算は、文章生成よりもプログラムの方が確実です。PAL（Gao et al., 2022）や Program-of-Thoughts（Chen et al., 2022）は、推論の一部をプログラムとして実行し、結果を利用することで、数値推論の正確性を高める発想を示しています。</p>
<p>経営会議シミュレーション（通し例A）では、資金繰りや売上予測、損益分岐点などを“文章で計算”すると事故が起きやすい。したがって、LLMは「どの式で何を計算すべきか」を提案し、計算そのものは計算ツールが行い、LLMはその結果を解釈して意思決定に結びつける、という分業が重要です。社内キャラでも同様で、例えば「何日後が締め切りか」といった日付計算は計算ツールに任せた方が安全です。</p>
<hr>
<h2 id="86-セキュリティと安全境界ツールは「攻撃面」を増やす">8.6 セキュリティと安全境界：ツールは「攻撃面」を増やす</h2>
<p>ツール利用は便利ですが、同時に攻撃面（attack surface）を増やします。特に「検索（外部テキストを取り込む）」と「実行（世界を変える）」は、設計を誤ると重大事故になります。この節では、古典的セキュリティ原則を土台に、ツール利用に固有の注意点を整理します。</p>
<h3 id="861-最小権限の原則Saltzer-&-Schroeder">8.6.1 最小権限の原則：Saltzer & Schroeder</h3>
<p>セキュリティ設計の古典として、Saltzer と Schroeder は情報保護の設計原則をまとめました。その中でも特に重要なのが <strong>最小権限の原則（Principle of Least Privilege）</strong> です。これは「各モジュールやユーザーは、必要最小限の権限だけを持つべきだ」という原則です（Saltzer & Schroeder, 1975 “The Protection of Information in Computer Systems”  <a href="https://doi.org/10.1145/361011.361067" target="_blank">https://doi.org/10.1145/361011.361067</a> ）。</p>
<p>ツール利用にこの原則を適用すると、次が設計要件になります。検索ツールは読み取りだけにし、更新系ツール（チケット作成など）は対象範囲を限定し、さらに高リスク操作には人間の確認を要求する。実在人物のデジタルツインでは、本人の名義での実行（送信や承認）は原則として許可しない、あるいは厳格な承認フローに置くべきです。社内キャラでも、社内システムの更新権限を与えるなら、業務上必要な範囲に限定し、ログと監査を必須にします。</p>
<h3 id="862-プロンプト注入（prompt-injection）と間接注入ツール出力は“敵対的”になり得る">8.6.2 プロンプト注入（prompt injection）と間接注入：ツール出力は“敵対的”になり得る</h3>
<p>ツール利用が増えると、モデルは外部テキスト（ウェブページ、文書、メール本文など）を取り込みます。ここに「指示文」が紛れ込むと、モデルが本来従うべき方針より、その指示に引っ張られる危険があります。これは一般にプロンプト注入（prompt injection）と呼ばれ、特に「検索で取り込んだページに攻撃指示が書かれている」形は間接注入（indirect injection）として問題になります。</p>
<p>学術的には、敵対的プロンプトがモデルの振る舞いを崩す研究として、整列済みモデルに対する普遍的攻撃が議論されています（Zou et al., 2023 “Universal and Transferable Adversarial Attacks on Aligned Language Models”  <a href="https://arxiv.org/abs/2307.15043" target="_blank">https://arxiv.org/abs/2307.15043</a> ）。ここでの重要点は、「外部テキストは信頼できない」という前提を設計に埋め込むことです。つまり、ツール出力は「事実の材料」であって「命令」ではない、と明確に区別し、命令として解釈しない防壁が必要です。</p>
<p>この防壁は、単に「無視して」と書くことではありません。設計としては、ツール出力を「引用ブロック」として扱い、そこに書かれた指示を“データ”として処理し、行動方針を書き換える入力として扱わない、という境界設計が必要です。さらに、実行系ツールの前には「ツール出力由来の指示が混ざっていないか」を検査する工程を入れるべきです。</p>
<h3 id="863-実行系ツールの安全確認サンドボックス監査ログ">8.6.3 実行系ツールの安全：確認、サンドボックス、監査ログ</h3>
<p>実行系ツールは、事故の影響が大きいので設計を分けます。最小限必要なのは次の3点です。</p>
<p>第一に確認です。重要な実行（送信、承認、更新）は、ユーザーに最終確認を求める設計にします。これは“人間の判断に戻す”という意味であり、人物らしさを壊すものではありません。むしろ、現実のCEOやCFOも重要な実行は確認します。</p>
<p>第二にサンドボックス（sandbox）です。コード実行や外部アクセスを伴うツールは隔離環境で動かし、ファイルやネットワークへのアクセスを制限します。これも最小権限の原則の具体化です。</p>
<p>第三に監査ログです。いつ誰が何を実行したかを残し、事後に追跡できるようにします。人物らしいAIでは「誰の名義で何をしたか」が社会的に重要になるため、ログは技術要件ではなく組織要件です。</p>
<hr>
<h2 id="87-失敗検知と回復ツールがあっても失敗するので失敗を前提にする">8.7 失敗検知と回復：ツールがあっても失敗するので、失敗を前提にする</h2>
<p>ツール利用とエージェントループは万能ではありません。検索は誤るし、文書は古いし、計算は前提がズレるし、ユーザーは誤解するし、モデルは統合を誤ります。したがって重要なのは、失敗をゼロにすることではなく、<strong>失敗を検知し、被害を小さくし、回復する</strong>ことです。</p>
<h3 id="871-失敗の分類検索失敗・統合失敗・表現失敗・実行失敗">8.7.1 失敗の分類：検索失敗・統合失敗・表現失敗・実行失敗</h3>
<p>失敗を設計対象にするには、まず分類します。検索失敗は「必要な根拠が取れない」「ノイズばかり取れる」「古い版を取る」などです。統合失敗は「根拠を誤解して結論を誤る」「複数根拠の矛盾を解消できず断言する」などです。表現失敗は第6章の語用論に関係し、「正しいが失礼」「曖昧すぎる」「約束してはいけないのに約束する」などです。実行失敗は「誤った更新」「二重実行」「権限外の操作」などです。</p>
<p>分類の目的は、検知方法が異なるからです。検索失敗はスコア分布や多様性、参照ゼロなどで検知でき、統合失敗は矛盾検知や根拠支持検査で検知でき、表現失敗は発話行為の条件（第6章）で検知でき、実行失敗は冪等性と確認フローで検知できます。</p>
<h3 id="872-ルールベース検知と検査役モデル二重化する">8.7.2 ルールベース検知と検査役モデル：二重化する</h3>
<p>最小の検知はルールベースで構いません。例えば「参照した根拠が空なら断言しない」「根拠が1件に偏っているなら追加検索する」「実行系ツールの前は必ず確認を入れる」などです。</p>
<p>しかし、自然言語の矛盾や支持関係はルールだけでは難しいので、追加で「検査役モデル」を置く設計が有効です。検査役モデルは、生成した主張と根拠を入力として「この主張は根拠から言えるか」「矛盾していないか」を判定します。これは一種の自然言語推論（NLI）であり、後の章で扱う評価の自動化とも結びつきます。</p>
<p>この「生成役と検査役の分離」は、会話の信頼性を上げる基本設計です。第6章で述べたように、会話は信頼の更新過程でもあるので、検査役があることで過度な断言が減り、信頼の破綻を防ぎやすくなります。</p>
<h3 id="873-自己一貫性（self-consistency）と多案生成推論の不確実性を露出させる">8.7.3 自己一貫性（self-consistency）と多案生成：推論の不確実性を露出させる</h3>
<p>推論の失敗を減らす一つの方法は、単一の生成に依存しないことです。Wang らは、推論問題において複数の推論経路をサンプリングし、最終回答を多数派で選ぶ「自己一貫性（self-consistency）」を提案しました（Wang et al., 2022 “Self-Consistency Improves Chain of Thought Reasoning in Language Models”  <a href="https://arxiv.org/abs/2203.11171" target="_blank">https://arxiv.org/abs/2203.11171</a> ）。これは厳密な正しさ保証ではありませんが、「一回の偶然の誤り」を減らす効果があります。</p>
<p>人物らしいAIでは、多案生成はそのまま“人格が揺れる”危険もあります。そこで、多案生成は「最終出力の揺れ」ではなく、「内部で候補を比較し、根拠の整合性が高いものを選ぶ」用途に寄せるのが安定します。つまり、ユーザーに複数案を投げるのではなく、内部で自己検査に使う、という設計です。</p>
<h3 id="874-反省（reflection）と改善ループ学習ではなく運用としての改善">8.7.4 反省（reflection）と改善ループ：学習ではなく運用としての改善</h3>
<p>ツール利用型エージェントでは、失敗を“次の行動改善”に活かすループも重要です。Reflexion は、試行の結果を言語的フィードバックとして蓄積し、次の試行に活かす枠組みを提案しました（Shinn et al., 2023 “Reflexion: Language Agents with Verbal Reinforcement Learning”  <a href="https://arxiv.org/abs/2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a> ）。また、自己修正の枠組みとして Self-Refine も提案されています（Madaan et al., 2023 “Self-Refine: Iterative Refinement with Self-Feedback”  <a href="https://arxiv.org/abs/2303.17651" target="_blank">https://arxiv.org/abs/2303.17651</a> ）。</p>
<p>ここで重要なのは、これらは「勝手に人格が変わる」学習ではなく、運用としての改善だという点です。実在人物のデジタルツインでは、運用中に人格がドリフトすると本人らしさが壊れるので、改善の対象は「検索精度」「根拠提示」「確認質問の上手さ」などの周辺機能に限定するのが安全です。架空キャラでは、改善を積極的に使う余地がありますが、それでもカノンを壊す更新は許さない、という境界が必要です（第7章の記憶タイプ分離と同じ発想です）。</p>
<hr>
<h2 id="88-通し例A/Bツール利用が「会議らしさ」と「社内で役立つ」を支える">8.8 通し例A/B：ツール利用が「会議らしさ」と「社内で役立つ」を支える</h2>
<h3 id="881-通し例ACEO/COO/CTO/CFOの経営会議シミュレーション">8.8.1 通し例A：CEO/COO/CTO/CFOの経営会議シミュレーション</h3>
<p>経営会議シミュレーションを、ツール利用の観点で具体化します。会議で扱う論点は「投資」「採用」「価格」「技術負債」「資金繰り」「法務リスク」など多岐にわたります。ここで人物らしさを作る鍵は、役職ごとに“観測したいもの”が違うことです。</p>
<p>CFOは、キャッシュ残高、資金繰り表、最悪ケースの耐性などを参照ツールで確認したい。CTOは、障害ログ、技術負債の指標、開発リソースの見積もりを参照・計算ツールで確認したい。COOは、実行計画のガントや人員配置を参照したい。CEOは、これらを統合し、議題に応じて「何を追加観測すべきか」を判断したい。</p>
<p>このとき、エージェントループは次のように働きます。議題が提示されると、まず「意思決定が変わりそうな不確実性は何か」を明確化します。これは EVI の $Z$ を定める作業です。次に、$\mathrm{EVI}>0$ と見積もられる情報についてツールを呼び、観測 $Y$ を得て信念を更新します。観測が揃ったら、意思決定モデル（第4章）に基づいて案を比較し、根拠の出典（どの文書、どの数字）を保持したまま、会議としての発話行為（提案、条件提示、合意、宿題化）へ落とします（第6章）。</p>
<p>この流れが「会議らしさ」を生む理由は、会議が本質的に“観測と合意の更新”だからです。ツールで観測し、議題を更新し、合意を確定し、タスクを割り当てる。AIがそれを再現できると、単なる雑談生成ではなく「意思決定の場」としてのリアリティが出ます。</p>
<p>重要なのは、実行系ツール（実際に予算を承認する、発注するなど）をこの段階で自動化しないことです。デジタルツインは「会議の議論」を模倣するのが目的であり、実行権限まで与えると、誤りのコストが跳ね上がります。最小権限の原則に従い、実行は人間の承認フローに残すのが現実的です。</p>
<h3 id="882-通し例B社内で役に立つ架空キャラ">8.8.2 通し例B：社内で役に立つ架空キャラ</h3>
<p>社内キャラは、相談者の状況を整理し、制度や手順を正確に案内し、次の一歩を具体化することが価値です。ここでツール利用は「正確性」と「信頼の維持」に直結します。</p>
<p>例えば制度の質問が来たとき、キャラはまず「制度名と適用範囲」を確認します。曖昧なら追加質問（観測）をし、明確なら規程の参照ツールで該当条文を引きます。ここで重要なのは、引いた条文をそのまま貼るのではなく、相談者の状況に合わせて要点を説明し、必要なら例外条件や手続きの順番を整理することです。これはLLMが得意な統合作業です。ただし、説明が規程から逸脱しないよう、根拠ブロックと説明ブロックを分離しておくと安全です（8.5）。</p>
<p>また、社内キャラがチケット作成などの実行系ツールを使う場合は、特に確認が重要です。相談者の入力には誤りがあり得るし、悪意もあり得ます。したがって、実行前に「作成するチケットの要約」「対象部署」「期限」「機密の有無」を明示し、ユーザーが確認できる形にしてから実行する設計にします。これにより、ELIZA効果による過信のリスクも下げられます。「AIが勝手にやった」ではなく、「ユーザーが確認して進めた」にできるからです。</p>
<p>架空キャラは人格的魅力を持ち得ますが、その魅力が強いほど境界線が重要です。共感的な言葉（第5章）と、根拠に基づく案内（第8章）が両立して初めて、「役に立つが依存させない」社内キャラになります。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしいAIを現実の用途に耐える形にするために、ツール利用とエージェントループを体系化しました。ツールは検索・参照・計算・実行・更新に分けて設計し、LLMはそれらを統合する役割に置くと安定します。エージェントはPOMDPとして定式化でき、ツール呼び出しや追加質問は期待情報価値（EVI）で「投資として元が取れるときだけ行う」と考えると、ループを回しすぎずに済みます。ツール呼び出しは関数・スキーマ・入出力契約で型を与え、監査可能性を確保します。根拠付けは参照と生成の分離、交差検証、計算の外部化で強化できます。一方、ツールは攻撃面を増やすので、最小権限の原則、プロンプト注入対策、実行系の確認と監査ログが不可欠です。最後に、失敗は避けられないため、分類し、検知し、回復する設計（検査役モデル、自己一貫性、反省ループ）を組み込みます。</p>
<p>次の章では、この「ツール利用＋ループ」を、複数エージェント（CEO/COO/CTO/CFOの同時進行）や、社会的関係（第6章）と結びつけ、合意形成・交渉・対立解消といった“集団の意思決定”をどうシミュレーション・運用するかへ進みます。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Lewis, P., Perez, E., Piktus, A., et al. (2020). “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.” <a href="https://arxiv.org/abs/2005.11401" target="_blank">https://arxiv.org/abs/2005.11401</a>)</p>
<p>Nakano, R., Hilvert, J., Mishkin, P., et al. (2021). “WebGPT: Browser-assisted question-answering with human feedback.” <a href="https://arxiv.org/abs/2112.09332" target="_blank">https://arxiv.org/abs/2112.09332</a>)</p>
<p>Yao, S., Zhao, J., Yu, D., et al. (2022). “ReAct: Synergizing Reasoning and Acting in Language Models.” <a href="https://arxiv.org/abs/2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a>)</p>
<p>Gao, L., Madaan, A., Zhou, S., et al. (2022). “PAL: Program-aided Language Models.” <a href="https://arxiv.org/abs/2211.10435" target="_blank">https://arxiv.org/abs/2211.10435</a>)</p>
<p>Chen, W., et al. (2022). “Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks.” <a href="https://arxiv.org/abs/2211.12588" target="_blank">https://arxiv.org/abs/2211.12588</a>)</p>
<p>Wang, X., Wei, J., Schuurmans, D., et al. (2022). “Self-Consistency Improves Chain of Thought Reasoning in Language Models.” <a href="https://arxiv.org/abs/2203.11171" target="_blank">https://arxiv.org/abs/2203.11171</a>)</p>
<p>Shinn, N., Cassano, F., Gopinath, A., et al. (2023). “Reflexion: Language Agents with Verbal Reinforcement Learning.” <a href="https://arxiv.org/abs/2303.11366" target="_blank">https://arxiv.org/abs/2303.11366</a>)</p>
<p>Madaan, A., Tandon, N., Gupta, P., et al. (2023). “Self-Refine: Iterative Refinement with Self-Feedback.” <a href="https://arxiv.org/abs/2303.17651" target="_blank">https://arxiv.org/abs/2303.17651</a>)</p>
<p>Zou, A., Wang, Z., Kolter, J. Z., & Fredrikson, M. (2023). “Universal and Transferable Adversarial Attacks on Aligned Language Models.” <a href="https://arxiv.org/abs/2307.15043" target="_blank">https://arxiv.org/abs/2307.15043</a>)</p>
<p>Saltzer, J. H., & Schroeder, M. D. (1975). “The Protection of Information in Computer Systems.” *Communications of the ACM*. <a href="https://doi.org/10.1145/361011.361067" target="_blank">https://doi.org/10.1145/361011.361067</a>)</p>
<h1 id="第9章-複数エージェントと組織・社会シミュレーション会議・交渉・合意形成を「設計可能」にする">第9章　複数エージェントと組織・社会シミュレーション：会議・交渉・合意形成を「設計可能」にする</h1>
<p>この章では、単体の「人間らしい対話エージェント」を、複数体が同時に存在し、互いに影響し合いながら意思決定する世界へ拡張する。目的は二つある。第一に、実在人物のデジタルツインを複数体用意して、経営会議やプロジェクト会議のような「集団の意思決定」を再現・分析できるようにすること。第二に、架空キャラクター（社内で役に立つAIキャラクター等）を含めた「キャスト」を設計し、社会・組織のシミュレーションへつなげることだ。</p>
<p>複数エージェントにすると、単体では見えなかった現象が現れる。協力・対立・交渉・同調・誤情報の増幅（もっともらしい誤りが“多数派の合意”で強化される）などである。これらは偶然ではなく、理論的に扱える対象であり、設計（ルール、情報構造、意思決定方式、検証手続き）によってかなり制御できる。そこで本章では、工学的な実装の前に、ゲーム理論・社会選択理論・意見ダイナミクス・エージェントベースモデリングといった「集団の振る舞いを記述する言語」を導入し、LLM（大規模言語モデル）を用いた複数エージェント系の設計へ落とし込む。</p>
<hr>
<h2 id="91-なぜ「複数エージェント」になると難しくなるのか相互依存と非定常性">9.1　なぜ「複数エージェント」になると難しくなるのか：相互依存と非定常性</h2>
<p>単体エージェントは、入力（質問、状況、記憶）から出力（発話、行動）への写像として設計できる。しかし複数体が同じ環境にいると、各エージェントの出力が他のエージェントの次の入力になる。つまり、あなたが設計したのは「一つの関数」ではなく「相互作用する関数の集合」であり、系全体が閉ループになる。</p>
<p>このとき難しさの根源は、各エージェントから見た世界が<strong>非定常（non-stationary）</strong>になる点にある。非定常とは、同じ状況に見えても、相手が学習・適応したり、会話の履歴が少し違うだけで、次の反応が変わってしまう性質である。単体では「同じ入力なら同じ出力」が設計目標になりやすいが、複数体では「相手が変わる」ため、入力分布自体が揺れる。</p>
<p>さらに、複数体になると「情報」が行動の中心になる。経営会議の例を考えると、CEO・COO・CTO・CFOは、同じ会社の将来を考えているようで、実際には「見ている情報（現場の事実、技術的制約、財務状態、採用市場）」が違う。会議では、単に結論を出すだけでなく、「情報を共有する」「情報を隠す」「情報を歪める」「相手に特定の印象を与える」といった情報操作が起こりうる。これはゲーム理論では<strong>不完全情報ゲーム</strong>や<strong>シグナリング（signaling）</strong>、<strong>チープトーク（cheap talk）</strong>として扱われる領域である（Spence 1973、Crawford & Sobel 1982）。</p>
<p>LLMベースの複数エージェントでも同じで、発話は単なる文章ではなく「他者の信念を動かす行動」になる。その結果、設計上の落とし穴として、次のような現象が起こりやすい。</p>
<p>第一に、<strong>同調（conformity）</strong>や<strong>集団浅慮（groupthink）</strong>が起きる。これは社会心理学でよく知られた現象で、集団内の調和や一体感が優先され、反証や代替案の検討が弱くなる（Janis 1972/1982）。LLMエージェントでは、口調・論調の同調が起こりやすく、誤りが訂正されず「会議として整った結論」だけが出力される危険がある。</p>
<p>第二に、<strong>誤情報のカスケード（cascading hallucination）</strong>が起きる。あるエージェントがもっともらしい誤りを言うと、それを前提に別のエージェントが議論を積み上げ、結果として全員が「整合的だが間違った物語」に収束する。近年のLLMマルチエージェント研究でも、この問題は明確に指摘され、工程分解や検証役の導入で緩和しようとする枠組みが提案されている（MetaGPT, Hong et al. 2023、ChatDev, Qian et al. 2023）。</p>
<p>この章のゴールは、こうした現象を「運が悪い」ではなく、「モデル化して設計する」対象として扱えるようにすることだ。</p>
<hr>
<h2 id="92-ゲーム理論で「相互作用」を定義する利得戦略均衡">9.2　ゲーム理論で「相互作用」を定義する：利得、戦略、均衡</h2>
<p>複数エージェントの相互作用を最も抽象的に表す理論が<strong>ゲーム理論（game theory）</strong>である。ゲーム理論は、複数の意思決定主体が互いの行動に影響し合う状況を、数学的対象として扱う。古典的基礎は von Neumann & Morgenstern『Theory of Games and Economic Behavior』（1944）に置かれ、非協力ゲームの中心概念としてナッシュ均衡が Nash（1950）により導入された。</p>
<h3 id="921-正規形ゲーム最小の形式化">9.2.1　正規形ゲーム：最小の形式化</h3>
<p>最も基本的には、正規形（normal form）のゲームを次のタプルで表す。</p>
<p>$$ G = \left( N, {A_i}_{i\in N}, {u_i}_{i\in N} \right) $$</p>
<p>ここで $N={1,\dots,n}$ はプレイヤー（エージェント）の集合、$A_i$ はエージェント $i$ が選べる行動（戦略）の集合、$u_i: A_1\times\cdots\times A_n \to \mathbb{R}$ は利得（効用）関数である。</p>
<p>経営会議の単純化した例として、「新規事業に投資する（I）」か「投資を抑える（C）」かを、CEOとCFOが同時に選ぶ状況を考える。CEOは成長を重視し、CFOは資金繰りを重視する。ここで $A_{\mathrm{CEO}}={I,C}$、$A_{\mathrm{CFO}}={I,C}$ として利得表を設計すれば、協調か対立か、どの組み合わせが安定するかを議論できる。</p>
<p>重要なのは、利得 $u_i$ を「善悪」や「倫理」ではなく、「そのエージェントが一貫して追う評価尺度」として置く点である。デジタルツインなら、その人物が過去に示した判断（発言、意思決定の傾向）から、暗黙に最大化していそうな尺度を推定する。架空キャラクターなら、作者が設計した価値観を利得として定義する。</p>
<h3 id="922-ナッシュ均衡互いに動かす理由がない状態">9.2.2　ナッシュ均衡：互いに動かす理由がない状態</h3>
<p>正規形ゲームでの中心概念が<strong>ナッシュ均衡（Nash equilibrium）</strong>である。混合戦略（確率的な戦略） $\sigma_i\in\Delta(A_i)$ を許すとき、戦略プロファイル $\sigma^*=(\sigma_1^*,\dots,\sigma_n^*)$ がナッシュ均衡であるとは、</p>
<p>$$ u_i(\sigma_i^*,\sigma_{-i}^*) \ge u_i(\sigma_i,\sigma_{-i}^*) \quad \forall i,\ \forall \sigma_i \in \Delta(A_i) $$</p>
<p>が成り立つことをいう。直観的には「他の全員が $\sigma_{-i}^*$ を選ぶなら、自分だけ $\sigma_i^*$ から変更しても得をしない」状態である。ナッシュ均衡の存在は Nash（1950）により示された（PNAS版：DOI 10.1073/pnas.36.1.48）。</p>
<p>この概念は、複数エージェント会話の設計にも対応する。例えば会議で「根拠を示さず強い断言をする」エージェントが得をする（発言力を持つ）設計にしてしまうと、均衡として全員が断言し始め、誤りが増える。逆に「根拠を示し、検証可能な主張だけが評価される」設計にすると、均衡は根拠重視に寄る。ここで重要なのは、<strong>均衡は“性格の結果”ではなく“環境ルールの結果”でもある</strong>ということだ。会議の議事運営、評価、責任の所在、意思決定方式（多数決か合意か）を変えると、同じエージェント集合でも均衡が変わる。</p>
<h3 id="923-相関均衡第三者の助言や共通信号を含める">9.2.3　相関均衡：第三者の助言や共通信号を含める</h3>
<p>現実の組織では、全員が独立に意思決定するわけではない。共通の資料、議長のまとめ、社内規程、あるいは「空気」のような共通信号に従って行動が相関する。この状況は、Aumann が導入した<strong>相関均衡（correlated equilibrium）</strong>で捉えられる（Aumann 1974、1987）。</p>
<p>相関均衡は、確率変数 $S$（共通信号）が各エージェントに推奨行動を与える状況で、「推奨に従うことが最適」になっている分布として定義される。直観的には「議長が各人に役割を割り振る」「会議の手順が発話の順番と内容を制約する」などが相関装置になる。</p>
<p>LLMマルチエージェントでは、この相関装置を<strong>オーケストレータ（進行役）やプロトコル</strong>として実装する。例えば「まずCFOがリスクを列挙し、次にCTOが技術負債を説明し、その後CEOが意思決定する」といった順序規則は、発話の相関を意図的に作り、誤りの増幅や同調を抑える方向に働きうる。</p>
<hr>
<h2 id="93-不完全情報と「他者モデル」タイプ信念そして推論">9.3　不完全情報と「他者モデル」：タイプ、信念、そして推論</h2>
<p>実際の会議では、各人が知っている情報も、価値観も、限界も違う。そこで必要になるのが<strong>不完全情報（incomplete information）</strong>の枠組みである。Harsanyi（1967）は、各プレイヤーが「タイプ（type）」と呼ばれる隠れたパラメータを持つとしてゲームを定式化し、ベイズ的に解く枠組み（ベイズゲーム）を確立した（Management Science, DOI 10.1287/mnsc.14.3.159）。</p>
<h3 id="931-ベイズゲームタイプと期待効用">9.3.1　ベイズゲーム：タイプと期待効用</h3>
<p>ベイズゲームでは、各エージェント $i$ にタイプ $\theta_i \in \Theta_i$ があり、全タイプ $\theta=(\theta_1,\dots,\theta_n)$ に対して事前分布 $p(\theta)$ があるとする。行動 $a=(a_1,\dots,a_n)$ に対する効用を $u_i(a,\theta)$ とし、各エージェントは自分のタイプ $\theta_i$ を観測しつつ、他者のタイプを確率的に推測しながら期待効用を最大化する。</p>
<p>$$ \max_{\pi_i} \ \mathbb{E}_{\theta_{-i}\sim p(\cdot\mid \theta_i)} \left[ u_i\big(\pi_i(\theta_i), \pi_{-i}(\theta_{-i}), \theta\big) \right]$$ ここで $\pi_i$ はタイプから行動への写像（戦略）である。</p>
<p>デジタルツインの文脈では、タイプ $\theta_i$ は「その人の価値観・リスク許容度・専門性・時間選好」などに相当する。架空キャラクターでは、設定（バックストーリー、信念、恐れ、執着）をタイプに含められる。重要なのは、タイプが固定である必要はなく、時間とともに更新される状態として扱うこともできる点だ。次章以降で扱う長期記憶は、この「タイプの変化」をデータとして支える役割を持つ。</p>
<h3 id="932-信念更新ベイズの定理と会話">9.3.2　信念更新：ベイズの定理と会話</h3>
<p>不完全情報の場面では、「会話」そのものが観測データである。ある発言 $m$ を聞いたとき、聞き手は「話し手がどのタイプならその発言をするか」を逆推論する。これはベイズの定理そのもので、</p>
<p>$$p(\theta \mid m) = \frac{p(m \mid \theta), p(\theta)}{p(m)}$$ と書ける。ここで $p(m\mid \theta)$ は「タイプ $\theta$ の話し手が発言 $m$ を選ぶ確率」である。つまり会話設計では、発言が信念更新を誘発することを前提にしなければならない。</p>
<p>LLMエージェントでこれを意識すると、次の問いが設計の中心になる。</p>
<p>「このエージェントは、どの情報を共有し、どの情報を保留し、どの表現で相手の信念を動かすべきか」</p>
<p>ここで表現の選択は、単なる“口調”ではなく戦略になる。Crawford & Sobel（1982）は、利害が完全に一致しない送信者と受信者の間では、コストのない会話（チープトーク）では情報が粗くしか伝わらない（完全には伝達できない）ことを示した（JSTOR stable 1913390）。つまり、会議で「言っただけ」を信用すると、情報が歪むのは理論的に自然である。したがって、組織シミュレーションでも「検証可能な資料の提示」「数値の根拠」「第三者の監査」など、チープトークを“コストのある主張”へ変換する装置が重要になる。</p>
<h3 id="933-限定合理性人間（とデジタルツイン）は最適化機械ではない">9.3.3　限定合理性：人間（とデジタルツイン）は最適化機械ではない</h3>
<p>古典的ゲーム理論は、プレイヤーが完全に合理的で、無限の計算能力を持つかのように振る舞う前提を置きやすい。しかし、人間はそうではない。Herbert A. Simon は、人間や組織が計算資源や情報に制約を持つため、最適化ではなく「満足化（satisficing）」を行うと論じた（Simon 1955, DOI 10.2307/1884852）。組織意思決定の理論としては March & Simon『Organizations』（1958）や、Cyert & March『A Behavioral Theory of the Firm』（1963）が、現実の企業が「目標の連立」「部門間の交渉」「ルーチン」によって動くことを示している。</p>
<p>デジタルツインや架空キャラクターを「人間らしく」するうえで重要なのは、この限定合理性を“欠陥”として消すのではなく、“個性”として設計することである。たとえばCFOは財務の不確実性を強く重視し、最適解探索よりも安全側の意思決定をしがちだ、という形で「探索深度」「リスク回避」をモデルパラメータとして明示できる。LLMは言語的には流暢に最適化してしまうことがあるため、むしろ限定合理性を再導入する設計（探索の打ち切り、保守的な判断、説明可能性を優先するなど）が「人間らしさ」に効く。</p>
<hr>
<h2 id="94-交渉と合意二者交渉から会議プロトコルへ">9.4　交渉と合意：二者交渉から会議プロトコルへ</h2>
<p>組織の意思決定の多くは、投票よりも交渉に近い。資源配分、優先順位、責任分担は、利害の調整として現れる。交渉を扱う代表的理論が、Nash（1950）の<strong>交渉解（Nash bargaining solution）</strong>と、Rubinstein（1982）の<strong>交互提案交渉モデル（alternating-offers bargaining）</strong>である。</p>
<h3 id="941-ナッシュ交渉解規範としての解">9.4.1　ナッシュ交渉解：規範としての解</h3>
<p>ナッシュ交渉解は「どの合意が公平か／合理的か」を、いくつかの公理（効率性、対称性、独立性など）から一意に導く規範的解である。合意案を $x\in \mathcal{F}$（実現可能集合）とし、合意できなかった場合の外部選択肢（disagreement point）を $d=(d_1,d_2)$ とすると、ナッシュ交渉解は次を最大化する $x^*$ として与えられる。</p>
<p>$$ x^* = \arg\max_{x\in \mathcal{F}} (u_1(x)-d_1),(u_2(x)-d_2) $$</p>
<p>ここで $u_i(x)$ はプレイヤー $i$ の効用である。原典は Nash「The Bargaining Problem」（Econometrica, 1950）で、JSTOR stable 1907266 などから参照できる。</p>
<p>経営会議の例に即して言えば、新規事業の予算配分 $b$ をめぐって CEO と CFO が交渉する状況で、CEOの効用が成長率、CFOの効用が破綻確率の低さ（あるいはフリーキャッシュフローの維持）に依存すると仮定すれば、ナッシュ交渉解は「双方が外部選択肢より得をする範囲で、積（改善の積）が最大の妥協点」を与える。これは実務的には「誰かが全勝する」ではなく「双方の譲歩が釣り合う」合意を導くことが多い。</p>
<p>LLMベースの会議シミュレーションにとって重要なのは、ナッシュ交渉解が「交渉の結果」を与えるだけで、「交渉の過程」を与えない点だ。そこで次に、過程を扱うモデルが必要になる。</p>
<h3 id="942-ルビンシュタイン交互提案モデル過程としての交渉">9.4.2　ルビンシュタイン交互提案モデル：過程としての交渉</h3>
<p>Rubinstein（1982）は、交渉を時間が進む逐次ゲームとして定義し、割引（待つほど価値が減る）を導入することで、交渉の過程と結果を同時に導いた。典型的には、パイ1を二人で分けるとき、プレイヤー1が最初に提案し、プレイヤー2が受諾か拒否を選び、拒否なら次期にプレイヤー2が提案…を無限に繰り返す。</p>
<p>このモデルで、各プレイヤーが割引因子 $\delta_1,\delta_2 \in (0,1)$ を持つとき、完全情報の下では一意の部分ゲーム完全均衡があり、先手の取り分は次の形になることが知られている（詳細は Rubinstein 1982 の導出参照）。</p>
<p>$$x_1^* = \frac{1-\delta_2}{1-\delta_1\delta_2}, \quad x_2^* = 1-x_1^*$$ 割引因子が大きい（待てる、急がない）ほど取り分は均等に近づき、割引因子が小さい（急ぐ）ほど先手が有利になる。これは組織の交渉にも直結する。資金が枯渇寸前の事業部は割引因子が小さく、妥協しやすい。逆にキャッシュに余裕がある側は待てるため強い。</p>
<p>LLM会議シミュレーションでは、割引因子に相当するものが「締切」「意思決定の遅延コスト」「次の会議までに失う機会」「ユーザー体験（長引く会話のストレス）」として現れる。つまり、交渉が長引くほど価値が減る設計にすることで、無限ループ的な会話を抑え、現実の会議らしい“妥協”に収束させられる。</p>
<h3 id="943-インセンティブとメカニズム嘘をつくのが得にならない設計">9.4.3　インセンティブとメカニズム：嘘をつくのが得にならない設計</h3>
<p>交渉の難しさは、各人が自分の私的情報を持ち、嘘や誇張が得になることがある点にある。これを扱うのが<strong>メカニズムデザイン（mechanism design）</strong>で、中心概念の一つが<strong>インセンティブ両立（incentive compatibility）</strong>である。Myerson（1979）は交渉問題をベイズ的集団選択として定式化し、インセンティブ両立な解を議論した（Econometrica, DOI 10.2307/1912346）。メカニズムデザインの考え方を会議に応用すると、次のような設計発想が得られる。</p>
<p>「会議参加者が、自分に不利な情報でも正しく出すほうが結局得になるように、議論のルール・評価・責任を設計する」</p>
<p>LLMエージェントを複数用いて会議を再現する場合も同じで、「誤情報を言ったエージェントが得をする」仕組みを作ると、必ず誤情報が増える。逆に「検証可能性を提示できない主張は意思決定に採用されない」「後から監査される」「出典が残る」といった制度を入れると、均衡行動が変わる。この観点は、単なるプロンプトの工夫よりも強力である。なぜなら、個々の発話を縛るのではなく、ゲームの構造（利得と制約）を変えるからだ。</p>
<hr>
<h2 id="95-集団の意思決定方式社会選択理論と「会議のルール設計」">9.5　集団の意思決定方式：社会選択理論と「会議のルール設計」</h2>
<p>交渉を経ても、最終的に「決める」必要がある。複数エージェントの会議シミュレーションでは、決定方式の設計がそのままシステムの性格になる。ここで必要になるのが<strong>社会選択理論（social choice theory）</strong>である。社会選択理論は、個人の選好（好み・順位付け）を集団の選好や決定へ集約する方法を研究する分野で、Arrow（1950, 1951）が中心的役割を果たした。</p>
<h3 id="951-社会厚生関数とアローの不可能性定理">9.5.1　社会厚生関数とアローの不可能性定理</h3>
<p>各人の選好を $\succeq_i$（「〜以上が好ましい」という順序）と書き、個人の選好プロファイル $(\succeq_1,\dots,\succeq_n)$ から社会の選好 $\succeq$ を出力する関数を</p>
<p>$$ F: (\succeq_1,\dots,\succeq_n) \mapsto \succeq $$</p>
<p>と定義する。この $F$ を社会厚生関数（social welfare function）という。Arrow は、もっとも自然に見える条件（例えば、全員がAをBより好むなら社会もAをBより好む、無関係な選択肢に依存しない、など）を同時に満たす $F$ は存在しないことを示した。これが<strong>アローの不可能性定理</strong>である（Arrow 1950「A Difficulty in the Concept of Social Welfare」JPE, DOI 10.1086/256963。書籍版は Arrow 1951『Social Choice and Individual Values』）。</p>
<p>この結果は、会議プロトコル設計にとって非常に現実的な示唆を持つ。すなわち「万能な意思決定ルールはない」。どんなルールにも歪みがあり、何かを犠牲にする。したがって、会議をシミュレーションするなら、まず「この会議では何を優先するか」を決め、そこに合うルールを選ぶべきである。例えば、スピードが最優先ならCEO単独決裁に近づき、正確性が最優先なら検証プロセスを重視した合意形成に近づく。</p>
<h3 id="952-戦略的投票嘘をつけると必ず操作される">9.5.2　戦略的投票：嘘をつけると必ず操作される</h3>
<p>投票にすると一見公平に見えるが、投票は戦略的になる。Gibbard（1973）は、3つ以上の選択肢がある一般の状況では、（独裁でない限り）誰かが嘘の投票で結果を有利にできることを示した（Econometrica, DOI 10.2307/1914083）。Satterthwaite（1975）も同様の定理を示し、現在は<strong>ギバード＝サタスワイスの定理</strong>として知られる（Journal of Economic Theory, DOI 10.1016/0022-0531(75)90050-2）。</p>
<p>LLMエージェント会議にこの話を持ち込むと、重要な結論が出る。</p>
<p>「“多数決をさせれば客観的になる”とは限らない。むしろ、エージェントの目標（利得）に応じて、投票行動が戦略的に歪むのは自然である。」</p>
<p>デジタルツインの場合、本人が戦略的に動く人物であれば、ツインも戦略的に動くのが“本人らしさ”かもしれない。一方で、社会・会社シミュレーションでそれを許すと、意図せず政治的ゲームが暴走する可能性もある。ここでも「何を再現したいか」が設計要件になる。</p>
<h3 id="953-「多数が正しい」は条件付きコンドルセ陪審定理と独立性">9.5.3　「多数が正しい」は条件付き：コンドルセ陪審定理と独立性</h3>
<p>「多数決は賢い」という直観は、数学的には<strong>コンドルセ陪審定理（Condorcet’s jury theorem）</strong>として定式化される。簡単化して、各投票者が独立に正答確率 $p>1/2$ で正しい選択肢を選ぶとき、投票者数 $n$ が増えるほど多数決が正しくなる確率は1に近づく。その確率は二項分布で</p>
<p>\sum_{k=(n+1)/2}^{n} \binom{n}{k} $p^k$ (1-p)^{n-k} ]</p>
<p>と書ける。</p>
<p>しかしここで鍵になるのは、投票が独立であることと、各人が $p>1/2$ の能力を持つことだ。LLMエージェント会議では、独立性が簡単に破れる。共通の誤った前提を共有すると、全員の投票が同方向にズレる。つまり多数決は「誤りの増幅装置」にもなる。この問題は次節の意見ダイナミクスとも関係する。</p>
<p>したがって、会議シミュレーションで「多数決」を採用するなら、独立性を保つ工夫が必要になる。例えば、最初に各役員ツインが独立に意見を出し、後から共有して議論するなど、情報の流れを設計する。これは工学的には「発話の順序」「共有メモリの公開タイミング」「相手の発言を見せないブラインド生成」などの実装で実現できる。</p>
<hr>
<h2 id="96-意見ダイナミクス会話で“考え”がどう収束するかを数式で見る">9.6　意見ダイナミクス：会話で“考え”がどう収束するかを数式で見る</h2>
<p>会議は、個々の意見が時間とともに変化していくプロセスである。これを扱うのが<strong>意見ダイナミクス（opinion dynamics）</strong>で、社会ネットワーク上での意見更新を線形・非線形の力学系として記述する。</p>
<h3 id="961-DeGrootモデル線形合意形成の最小モデル">9.6.1　DeGrootモデル：線形合意形成の最小モデル</h3>
<p>DeGroot（1974）は、各人が他者の意見の加重平均に従って自分の意見を更新するモデルを提案した（JASA, DOI 10.1080/01621459.1974.10480137）。エージェント $i$ の時刻 $t$ の意見を $x_i(t)$ とし、重み行列 $W=[w_{ij}]$（$w_{ij}\ge 0,\ \sum_j w_{ij}=1$）を用いると、</p>
<p>$$x_i(t+1) = \sum_{j=1}^{n} w_{ij} x_j(t)$$ 行列形式では</p>
<p>$$ x(t+1) = W x(t) $$</p>
<p>である。条件（例えば $W$ が適切に“強連結”であるなど）が満たされると、意見は一つの値に収束し（コンセンサス）、その値は初期意見の重み付き平均になる。</p>
<p>このモデルは極端に単純だが、会議設計の直観を与える。たとえば、CEOが強い影響力を持つ（多くの人がCEOを参照する）なら、$W$ の構造としてCEO列の重みが大きくなり、最終意見はCEOに引っ張られる。逆に多元的な影響構造なら、合意はより分散的になる。</p>
<p>LLM複数エージェントでは、各発話が他者の意見を更新する“入力”になるので、実装上は $W$ を直接置かなくても、発話生成の規則が暗黙の $W$ を作る。例えば「上位者の発言を強く尊重する」性格付けは、DeGrootの重み行列で言えば上位者への重みを増やすことに相当する。</p>
<h3 id="962-Friedkin–Johnsenモデル頑固さ（stubbornness）を導入する">9.6.2　Friedkin–Johnsenモデル：頑固さ（stubbornness）を導入する</h3>
<p>現実には、人は完全に他者に合わせない。初期意見をある程度保持する“頑固さ”がある。Friedkin–Johnsenモデルは、DeGrootを拡張してその性質を表現する。典型的には、対角行列 $\Lambda=\mathrm{diag}(\lambda_1,\dots,\lambda_n)$（$\lambda_i\in[0,1]$）を用い、</p>
<p>$$ x(t+1) = \Lambda W x(t) + (I-\Lambda) x(0) $$</p>
<p>とする（基礎は Friedkin & Johnsen の社会影響ネットワーク理論として整理され、書籍として Friedkin & Johnsen『Social Influence Network Theory』（Cambridge, 2011, DOI 10.1017/CBO9780511976735）などで参照できる）。</p>
<p>$\lambda_i$ が小さいほど初期意見 $x_i(0)$ に強く留まり、$\lambda_i$ が大きいほど他者の意見に追随する。これはデジタルツインの個性設計に極めて有用である。例えばCFOは財務の原則（安全側）に頑固で、CEOは市場の情報で意見を更新しやすい、という設計を $\lambda_i$ と $W$ で分けて表現できる。</p>
<h3 id="963-有界信頼（bounded-confidence）分断と極化のモデル">9.6.3　有界信頼（bounded confidence）：分断と極化のモデル</h3>
<p>会議で起こる現象として「分断」や「極化」がある。これは線形平均モデルでは表現しづらい。そこで有名なのが<strong>有界信頼モデル（bounded confidence model）</strong>で、Deffuant et al.（2000）や Hegselmann & Krause（2002）が代表である。</p>
<p>Deffuantモデルでは、二人 (i,j) が交流するとき、意見差が閾値 $\varepsilon$ より小さい場合だけ意見が近づく。</p>
<p>$$ \text{if } |x_i(t)-x_j(t)| < \varepsilon,\quad x_i(t+1)=x_i(t)+\mu(x_j(t)-x_i(t)) $$</p>
<p>(\mu\in$0,1/2]$ は歩み寄り係数である（Deffuant et al., 2000, DOI 10.1142/S0219525900000078）。Hegselmann–Krauseモデルも同様に、近い意見だけを平均する仕組みを持ち、条件によっては複数クラスターへ分裂する（Hegselmann & Krause, 2002, JASSS 5(3) 論文PDFが公開されていることが多い）。</p>
<p>LLMエージェント会議では、この $\varepsilon$ は「相手の発言をどれだけ信頼するか」「同じ前提を共有していると感じるか」に相当する。エージェントに強い“部門文化”を与えると、$\varepsilon$ が小さくなり、他部門の主張を受け入れなくなる。これは現実の組織でもよくある現象であり、むしろ再現したいなら必要な機構だが、会社全体の合意形成を狙うなら分断が暴走しないように“翻訳役”のエージェント（社内AIキャラクターなど）を設計し、$\varepsilon$ を事実上大きくする介入が必要になる。</p>
<hr>
<h2 id="97-マルチエージェント強化学習とマルコフゲーム環境が時間発展する状況へ">9.7　マルチエージェント強化学習とマルコフゲーム：環境が時間発展する状況へ</h2>
<p>ここまでの議論は、会議のような「短い相互作用」を主に扱った。しかし会社や社会シミュレーションでは、日々の行動の積み重ねが次の状態を作る。そこで必要になるのが、動的ゲームとしての<strong>マルコフゲーム（Markov game）</strong>、別名<strong>確率ゲーム（stochastic game）</strong>である。基礎は Shapley（1953）が導入した（PNAS, DOI 10.1073/pnas.39.10.1095）。Littman（1994）はこれをマルチエージェント強化学習の枠組みとして整理し、現在のMulti-Agent Reinforcement Learning（複数エージェント強化学習）の基礎になっている。</p>
<h3 id="971-マルコフゲームの定義">9.7.1　マルコフゲームの定義</h3>
<p>マルコフゲームは次で与えられる。</p>
<ul>
<li>状態空間 $S$</li>
<li>各エージェントの行動空間 $A_i$、合同行動 $A=A_1\times\cdots\times A_n$</li>
<li>状態遷移確率 $P(s' \mid s, a)$</li>
<li>各エージェントの報酬関数 $r_i(s,a)$</li>
<li>割引因子 $\gamma\in(0,1)$</li>
</ul>
<p>時刻 $t$ に状態 $s_t$ があり、エージェントが行動 $a_t=(a_{1,t},\dots,a_{n,t})$ を選ぶと、報酬 $r_i(s_t,a_t)$ を得て、次状態 $s_{t+1}\sim P(\cdot\mid s_t,a_t)$ に遷移する。エージェント $i$ の目的は割引和</p>
<p>$$G_i = \sum_{t=0}^{\infty} \gamma^t r_i(s_t,a_t)$$ の期待値を最大化することになる。</p>
<p>会社シミュレーションでは、状態 $s_t$ に「売上、利益、解約率、採用人数、技術負債、プロジェクト進捗、規制リスク」などを含められる。行動 $a_{i,t}$ は「施策決定」「採用」「投資」「開発優先度」「価格改定」などになる。会議は、その行動選択を行うための内部プロセスとして、マルコフゲームの中に埋め込める。</p>
<h3 id="972-LLMを政策（policy）として見る">9.7.2　LLMを政策（policy）として見る</h3>
<p>強化学習では、状態から行動を選ぶ規則を<strong>方策（policy）</strong> $\pi_i(a_i\mid o_i)$ と呼ぶ。ここで $o_i$ は観測で、部分観測の場合は $o_i$ が状態 $s$ を完全には含まない。LLMエージェントは本質的に部分観測である。なぜなら、入力できるコンテキスト長が有限で、外界情報はツールを通じてしか得られず、さらに記憶検索も近似だからだ。</p>
<p>したがって、LLMエージェントを数理的に見るなら、「観測 $o_i$（対話履歴、検索結果、メモリの抜粋）から、行動 $a_i$（発話、ツール呼び出し、意思決定）をサンプルする確率的方策」とみなせる。すると、マルチエージェント会議は「自然言語を行動空間に持つマルコフゲーム」として整理できる。</p>
<p>ただし、ここで重要な注意がある。LLMは通常、あなたの会社シミュレーション環境で強化学習されていない。つまり $\pi_i$ は環境に最適化されておらず、一般コーパスで学んだ言語的予測器として振る舞う。このギャップは、現実の人間に似せたデジタルツインを作る際に、かえって有利にも不利にも働く。有利な点は、言語的常識や説明能力が高いこと。不利な点は、環境固有のルール（社内規程、財務制約、製品制約）に忠実な方策が自然には生まれないことだ。したがって、会社シミュレーションでは、方策を「プロンプトだけで作る」よりも、環境側（状態遷移、評価、検証、責任）を設計して“誘導する”ほうが頑健になりやすい。</p>
<hr>
<h2 id="98-LLMマルチエージェントの実装パターン会議を壊さないための制度設計">9.8　LLMマルチエージェントの実装パターン：会議を壊さないための制度設計</h2>
<p>ここからは、理論を実装設計へ接続する。近年、LLMを複数エージェントとして協調させる枠組みがいくつも提案されている。代表例として、役割演技で協調を促す CAMEL（Li et al., 2023, arXiv:2303.17760）、複数エージェント会話をプログラム可能にする AutoGen（Wu et al., 2023, arXiv:2308.08155）、ソフトウェア開発工程を会話で分割する ChatDev（Qian et al., 2023, arXiv:2307.07924）、標準作業手順を組み込んで誤りの連鎖を抑える MetaGPT（Hong et al., 2023, arXiv:2308.00352）がある。これらは領域は違うが、共通して「役割」「工程分解」「検証」「会話の制約」を重視している。</p>
<h3 id="981-会議を“ゲーム”として設計する利得と制約を先に決める">9.8.1　会議を“ゲーム”として設計する：利得と制約を先に決める</h3>
<p>会議シミュレーションを作るとき、多くの人が最初にやりがちな誤りは「各役員の口調や性格を先に固める」ことである。もちろん性格は重要だが、集団の振る舞いを決めるのは、しばしば口調よりも「制度」である。本章のゲーム理論の議論を踏まえるなら、まず次を明確にするのが順序として自然だ。</p>
<p>第一に、この会議の目的関数をどう置くかである。たとえば「中期の企業価値最大化」「資金ショート確率の最小化」「技術負債の抑制」「現場の安定運用」など、役割ごとに重みが違う評価尺度がある。これが利得 $u_i$ の核になる。デジタルツインなら、過去の発言や意思決定の傾向（財務安全性をどこまで重視したか、スピードをどこまで優先したか）から推定する。架空キャラクターなら、設定として設計し、ストーリー上の一貫性を守る。</p>
<p>第二に、制約である。財務制約（キャッシュ、借入条件）、技術制約（アーキテクチャ、依存関係、セキュリティ）、人的制約（採用市場、稼働時間）を状態 $s$ と遷移 $P$ の側で表す。ここを曖昧にすると、LLMは「言語的にもっともらしい理想解」を出してしまい、現実らしさが壊れる。</p>
<p>第三に、意思決定方式である。CEOが最終決裁をするなら、社会選択ではなく権限構造のモデルになる。役員合議なら、投票や合意形成プロトコルが必要になる。ここを適当にすると、会議が終わらなかったり、逆にすぐに全員一致したりする。DeGroot型に勝手に収束してしまうのは典型的な不自然さである。</p>
<h3 id="982-「情報の流れ」を設計する独立性検証そして誤情報カスケード対策">9.8.2　「情報の流れ」を設計する：独立性、検証、そして誤情報カスケード対策</h3>
<p>意見ダイナミクスとコンドルセの議論から、会議の質を決めるのは情報の流れだと分かる。LLMマルチエージェント会議で特に重要なのは、誤情報が共有コンテキストに入った瞬間に、全員がそれを前提に話し始める点である。これを避ける実務的な設計は、「独立に考える段階」と「共有して議論する段階」を分けることに尽きる。</p>
<p>具体的には、会議を次の二段階として設計するのが強い。</p>
<p>最初に、各役員エージェントが“他者の発言を見ずに”自分の見立てを作る。ここではツール（社内データ検索、財務計算、バグ件数集計）を使わせてもよいが、他の役員の結論は見せない。これはコンドルセの独立性に対応する。</p>
<p>次に、共有フェーズで互いの主張を突き合わせる。ここでは「主張には根拠を添える」「数値には出典を添える」「反対意見を最低1つは検討する」など、議論プロトコルを導入する。ChatDev が提案する “communicative dehallucination（対話的脱幻覚化）” は、まさにこの段階での曖昧さ除去・検証の設計である（Qian et al., 2023）。</p>
<p>さらに、会議に「検証役（auditor）」を入れるのは非常に有効である。検証役は意思決定をしない代わりに、主張の前提と矛盾、数値の整合性、根拠の欠落を指摘する。これはゲーム理論で言えば、利得構造を変える相関装置であり、誤情報を言う戦略を劣位にする。AI安全の文脈では、複数モデルを議論させて真偽を見極める「ディベート（debate）」が提案されており、考え方としては同じ方向にある（Irving, Christiano, Amodei 2018, arXiv:1805.00899）。</p>
<h3 id="983-会議を“有限時間”にする割引・締切・議事運営の実装">9.8.3　会議を“有限時間”にする：割引・締切・議事運営の実装</h3>
<p>Rubinstein型の交渉モデルが示すように、締切や遅延コストがないと交渉は長引く。LLM会議でも同じで、無限に議論できてしまう。そこで、会議シミュレーションでは「時間」を制度として実装することが重要になる。</p>
<p>たとえば、会議には議題ごとに最大ターン数を設け、超過すると自動的に次の手続きへ移る（例えばCEO決裁、または次回持ち越し）。これは単なる打ち切りではなく、割引因子 $\delta$ を導入することに相当する。待つほど価値が減る（機会損失が増える）と設計すると、各エージェントは早期合意に向かう動機を持つ。</p>
<p>ただし注意すべきは、単に締切を置くと「結論を急ぐ＝検証を省く」に傾きやすいことだ。そこで現実の会議運営と同様に、議事進行を役割として分離する。議長（モデレータ）がターン配分と議題管理を行い、書記（サマライザ）が決定事項と未解決事項を記録し、検証役が根拠を確認する。この分業は、LLMマルチエージェント研究が繰り返し採用しているパターンでもある（AutoGen, MetaGPT など）。</p>
<h3 id="984-ケーススタディCEO・COO・CTO・CFOの経営会議をどう“モデル化”するか">9.8.4　ケーススタディ：CEO・COO・CTO・CFOの経営会議をどう“モデル化”するか</h3>
<p>最後に、抽象論を具体に落とすため、典型的な経営会議の骨格をモデルとして描いてみよう。ここでは、CEO・COO・CTO・CFOの4名（デジタルツインまたは架空キャラ）に加え、社内の役に立つAIキャラクター（例えば「全体最適の観点で質問する参謀」や「議論の論点を整理するファシリテータ」）を1名入れる状況を想定する。</p>
<p>会議の状態 $s$ には、財務（現金残高、月次の支出、売上、粗利、借入条件）、プロダクト（主要指標、解約率、障害件数、開発速度、技術負債指標）、組織（人員、採用市場、稼働率）、外部環境（競合動向、規制、景気）を含める。会議の行動 $a_i$ は発話だけでなく、「意思決定の提案」「反対」「条件付き賛成」「資料要求」「ツール呼び出し」「決裁」のような“会議上の行為”として定義する。発話はその行為の実現形であり、自然言語はインターフェースだと考えるとよい。</p>
<p>各役員の効用 $u_i$ は、同じ会社の成功に関わりつつも、重みが違う。例えばCEOは成長率や市場シェアの重みが大きく、CFOは破綻確率や資金繰りの重みが大きい。CTOは技術負債や運用リスクの重みが大きく、COOは現場の実行可能性とオペレーション安定性が大きい。これを単純化して、次のような線形効用で出発してもよい。</p>
<p>$$ u_i(s, a) = w_i^\top \phi(s, a) $$</p>
<p>ここで $\phi(s,a)$ は状態と行動から計算される特徴量（例えば「12ヶ月後の売上期待値」「キャッシュ残高の下振れ確率」「障害発生率」「採用成功確率」など）で、$w_i$ が役員ごとの重みである。もちろん現実は線形ではないが、最初のプロトタイプとしては十分に強い。</p>
<p>次に重要なのが、情報構造（誰が何を知っているか）である。例えばCFOは資金繰りの精密な見通しを知っているが、CTOは技術負債の実態を知っている。CEOは市場ストーリーと投資家心理を知っている。COOは現場のボトルネックを知っている。これらの情報は会話を通じて共有されるが、チープトーク問題がある以上、すべてを無条件には信じられない。そこで「財務は財務ツールの結果が優先」「稼働や障害は運用データが優先」「市場は外部検索の一次情報が優先」といった検証規則を設ける。これにより、誤情報を言う利得を下げ、根拠の提示を均衡にする。</p>
<p>さらに、意思決定方式を決める。CEOが単独決裁なら、会議は「情報集約→CEOが意思決定」になる。合議なら、投票や合意形成が必要だが、アローやギバード＝サタスワイスが示すように、万能な集約は不可能で操作も起こりうる。そこで「特定の議題はCFOに拒否権」「技術リスクが一定以上ならCTOの拒否権」「運用上の実行計画がないとCOOが保留できる」など、現実の企業に近い権限構造を入れると、会議は“それらしく”なる。これは社会選択を完全に解くのではなく、制度として歪みを選ぶ設計である。</p>
<p>最後に、社内AIキャラクターの役割を明確にする。このキャラクターを「全員の代弁者」にすると、会議は簡単に同調しやすい。むしろ有効なのは、検証役・翻訳役・論点整理役として設計し、個別利害を持たない（あるいは“会議の質”を利得にする）ことだ。これにより、集団浅慮を抑え、誤情報カスケードを早期に止める役割を担える。</p>
<hr>
<h2 id="99-まとめ複数エージェントは「人格」より先に「制度」を設計する">9.9　まとめ：複数エージェントは「人格」より先に「制度」を設計する</h2>
<p>複数エージェントの会話・会議・社会シミュレーションでは、個々のエージェントのキャラクター設計は重要だが、それ以上に「相互作用のルール」を設計することが支配的になる。本章で見たように、ゲーム理論は相互作用を利得と戦略として記述し、社会選択理論は意思決定方式の限界を示し、意見ダイナミクスは会話がどう収束・分裂するかを数式で描き、マルコフゲームは会社や社会の時間発展を扱う枠組みを与える。</p>
<p>LLMを使うと、会話の見た目は簡単に“それっぽく”なる。しかし集団の失敗（同調、誤情報の増幅、政治的操作）は、見た目の自然さとは独立に起こる。だからこそ、「会議の制度」から逆算してエージェントを設計する必要がある。次章以降では、複数エージェントを実際の社会・会社シミュレーションへ拡張するために、評価・監査・安全・倫理、そしてモデル更新の実務へ進む。</p>
<hr>
<h2 id="参考文献（リンク）">参考文献（リンク）</h2>
<p>von Neumann, J. & Morgenstern, O. (1944). *Theory of Games and Economic Behavior*. Princeton University Press.  <a href="https://press.princeton.edu/books/paperback/9780691130613/theory-of-games-and-economic-behavior" target="_blank">https://press.princeton.edu/books/paperback/9780691130613/theory-of-games-and-economic-behavior</a>)</p>
<p>Nash, J. (1950). Equilibrium points in n-person games. *PNAS*.  <a href="https://www.pnas.org/doi/10.1073/pnas.36.1.48" target="_blank">https://www.pnas.org/doi/10.1073/pnas.36.1.48</a>)</p>
<p>Nash, J. (1950). The Bargaining Problem. *Econometrica*. JSTOR stable:  <a href="https://www.jstor.org/stable/1907266" target="_blank">https://www.jstor.org/stable/1907266</a>)</p>
<p>Rubinstein, A. (1982). Perfect Equilibrium in a Bargaining Model. *Econometrica*. JSTOR stable:  <a href="https://www.jstor.org/stable/1912531" target="_blank">https://www.jstor.org/stable/1912531</a>)</p>
<p>Harsanyi, J. (1967). Games with Incomplete Information Played by “Bayesian” Players, Part I. *Management Science*.  <a href="https://doi.org/10.1287/mnsc.14.3.159" target="_blank">https://doi.org/10.1287/mnsc.14.3.159</a>)</p>
<p>Aumann, R. (1974). Subjectivity and correlation in randomized strategies. *Journal of Mathematical Economics*.  <a href="https://doi.org/10.1016/0304-4068%2874%2990037-8" target="_blank">https://doi.org/10.1016/0304-4068(74)90037-8</a>)</p>
<p>Aumann, R. (1987). Correlated Equilibrium as an Expression of Bayesian Rationality. *Econometrica*.  <a href="https://doi.org/10.2307/1911154" target="_blank">https://doi.org/10.2307/1911154</a>)</p>
<p>Arrow, K. (1950). A Difficulty in the Concept of Social Welfare. *Journal of Political Economy*.  <a href="https://doi.org/10.1086/256963" target="_blank">https://doi.org/10.1086/256963</a>)</p>
<p>Arrow, K. (1951). *Social Choice and Individual Values*. Wiley.</p>
<p>Gibbard, A. (1973). Manipulation of Voting Schemes: A General Result. *Econometrica*.  <a href="https://doi.org/10.2307/1914083" target="_blank">https://doi.org/10.2307/1914083</a>)</p>
<p>Satterthwaite, M. (1975). Strategy-proofness and Arrow’s conditions. *Journal of Economic Theory*.  <a href="https://doi.org/10.1016/0022-0531%2875%2990050-2" target="_blank">https://doi.org/10.1016/0022-0531(75)90050-2</a>)</p>
<p>Condorcet, M. de (1785). *Essay on the Application of Analysis to the Probability of Majority Decisions*.（陪審定理の原典。概説として： <a href="https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem" target="_blank">https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem</a>)  ）</p>
<p>DeGroot, M. (1974). Reaching a Consensus. *Journal of the American Statistical Association*.  <a href="https://doi.org/10.1080/01621459.1974.10480137" target="_blank">https://doi.org/10.1080/01621459.1974.10480137</a>)</p>
<p>Friedkin, N. & Johnsen, E. (2011). *Social Influence Network Theory*. Cambridge University Press.  <a href="https://doi.org/10.1017/CBO9780511976735" target="_blank">https://doi.org/10.1017/CBO9780511976735</a>)</p>
<p>Deffuant, G. et al. (2000). Mixing beliefs among interacting agents. *Advances in Complex Systems*.  <a href="https://doi.org/10.1142/S0219525900000078" target="_blank">https://doi.org/10.1142/S0219525900000078</a>)</p>
<p>Hegselmann, R. & Krause, U. (2002). Opinion dynamics and bounded confidence models. *Journal of Artificial Societies and Social Simulation (JASSS)*.（例：pdfが流通） <a href="https://jasss.soc.surrey.ac.uk/5/3/2.html" target="_blank">https://jasss.soc.surrey.ac.uk/5/3/2.html</a>)</p>
<p>Shapley, L. (1953). Stochastic Games. *PNAS*.  <a href="https://doi.org/10.1073/pnas.39.10.1095" target="_blank">https://doi.org/10.1073/pnas.39.10.1095</a>)</p>
<p>Littman, M. (1994). Markov games as a framework for multi-agent reinforcement learning.  <a href="https://www.cs.duke.edu/courses/spring07/cps296.3/littman94markov.pdf" target="_blank">https://www.cs.duke.edu/courses/spring07/cps296.3/littman94markov.pdf</a>)</p>
<p>Simon, H. (1955). A Behavioral Model of Rational Choice. *The Quarterly Journal of Economics*.  <a href="https://doi.org/10.2307/1884852" target="_blank">https://doi.org/10.2307/1884852</a>)</p>
<p>March, J. & Simon, H. (1958). *Organizations*. Wiley.（概説：Google Books等）</p>
<p>Cyert, R. & March, J. (1963). *A Behavioral Theory of the Firm*. Prentice-Hall.</p>
<p>Spence, M. (1973). Job Market Signaling. *The Quarterly Journal of Economics*.  <a href="https://doi.org/10.2307/1882010" target="_blank">https://doi.org/10.2307/1882010</a>)</p>
<p>Crawford, V. & Sobel, J. (1982). Strategic Information Transmission. *Econometrica*. JSTOR stable:  <a href="https://www.jstor.org/stable/1913390" target="_blank">https://www.jstor.org/stable/1913390</a>)</p>
<p>Kreps, D. & Wilson, R. (1982). Reputation and Imperfect Information. *Journal of Economic Theory*.  <a href="https://doi.org/10.1016/0022-0531%2882%2990030-8" target="_blank">https://doi.org/10.1016/0022-0531(82)90030-8</a>)</p>
<p>Myerson, R. (1979). Incentive Compatibility and the Bargaining Problem. *Econometrica*.  <a href="https://doi.org/10.2307/1912346" target="_blank">https://doi.org/10.2307/1912346</a>)</p>
<p>Bonabeau, E. (2002). Agent-based modeling: Methods and techniques for simulating human systems. *PNAS*.  <a href="https://doi.org/10.1073/pnas.082080899" target="_blank">https://doi.org/10.1073/pnas.082080899</a>)</p>
<p>Epstein, J. & Axtell, R. (1996). *Growing Artificial Societies: Social Science from the Bottom Up*. MIT Press.  <a href="https://mitpress.mit.edu/9780262550253/growing-artificial-societies/" target="_blank">https://mitpress.mit.edu/9780262550253/growing-artificial-societies/</a>)</p>
<p>Schelling, T. (1971). Dynamic Models of Segregation. *Journal of Mathematical Sociology*.（pdf例） <a href="https://pdodds.w3.uvm.edu/research/papers/others/1971/schelling1971a.pdf" target="_blank">https://pdodds.w3.uvm.edu/research/papers/others/1971/schelling1971a.pdf</a>)</p>
<p>Janis, I. (1972). *Victims of Groupthink*. Houghton Mifflin.（要約pdf例） <a href="https://med.stanford.edu/content/dam/sm/pedsendo-1/documents/Groupthink_by_Iriving_L_Janis_Summary_pd.pdf" target="_blank">https://med.stanford.edu/content/dam/sm/pedsendo-1/documents/Groupthink_by_Iriving_L_Janis_Summary_pd.pdf</a>)</p>
<p>Irving, G., Christiano, P., & Amodei, D. (2018). AI Safety via Debate.  <a href="https://arxiv.org/abs/1805.00899" target="_blank">https://arxiv.org/abs/1805.00899</a>)</p>
<p>Li, G. et al. (2023). CAMEL: Communicative Agents for “Mind” Exploration of Large Language Model Society.  <a href="https://arxiv.org/abs/2303.17760" target="_blank">https://arxiv.org/abs/2303.17760</a>)</p>
<p>Wu, Q. et al. (2023). AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation.  <a href="https://arxiv.org/abs/2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a>)</p>
<p>Qian, C. et al. (2023). ChatDev: Communicative Agents for Software Development.  <a href="https://arxiv.org/abs/2307.07924" target="_blank">https://arxiv.org/abs/2307.07924</a>)</p>
<p>Hong, S. et al. (2023). MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework.  <a href="https://arxiv.org/abs/2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a>)</p>
<h1 id="第10章-評価・検証・監査人物らしさを「測る」ための科学と実務">第10章　評価・検証・監査：人物らしさを「測る」ための科学と実務</h1>
<p>第9章では、複数エージェントによる会議や組織シミュレーションを、ゲーム理論・社会選択理論・意見ダイナミクス・マルコフゲームといった枠組みで捉えました。そこでは、個々のエージェントの振る舞い以上に、「相互作用のルール」や「情報の流れ」が全体の性格を決めることを強調しました。</p>
<p>ここで必ず突き当たるのが、次の問いです。</p>
<p>「このシステムは、狙った通りに“人物らしく”できているのか。現実の人物を模倣するなら、どの程度“本人らしい”のか。架空キャラなら、設定（カノン）にどれだけ忠実で、かつ役に立つのか。さらに複数エージェントの会議や会社シミュレーションとして、結果は妥当なのか。」</p>
<p>この章は、その問いに答えるための「評価（evaluation）」を体系化します。評価は、単に点数をつける作業ではありません。評価は、設計と改善を可能にするための測定科学です。測れないものは改善しにくい一方、測り方を誤るとシステムが壊れます（測定が目的化し、ズルが最適になる）。だからこそ、評価は“最後の工程”ではなく、設計の中心であり、しかも心理測定・統計・情報検索・安全工学が交差する分野になります。</p>
<p>本章では、人物らしさの評価を次の三層で扱います。第一に「測りたい概念（構成概念：construct）を定義し、妥当性と信頼性を確保する」という測定論です。第二に「指標（メトリクス）とデータ」をどう設計するかです。第三に「運用時の監査とドリフト（変化）の検知」をどう行うかです。通し例A（CEO/COO/CTO/CFO のデジタルツイン）と通し例B（社内で役に立つ架空キャラ）を通じて、同じ評価枠組みでも“正しさの定義”と“許される創作”が異なることを具体化します。</p>
<hr>
<h2 id="101-評価の前にやるべきこと何を「良い」とするのかを数学的に明示する">10.1　評価の前にやるべきこと：何を「良い」とするのかを数学的に明示する</h2>
<h3 id="1011-「人物らしさ」は単一のスコアではない">10.1.1　「人物らしさ」は単一のスコアではない</h3>
<p>「人物らしい」を一つの数で表そうとすると、ほぼ必ず破綻します。なぜなら人物らしさは、少なくとも（i）内容の妥当性（事実や根拠）、（ii）意思決定の一貫性（価値観・優先順位）、（iii）会話の社会性（礼儀・含意・信頼）、（iv）長期記憶の整合性（過去との矛盾の少なさ）、（v）役割適合（CEOらしさ、CFOらしさ等）、（vi）安全境界の遵守、のように複数の軸を持ちます。これらは相互にトレードオフで、同時に最大化できない場合があります。</p>
<p>そこで評価は、まず「多目的最適化」として定義するのが自然です。システムの行動（応答やツール利用）を $\pi$ とし、複数の評価指標を $J_1(\pi),J_2(\pi),\dots,J_K(\pi)$ と置くと、設計は</p>
<p>$$ \text{良いシステム} ;;\Longleftrightarrow;; (J_1(\pi),\dots,J_K(\pi)) \text{ が望ましい領域にある} $$</p>
<p>という形になります。単一スカラーに潰すなら重み付き和 $J(\pi)=\sum_k w_k J_k(\pi)$ ですが、重み $w_k$ は“科学的に自動で決まる”ものではなく、用途（デジタルツインか架空キャラか、社内での利用か公開か）で決まる設計要件です。</p>
<h3 id="1012-「模倣」と「創作」を同じ評価で測ると壊れる">10.1.2　「模倣」と「創作」を同じ評価で測ると壊れる</h3>
<p>デジタルツインと架空キャラでは、根本の評価が違います。デジタルツインは「本人の過去の行動や発言と整合すること」が中心で、根拠のない創作は事故です。架空キャラは「設定と整合しつつ、状況に応じて創作的に振る舞うこと」が価値で、むしろ空白を埋める能力が求められます。</p>
<p>したがって評価では、少なくとも「どの情報を“事実”として固定し、どの情報を“創作可能”として扱うか」を明確にし、その境界を越えた出力をエラーとして扱う必要があります。第7章の長期記憶設計で、記憶項目に種類（観測・伝聞・推測・設定など）を付けたのは、この評価境界を作るためでもありました。</p>
<hr>
<h2 id="102-測定の基礎妥当性（validity）と信頼性（reliability）を押さえる">10.2　測定の基礎：妥当性（validity）と信頼性（reliability）を押さえる</h2>
<p>評価を「科学」にするために、心理測定（psychometrics）から最低限の概念を借ります。ここでのポイントは、モデルやアルゴリズムの前に、「測定がちゃんと測れているか」を点検できるようになることです。</p>
<h3 id="1021-信頼性測定はブレるそのブレを見積もる">10.2.1　信頼性：測定はブレる。そのブレを見積もる</h3>
<p>信頼性とは、「同じものを測るなら、測定結果が安定する」性質です。人物らしさ評価は多くが人手評価（人間の評定）を含むため、評定者によって点数がブレます。ブレを放置すると、改善したのか悪化したのか判定できません。</p>
<p>代表的な信頼性の指標として、評定者間一致（inter-rater agreement）と、内部一貫性（internal consistency）があります。</p>
<p>評定者間一致を最小に測る有名な指標が <strong>コーエンのカッパ係数（Cohen’s kappa）</strong> です。2人の評定者がカテゴリ（例えば「本人らしい／本人らしくない」）を付けるとき、観測一致率を $p_o$、偶然一致の期待値を $p_e$ とすると、</p>
<p>$$ \kappa=\frac{p_o-p_e}{1-p_e}$$ です（Cohen, 1960）。$\kappa=1$ なら完全一致、$\kappa=0$ なら偶然一致と同程度です。人物らしさ評価では、$\kappa$ が低い場合、モデルが悪い可能性もありますが、もっと頻繁には「評価基準が曖昧」か「タスクが曖昧」か「評定者が必要な情報を持っていない」ことが原因です。つまり、$\kappa$ はモデルの欠陥だけでなく、評価設計の欠陥を発見する検査にもなります。</p>
<p>内部一貫性の代表が <strong>クロンバックのアルファ（Cronbach’s alpha）</strong> です。複数の質問項目（例えば「一貫性」「礼儀」「根拠の明確さ」など）で同じ概念を測るとき、項目数を $K$、各項目の分散を $\sigma_i^2$、合計得点の分散を $\sigma_T^2$ とすると</p>
<p>$$ \alpha=\frac{K}{K-1}\left(1-\frac{\sum_{i=1}^{K}\sigma_i^2}{\sigma_T^2}\right)$$ です（Cronbach, 1951）。$\alpha$ が高いほど「項目が同じものを測っている」傾向がありますが、高ければ良いと単純化するのは危険です。人物らしさは多面的なので、むしろ異なる側面を混ぜれば $\alpha$ は下がります。大事なのは「何を同じ概念として束ねるか」を設計することです。</p>
<h3 id="1022-妥当性測りたいものを測れているか">10.2.2　妥当性：測りたいものを測れているか</h3>
<p>妥当性とは「測りたいもの（構成概念）を本当に測れているか」という性質です。例えば「丁寧な口調」を測って高得点でも、「本人らしさ」を測れているとは限りません。デジタルツイン評価でありがちな失敗は、流暢さや丁寧さが高いモデルが高得点になり、本人の判断傾向の再現が置き去りになることです。</p>
<p>心理測定では、妥当性を多面的に点検します。特に有名なのが Campbell & Fiske（1959）の多特性多方法行列（multitrait-multimethod matrix）で、同じ特性を異なる方法で測って一致する（収束妥当性：convergent validity）か、異なる特性は区別できる（弁別妥当性：discriminant validity）かを点検します。人物らしさ評価に翻訳すると、例えば「本人らしさ」を（i）人間評定、（ii）過去ログとの行動一致率、（iii）第三者が見分けられるか（識別テスト）、のように複数の方法で測り、同じ方向の結論が出るかを見ます。異なる側面（正確性、安全性、礼儀）を混ぜて評価する場合は、混ざり方が妥当かを同様に点検します。</p>
<hr>
<h2 id="103-評価データの作り方シナリオ（状況）を設計し答えの“不確実性”も扱う">10.3　評価データの作り方：シナリオ（状況）を設計し、答えの“不確実性”も扱う</h2>
<h3 id="1031-シナリオベース評価人物らしさは状況依存で現れる">10.3.1　シナリオベース評価：人物らしさは状況依存で現れる</h3>
<p>人物らしさは、一般論の説明よりも、状況依存の意思決定で露出します。したがって評価データは、自然言語の穴埋めではなく、状況（コンテクスト）を含むシナリオとして設計するのが有効です。第4章で述べた通り、行動は状況 $s$ と人物パラメータ $\theta$ に依存し、最小には $\pi_\theta(a\mid s)$ と書けました。評価は、この $\pi_\theta$ が狙いの人物（またはキャラ設定）の分布に近いかを測る問題になります。</p>
<p>通し例A（CEO/COO/CTO/CFO）では、シナリオは例えば「投資判断」「採用凍結」「障害対応」「価格改定」「法務リスクの顕在化」など、経営に典型的で、役職ごとの価値観が衝突しやすい局面を中心に作ります。通し例B（社内キャラ）では、「制度の案内」「トラブルシュート」「相談の整理」「チーム内摩擦の調停」など、役に立つ場面を中心に作ります。架空キャラの場合は、キャラの“信念”や“口癖”が出る状況も含めますが、評価の中心は見た目の口調よりも、行動選択（提案、確認、保留、拒否）の一貫性に置くと、改善に効く評価になります。</p>
<h3 id="1032-「正解」は一つとは限らない分布としての教師データ">10.3.2　「正解」は一つとは限らない：分布としての教師データ</h3>
<p>人物らしさ評価で最も重要な設計原則は、「正解を一つに固定しない」ことです。実在人物でも、同じ状況で必ず同じ判断をするわけではありません。架空キャラでも、作者が未定義の空白があれば複数の解釈があり得ます。</p>
<p>したがって教師データは、「唯一の正解」ではなく、「受け入れ可能な回答集合」や「好ましさの分布」として持つのが自然です。最小には、状況 $s$ に対して、望ましい行動 $a$ の分布 $p^*(a\mid s)$ を持つとします。モデルの分布を $p_\theta(a\mid s)$ とすると、行動一致を測る自然な損失は交差エントロピー（cross-entropy）です：</p>
<p>$$ \mathcal{L}(\theta)= -\mathbb{E}_{s}\left[\sum_{a} p^*(a\mid s)\log p_\theta(a\mid s)\right]$$ これは模倣学習（imitation learning）の最も基本形で、行動の確率分布を直接合わせる評価になります。実務では $p^*(a\mid s)$ を厳密に得るのは難しいので、複数の人間評定者や、本人の過去ログから「どの行動がどの程度らしいか」をラベルとして作ります。</p>
<h3 id="1033-ペア比較（A/B評価）を中心にする人は絶対点より相対比較が得意">10.3.3　ペア比較（A/B評価）を中心にする：人は絶対点より相対比較が得意</h3>
<p>人間は「100点満点で採点」より、「AとBならどちらが本人らしいか」という相対比較の方が安定しやすいことが多いです。この相対比較は、統計的に扱いやすいモデルが古くからあり、代表が <strong>ブラッドリー＝テリー（Bradley–Terry）モデル</strong> です（Bradley & Terry, 1952）。候補 $i$ と $j$ の“強さ”を $s_i, s_j$ とすると、$i$ が $j$ に勝つ確率を</p>
<p>$$P(i \succ j)=\sigma(s_i-s_j)=\frac{1}{1+\exp(-(s_i-s_j))}$$ と置き、比較結果から $s_i$ を推定します。これはChatbot Arenaのようなモデル比較でも本質的に使われる考え方です。人物らしさ評価でも、デジタルツインの複数バージョンや、異なる記憶設計、異なる会議プロトコルを比較するときに、ペア比較は強い道具になります。</p>
<hr>
<h2 id="104-主要メトリクス一貫性・根拠・検索・校正（calibration）を数式で測る">10.4　主要メトリクス：一貫性・根拠・検索・校正（calibration）を数式で測る</h2>
<p>この節では、人物らしさに直結しやすい評価指標を、なるべく「改善に効く」形で整理します。ここで重要なのは、メトリクスは“点数”ではなく“診断”である、という姿勢です。点数が上がってもシステムが良くなるとは限りません。どこが悪いかを分解して示す指標が価値になります。</p>
<h3 id="1041-意思決定の忠実度分布距離（KLダイバージェンス）と後悔（regret）">10.4.1　意思決定の忠実度：分布距離（KLダイバージェンス）と後悔（regret）</h3>
<p>状況 $s$ における望ましい行動分布が $p^*(a\mid s)$、モデルが $p_\theta(a\mid s)$ を出すとき、分布の近さを測る代表が <strong>カルバック＝ライブラー・ダイバージェンス（Kullback–Leibler divergence, KL）</strong> です：</p>
<p>$$D_{\mathrm{KL}}(p^*|p_\theta)=\sum_a p^*(a\mid s)\log\frac{p^*(a\mid s)}{p_\theta(a\mid s)}$$ これは「教師分布の下で、モデルがどれだけ見当違いな確率を割り当てたか」を測ります。デジタルツインでは、本人が選びがちな行動（例えばCFOなら“条件付き賛成”）に低確率を割り当てると、KLが大きくなります。</p>
<p>もう一つ、意思決定の質を測る重要な概念が <strong>後悔（regret）</strong> です。環境における行動の価値（効用）を (U(s,a)) とし、最適行動を $a^*(s)=\arg\max_a U(s,a)$ とすると、モデルが選んだ行動 $a$ の後悔は</p>
<p>$$ \mathrm{Regret}(s)=U(s,a^*(s)) - U(s,a) $$</p>
<p>です。デジタルツイン評価では、後悔を最小化することが必ずしも目的ではありません。本人が合理的でない判断をするなら、それも再現されるべきです。しかし会社シミュレーションや社内キャラでは、「役に立つ」ことを目標にするなら後悔の小ささが重要になります。つまり、デジタルツインは忠実度（本人に似ているか）を重視し、社内キャラは有用性（後悔が小さいか）を重視しやすい、という評価の違いがここに現れます。</p>
<h3 id="1042-不確実性表明の質適切な校正（calibration）">10.4.2　不確実性表明の質：適切な校正（calibration）</h3>
<p>第6章で述べた通り、人物らしさと信頼は「断言・推測・保留の使い分け」に強く依存します。そこで重要になるのが <strong>確率予測の校正（calibration）</strong> です。校正とは、モデルが「確信度 $p$ で正しい」と言ったとき、本当に $p$ の割合で正しい、という性質です。</p>
<p>校正を測る代表が <strong>ブライアスコア（Brier score）</strong> です（Brier, 1950）。二値事象（正しい＝1、誤り＝0）に対し、予測確率を $p_i$、実現を $y_i\in{0,1}$ とすると、</p>
<p>$$ \mathrm{BS}=\frac{1}{N}\sum_{i=1}^{N}(p_i-y_i)^2$$ です。小さいほど良い。校正を理論的に扱うには、<strong>正則（厳密）適切スコアリングルール（strictly proper scoring rule）</strong> という考え方があり、代表的整理として Gneiting & Raftery（2007）がよく引用されます。ここでの要点は、適切なスコアを採用すると、モデルは「正直な確率」を出すことが得になる、ということです。人物らしいAIでも、確信度を出させるなら、校正されているかを評価し、過度な断言が得にならないように学習・運用を設計する必要があります。</p>
<p>実務でよく使われる校正指標として、期待校正誤差（Expected Calibration Error: ECE）もあります。確信度をビンに分け、ビン内の平均確信度と実際の正解率の差を集計します。深層学習モデルの校正問題を広く示した研究として Guo et al.（2017）が有名です。</p>
<h3 id="1043-長期一貫性矛盾率と自己整合">10.4.3　長期一貫性：矛盾率と自己整合</h3>
<p>長期一貫性を評価する最小の指標は「矛盾率」です。これは、ある会話や一連の意思決定の中で、「過去に自分が置いた前提・合意・主張」と矛盾する主張をどれだけ出したか、という割合です。矛盾の判定は難しいですが、少なくとも“同じ質問を別の言い方で複数回問う”ことで、自己整合性（self-consistency）をチェックできます。</p>
<p>自己整合性という言葉は推論分野でも使われますが（Wang et al., 2022）、ここでは「過去ログに対する整合」と「同一条件での再現性」を含めた意味で使います。デジタルツインでは、再現性が高いほど良いとは限りません（本人が気分で変わるなら変動も本人らしさ）。しかし、根拠がないのに変動するのは危険です。そこで評価では、変動を「根拠が変わったのか」「観測が変わったのか」「単にブレたのか」に分解できるログ設計（第7章・第8章）が重要になります。</p>
<h3 id="1044-検索と記憶参照の評価情報検索（IR）メトリクスを使う">10.4.4　検索と記憶参照の評価：情報検索（IR）メトリクスを使う</h3>
<p>第7章の記憶検索は、情報検索（Information Retrieval: IR）の問題です。したがってIRのメトリクスがそのまま使えます。</p>
<p>検索対象集合から、正解文書（参照すべき記憶）があるとき、上位 $k$ 件の適合率（precision@k）と再現率（recall@k）は</p>
<p>$$ \mathrm{Precision@k}=\frac{\#(\text{上位kの中の正解})}{k},\quad \mathrm{Recall@k}=\frac{\#(\text{上位kの中の正解})}{\#(\text{正解総数})}$$ です。さらに、正解が何番目に出てくるかを評価する平均逆順位（Mean Reciprocal Rank: MRR）は</p>
<p>$$ \mathrm{MRR}=\frac{1}{N}\sum_{i=1}^{N}\frac{1}{\mathrm{rank}_i}$$ で、$\mathrm{rank}_i$ はクエリ $i$ に対する最初の正解の順位です。段階的関連度（どれが最も重要な根拠か）を扱うには NDCG（Normalized Discounted Cumulative Gain）が有名で、Järvelin & Kekäläinen（2002）が体系化しました。DCGを</p>
<p>$$ \mathrm{DCG@k}=\sum_{i=1}^{k}\frac{2^{rel_i}-1}{\log_2(i+1)}$$ と定義し、理想ランキングの DCG（IDCG）で割って正規化したものが NDCG です。</p>
<p>人物らしさにおいて検索メトリクスが重要なのは、検索が悪いと「本人らしくない」以前に、そもそも根拠が抜けるからです。デジタルツインが本人の過去発言を参照できないなら、推測で補完し、捏造に近づきます。社内キャラが規程を参照できないなら、一般論で埋め、事故に近づきます。検索は“周辺機能”ではなく、人物らしさと安全の根幹です。</p>
<h3 id="1045-根拠に基づく生成（faithfulness）引用と主張の対応を評価する">10.4.5　根拠に基づく生成（faithfulness）：引用と主張の対応を評価する</h3>
<p>検索をしても、参照した根拠と生成した主張がズレると意味がありません。そこで、生成が根拠に忠実か（faithful）を評価する必要があります。これは要約の事実性評価や、根拠付き生成の研究で長年議論されてきました。近年の長文生成の事実性評価として、主張を原子化（atomic facts）して検証する FactScore のような提案があります（Min et al., 2023）。また、外部根拠がなくても自己一貫性から幻覚を検知するアプローチとして SelfCheckGPT が提案されています（Manakul et al., 2023）。これらは万能ではありませんが、「根拠と主張を別物として扱い、対応関係を評価する」という姿勢を教えてくれます。</p>
<hr>
<h2 id="105-人手評価の設計主観を“データ”として扱う方法">10.5　人手評価の設計：主観を“データ”として扱う方法</h2>
<h3 id="1051-Turingテストの限界見た目の自然さは安全も忠実度も保証しない">10.5.1　Turingテストの限界：見た目の自然さは安全も忠実度も保証しない</h3>
<p>人間らしさの古典的評価として、チューリングテスト（Turing, 1950）が有名です。しかしチューリングテストは、相手が人間か機械かを見分けられないか、という「外形的自然さ」の試験であり、デジタルツインの忠実度や、社内キャラの正確性、安全性を保証しません。むしろ、見分けられないほど流暢な誤りは危険です（第6章の信頼の議論）。</p>
<p>したがって本書の目的では、Turingテスト的な「騙せるか」ではなく、「根拠に基づいているか」「意思決定が一貫しているか」「安全境界を守れるか」を評価の中心に置きます。自然さは重要ですが、主指標にすると評価が歪みやすいので、補助指標として扱うのが安全です。</p>
<h3 id="1052-ペア比較とElo人間評定を統計モデルで吸収する">10.5.2　ペア比較とElo：人間評定を統計モデルで吸収する</h3>
<p>人手評価はブレます。そこで、ペア比較の結果を確率モデルに落として集約します。Bradley–Terryモデルはその一つでした。もう一つ、実務で分かりやすい集約法が <strong>Eloレーティング</strong> です（Elo, 1978）。これは本来チェスのレーティングですが、モデル比較にも応用されます。モデルAのレーティングを $R_A$、Bを $R_B$ とすると、Aが勝つ期待確率を</p>
<p>$$E_A=\frac{1}{1+10^{(R_B-R_A)/400}}$$ と置き、実際の勝敗結果 $S_A\in{0,1}$ に基づいて</p>
<p>$$ R_A \leftarrow R_A + K(S_A - E_A) $$</p>
<p>で更新します。ここで $K$ は更新の強さです。会話モデルの評価では、同じプロンプト集合でもモデルの強さが大まかに比較でき、改善の方向性を掴みやすくなります。</p>
<p>ただし注意が必要です。ペア比較は「どちらが良いか」を測るので、「どこが悪いか」の診断には弱い。そこで、ペア比較は総合順位付けに使い、診断は別の細分化メトリクス（矛盾率、検索精度、校正、根拠忠実度など）で行うのが良い分業です。</p>
<h3 id="1053-評定者への指示（ルーブリック）を“操作変数”として設計する">10.5.3　評定者への指示（ルーブリック）を“操作変数”として設計する</h3>
<p>評定者に何を見せ、何を評価させるかは、実験条件そのものです。例えば「本人らしいか」を評価させるとき、評定者が本人を知らないなら評価は不可能に近い。評定者が知っているとしても、何を根拠に本人らしいと判断してよいか（過去ログの提示、役職の説明、会議の前提資料）を揃えないと、評定は雑音になります。</p>
<p>評価では「評定者を教育する」のではなく、「評定者が安定に判断できる情報構造を作る」ことが核心です。そのためには、（i）評価項目を定義し、（ii）良い例と悪い例を少数提示し、（iii）迷いやすい境界（例えば“丁寧だが本人らしくない”）をルール化し、（iv）評定者間一致（$\kappa$ など）で妥当性を点検し、必要なら項目定義を更新します。これは心理測定でいう構成概念の明確化と同じ作業です。</p>
<hr>
<h2 id="106-自動評価LLM-as-a-Judge-の利点と落とし穴そして「二段階評価」">10.6　自動評価：LLM-as-a-Judge の利点と落とし穴、そして「二段階評価」</h2>
<h3 id="1061-自動評価が必要な理由回帰テスト（regression-test）としての評価">10.6.1　自動評価が必要な理由：回帰テスト（regression test）としての評価</h3>
<p>人物らしいAIを開発すると、記憶設計やツール利用、会議プロトコルなど、多くの部品を変更します。すると「前はできていたことが壊れる」回帰（regression）が頻繁に起こります。そこで、評価は一度きりのベンチマークではなく、継続的に回す回帰テストとして機能する必要があります。これには自動評価が不可欠です。</p>
<p>ただし自動評価には限界があります。特に「本人らしさ」や「会議の妥当性」は、完全自動で測るのが難しい。したがって現実的な方針は、評価を二段階に分けることです。第一段階は自動評価で「明らかな失敗」を高速に弾く（根拠ゼロ断言、検索が外れている、矛盾、スキーマ違反など）。第二段階は人手評価で「微妙な品質」を測る（本人らしさ、説得力、会議の納得感など）。この二段階にすると、コストを抑えつつ品質を上げられます。</p>
<h3 id="1062-LLM-as-a-Judge人間評定を代理するという発想">10.6.2　LLM-as-a-Judge：人間評定を代理するという発想</h3>
<p>近年、別の大規模言語モデルに評価させる、いわゆる LLM-as-a-Judge が広く使われるようになりました。代表例として MT-Bench と Chatbot Arena があり、モデル同士の応答を比較評価する枠組みが提案されています（Zheng et al., 2023）。また、指示追従モデルの比較として AlpacaEval のような評価枠組みも提案されています（Dubois et al., 2023）。</p>
<p>この発想は強力です。なぜなら、評価そのものが自然言語理解を必要とし、ルーブリック適用が難しいからです。評価モデルを使うと、大量の比較が低コストで可能になります。</p>
<p>しかし落とし穴も明確です。第一に、評価モデルのバイアスが入ることです。丁寧な口調や長い説明が高評価になり、実際の正確性や本人らしさが置き去りになることがあります。第二に、同じモデル系列で評価すると、文体の近さが過大評価される可能性があります。第三に、評価モデルも幻覚するので、評価の根拠が壊れることがあります。したがって LLM-as-a-Judge は「人間評価の置き換え」ではなく、「人間評価を増幅する補助」として使うのが安全です。</p>
<p>実務的な対策としては、（i）評価モデルを複数用意し、平均や多数決で安定化する、（ii）評価の入力に根拠（引用・参照）を含め、根拠忠実度を評価させる、（iii）評価モデルの判断と人間判断の相関を定期的に点検する、（iv）評価モデルが出した理由を監査し、明らかな誤判定を除外する、といった運用が必要になります。</p>
<h3 id="1063-ベンチマークの使い方一般能力の測定と人物らしさの測定を分ける">10.6.3　ベンチマークの使い方：一般能力の測定と、人物らしさの測定を分ける</h3>
<p>LLMの一般能力を測るベンチマークとして、HELM（Liang et al., 2022）や BIG-bench（Srivastava et al., 2022）などがあります。また、真実性の観点では TruthfulQA（Lin et al., 2022）が広く知られています。これらは、あなたの人物らしさシステムを設計するときにも役に立ちますが、そのまま「人物らしさ」の評価にはなりません。</p>
<p>正しい使い方は分業です。一般ベンチマークは「基礎学力」の測定として使い、人物らしさは「あなたが設計したシナリオ」と「あなたが定義した評価軸」で測ります。例えば社内キャラは、一般の百科知識ベンチマークで高得点でも、社内規程の案内が間違っていれば失格です。逆にデジタルツインは、一般の正確性ベンチマークでやや劣っても、本人の判断傾向を忠実に再現できるなら価値があります。評価は目的に従属します。</p>
<hr>
<h2 id="107-頑健性評価分布シフト敵対入力そして“誤情報の増幅”を測る">10.7　頑健性評価：分布シフト、敵対入力、そして“誤情報の増幅”を測る</h2>
<h3 id="1071-分布シフト訓練と本番の状況は違う">10.7.1　分布シフト：訓練と本番の状況は違う</h3>
<p>人物らしさシステムは、必ず分布シフト（distribution shift）に直面します。デジタルツインが想定していない新規事業、架空キャラが想定していない相談、会社シミュレーションの突発イベントなどです。分布シフト下では、一般に性能が落ちます。だからこそ評価では、通常ケースだけでなく、境界ケース（例外、矛盾、情報不足、緊急時）を意図的に含める必要があります。</p>
<p>評価を数式で書くなら、通常分布 $P_{\mathrm{train}}(s)$ ではなく、より広い分布 $P_{\mathrm{deploy}}(s)$ での期待性能を評価したい。しかし $P_{\mathrm{deploy}}$ は未知です。そこで実務では、テスト分布を複数用意し（通常・ストレス・敵対・無情報など）、各分布での性能を並べて、最低性能（worst-case）も見るのが現実的です。最小には</p>
<p>$$J_{\min}(\pi)=\min_{e\in \mathcal{E}} \ \mathbb{E}_{s\sim P_e}[J(\pi;s)$$ のように、環境集合 $\mathcal{E}$ の中で最悪の期待性能を見る、という評価が設計判断に効きます。</p>
<h3 id="1072-誤情報カスケードの評価複数エージェントの特有失敗">10.7.2　誤情報カスケードの評価：複数エージェントの特有失敗</h3>
<p>第9章で述べた通り、複数エージェントでは、誤情報が会話を通じて増幅する危険があります。したがって評価では、単体の正確性だけでなく、集団としての誤り増幅を測ります。</p>
<p>実務的には、会議シミュレーションで「1つだけ誤った前提を混ぜた」シナリオを作り、その誤りが（i）誰かに指摘されて修復されるか、（ii）指摘されずに合意されるか、（iii）検証役が止められるか、を測ります。これは第8章の失敗検知を、マルチエージェントに拡張した評価です。会議の制度（検証役、資料要求プロトコル、独立思考フェーズ）を導入した場合に、この誤り増幅率が下がるなら、その制度設計は“効いている”と評価できます。</p>
<hr>
<h2 id="108-運用監査とドリフト検知良いモデルも時間で劣化する">10.8　運用監査とドリフト検知：良いモデルも時間で劣化する</h2>
<p>評価は開発だけで終わりません。運用に入ると、ユーザー、話題、社内規程、会社の状況が変わり、モデルはドリフトします。ドリフトには二種類あります。入力分布の変化（data drift）と、意味の変化（concept drift）です。例えば、相談内容の話題が変わるのは data drift で、同じ言葉の意味が社内で変わる（制度改定など）のは concept drift に近い。</p>
<h3 id="1081-ログ設計何を残すと監査できるか">10.8.1　ログ設計：何を残すと監査できるか</h3>
<p>監査可能性の中核はログです。第7章・第8章の議論から、最低限、次の情報はログとして残せる形にしておくと強いです。すなわち「入力（ユーザー発話と状況）」「参照した記憶・文書」「ツール呼び出し（引数と出力）」「生成した主張（可能なら原子化）」「確信度や保留表明」「実行系の操作（あれば）」「最終応答」です。</p>
<p>ここで重要なのは、ログは「大量に残す」ことではなく、「後で“なぜそう言ったか”を再構成できる」ことです。再構成できないログは、ただのデータ廃棄物になります。特にデジタルツインでは、本人名義の発言と誤解される危険があるため、「どの根拠に基づくか」を追跡できるログは必須です。</p>
<h3 id="1082-ドリフト検知を数式で書く分布距離と変化点検知">10.8.2　ドリフト検知を数式で書く：分布距離と変化点検知</h3>
<p>入力の話題分布が変わったかを検知するには、分布距離が使えます。例えば、トピック分類器や埋め込みクラスタで入力をカテゴリ化し、時刻 $t$ の分布を $P_t$、過去の基準分布を $P_0$ とすると、KLダイバージェンス</p>
<p>$$D_{\mathrm{KL}}(P_t|P_0)=\sum_x P_t(x)\log\frac{P_t(x)}{P_0(x)}$$ が大きくなったらドリフトの兆候、といった監視ができます。KLが不安定なら Jensen–Shannon divergence（対称で有限）を使うこともあります。</p>
<p>さらに「ある時点で急に変わった」を検知するには、変化点検知（change-point detection）の古典である CUSUM（累積和管理）や Page–Hinkley テストなどが使われます。例えば誤り率 $e_t$ の平均が変わったかを見るとき、平均との差の累積和を $S_t$ として</p>
<p>$$ S_t=\max(0, S_{t-1} + (e_t-\mu_0) - k) $$</p>
<p>のように更新し、閾値を超えたらアラートを出す、という管理図の発想です（詳細な理論整理は Basseville & Nikiforov『Detection of Abrupt Changes』（1993）などが古典です）。ここでのポイントは、監視は“モデルの中身”ではなく“外に現れる指標”でできる、ということです。</p>
<h3 id="1083-運用評価は「テストの自動化」に似ている">10.8.3　運用評価は「テストの自動化」に似ている</h3>
<p>運用の監査と評価は、ソフトウェアテストに非常に似ています。回帰テスト（以前できたことができるか）、カナリアリリース（少数ユーザーで試す）、アラート（異常検知）などはそのまま移植できます。人物らしさシステムではさらに、（i）根拠参照の失敗、（ii）過度な断言、（iii）安全境界違反、（iv）複数エージェント会議の誤情報増幅、といった特有の失敗モードを監視対象に含めます。評価は、開発のための計測であると同時に、運用のための安全装置でもあります。</p>
<hr>
<h2 id="109-通し例A/B評価設計を「そのまま改善ループ」に接続する">10.9　通し例A/B：評価設計を「そのまま改善ループ」に接続する</h2>
<h3 id="1091-通し例ACEO/COO/CTO/CFO-デジタルツインの評価">10.9.1　通し例A：CEO/COO/CTO/CFO デジタルツインの評価</h3>
<p>デジタルツインの評価は、本人の過去ログ（議事録、メール、メモ）と、関係者の判断（その人を知る評価者）を両方使うのが現実的です。ここで最初にやるべきは、「本人の判断が露出するシナリオ」を作ることです。例えば投資判断シナリオなら、同じ投資案件に対し、キャッシュ状況や競合状況、障害状況を変えた反実仮想（counterfactual）を用意し、判断がどう変わるべきか（あるいは変わらないべきか）を評価します。本人の過去ログがある条件では、根拠参照ができるかを厳しく見る。ログがない条件では、保留・確認・条件提示ができるかを評価し、勝手な“本人経験”の捏造を重い減点にします。</p>
<p>測定は、（i）ペア比較で総合順位を作り（Bradley–Terry/Elo）、（ii）診断指標で内訳を取ります。診断指標には、検索精度（precision@k/recall@k）、根拠忠実度（引用と主張の対応）、矛盾率、校正（Brier/ECE）を含める。これらが改善したのに総合順位が落ちたなら、ルーブリックがずれているか、評価者が“見た目”に引っ張られている可能性があり、妥当性点検（10.2）が必要になります。</p>
<p>最後に重要なのは、デジタルツインは「本人の代理として実行しない」ことです。評価で高得点でも、運用で世界を変える権限を与えるのは別問題です（第8章の最小権限）。評価は、その境界線の設計まで含めて行うべきです。</p>
<h3 id="1092-通し例B社内で役に立つ架空キャラの評価">10.9.2　通し例B：社内で役に立つ架空キャラの評価</h3>
<p>架空キャラは、忠実度の対象が「実在人物」ではなく「設定（カノン）」です。したがって評価は、（i）カノン整合性（設定と矛盾しないか）、（ii）有用性（相談者の後悔を減らせるか）、（iii）安全境界（過信を誘発しないか、機密を扱わないか）、（iv）会話の社会性（礼儀と信頼維持）、に分解できます。</p>
<p>カノン整合性は、矛盾率と類似の評価が使えます。設定文書や過去発言（キャラの“公式発言”）と矛盾する主張が出たら減点です。一方で未定義領域の創作は、妥当な範囲で許容されます。ここで「許容される創作の境界」を明示しないと、評価者の好みで点数がブレます。したがって、評定者ルーブリックに「設定を変更する発言は不可」「未定義を補う創作は可。ただし既存発言と整合すること」といったルールを入れ、$\kappa$ で一致を点検します。</p>
<p>有用性は、状況 $s$ の下での後悔（regret）やタスク達成率（例えば「正しい申請フローに到達できたか」）で測れます。さらに運用では、ユーザー満足や再利用率などの指標も見ますが、これらは“楽しいキャラ”に偏りやすく、正確性や安全性とトレードオフになります。したがって、運用指標は多目的として扱い、最低限の安全・正確性を満たさない限り「面白さ」で補えないように評価設計を組みます。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしいAIを開発・運用するための評価を、「測定論（妥当性と信頼性）」「メトリクス設計」「自動評価と人手評価の二段階」「頑健性評価」「運用監査とドリフト検知」という流れで体系化しました。</p>
<p>重要なメッセージは三つです。第一に、人物らしさは単一スコアではなく多目的であり、用途ごとに優先順位が変わる。第二に、評価はモデルの点数付けではなく、改善のための診断であり、検索・根拠・校正・矛盾といった分解指標が効く。第三に、評価は開発で終わらず、監査とドリフト検知として運用の安全装置になる。</p>
<p>次の章では、評価で見つかった課題を「モデル更新」へどうつなげるかを扱います。具体的には、データ収集、フィードバックの形式（ペア比較、コメント、エラー分類）、学習方法（教師あり学習、選好学習、強化学習、人間の介入）、そして人格・設定のドリフトを防ぐ更新規律を、理論と実務の両面から整理します。</p>
<hr>
<h2 id="参考文献（本章で言及した主要出典）">参考文献（本章で言及した主要出典）</h2>
<p>Turing, A. M. (1950). “Computing Machinery and Intelligence.” *Mind*. <a href="https://doi.org/10.1093/mind/LIX.236.433" target="_blank">https://doi.org/10.1093/mind/LIX.236.433</a>)</p>
<p>Campbell, D. T., & Fiske, D. W. (1959). “Convergent and discriminant validation by the multitrait-multimethod matrix.” *Psychological Bulletin*. <a href="https://doi.org/10.1037/h0046016" target="_blank">https://doi.org/10.1037/h0046016</a>)</p>
<p>Cohen, J. (1960). “A coefficient of agreement for nominal scales.” *Educational and Psychological Measurement*. <a href="https://doi.org/10.1177/001316446002000104" target="_blank">https://doi.org/10.1177/001316446002000104</a>)</p>
<p>Cronbach, L. J. (1951). “Coefficient alpha and the internal structure of tests.” *Psychometrika*. <a href="https://doi.org/10.1007/BF02310555" target="_blank">https://doi.org/10.1007/BF02310555</a>)</p>
<p>Brier, G. W. (1950). “Verification of forecasts expressed in terms of probability.” *Monthly Weather Review*. <a href="https://doi.org/10.1175/1520-0493%281950%29078" target="_blank">https://doi.org/10.1175/1520-0493(1950)078</a> 078)<0001:VOFETI>2.0.CO;2</p>
<p>Gneiting, T., & Raftery, A. E. (2007). “Strictly Proper Scoring Rules, Prediction, and Estimation.” *Journal of the American Statistical Association*. <a href="https://doi.org/10.1198/016214506000001437" target="_blank">https://doi.org/10.1198/016214506000001437</a>)</p>
<p>Guo, C., Pleiss, G., Sun, Y., & Weinberger, K. Q. (2017). “On Calibration of Modern Neural Networks.” <a href="https://arxiv.org/abs/1706.04599" target="_blank">https://arxiv.org/abs/1706.04599</a>)</p>
<p>Bradley, R. A., & Terry, M. E. (1952). “Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.” *Biometrika*. <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a>)</p>
<p>Elo, A. E. (1978). *The Rating of Chessplayers, Past and Present.* Arco.（概説と式の参照例） <a href="https://www.glicko.net/research/acjpaper.pdf" target="_blank">https://www.glicko.net/research/acjpaper.pdf</a>)</p>
<p>Järvelin, K., & Kekäläinen, J. (2002). “Cumulated gain-based evaluation of IR techniques.” *ACM TOIS*. <a href="https://doi.org/10.1145/582415.582418" target="_blank">https://doi.org/10.1145/582415.582418</a>)</p>
<p>Liang, P., Bommasani, R., et al. (2022). “Holistic Evaluation of Language Models (HELM).” <a href="https://arxiv.org/abs/2211.09110" target="_blank">https://arxiv.org/abs/2211.09110</a>)</p>
<p>Srivastava, A., et al. (2022). “BIG-bench: Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models.” <a href="https://arxiv.org/abs/2206.04615" target="_blank">https://arxiv.org/abs/2206.04615</a>)</p>
<p>Lin, S., Hilton, J., & Evans, O. (2022). “TruthfulQA: Measuring How Models Mimic Human Falsehoods.” <a href="https://arxiv.org/abs/2109.07958" target="_blank">https://arxiv.org/abs/2109.07958</a>)</p>
<p>Min, S., et al. (2023). “FActScore: Fine-grained Evaluation of Factuality in Long-form Text Generation.” <a href="https://arxiv.org/abs/2305.14251" target="_blank">https://arxiv.org/abs/2305.14251</a>)</p>
<p>Manakul, P., Liusie, A., & Gales, M. (2023). “SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models.” <a href="https://arxiv.org/abs/2303.08896" target="_blank">https://arxiv.org/abs/2303.08896</a>)</p>
<p>Zheng, L., Chiang, W.-L., et al. (2023). “Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.” <a href="https://arxiv.org/abs/2306.05685" target="_blank">https://arxiv.org/abs/2306.05685</a>)</p>
<p>Dubois, Y., et al. (2023). “AlpacaEval: An Automatic Evaluator of Instruction-following Models.” <a href="https://arxiv.org/abs/2304.02023" target="_blank">https://arxiv.org/abs/2304.02023</a>)</p>
<p>Basseville, M., & Nikiforov, I. V. (1993). *Detection of Abrupt Changes: Theory and Application.* Prentice Hall. （概説情報） <a href="https://hal.science/hal-01357983/document" target="_blank">https://hal.science/hal-01357983/document</a>)</p>
<h1 id="第11章-学習と更新人物らしさを改善し続けるためのデータ・最適化・ドリフト制御">第11章　学習と更新：人物らしさを改善し続けるためのデータ・最適化・ドリフト制御</h1>
<p>第10章では、人物らしさを「測る」ために、妥当性（validity）と信頼性（reliability）を押さえ、シナリオ設計・人手評価・自動評価・運用監査までを体系化しました。評価が整うと、次に必ず出てくる問いはこうです。</p>
<p>「評価で見つかった欠点を、どうやって直すのか。直した結果、別の能力が壊れていないことをどう担保するのか。そして、時間が経って状況やデータが変わっても、人物らしさが崩れないようにどう運用するのか。」</p>
<p>この章は、その問いに答える章です。話題は「学習（training）」と「更新（update）」です。ただし、ここでいう更新は、ニューラルネットの重み（パラメータ）を更新することだけを指しません。人物らしさのシステムは、外部記憶（第7章）、ツール利用（第8章）、複数エージェントの会議制度（第9章）など、多くの部品の組み合わせで動きます。多くの場合、重みを動かすより先に、記憶ストアや検索インデックス、会議プロトコル、評価の設計を直した方が、安く、速く、安全に改善します。逆に、重みの更新は強力ですが、失敗すると「人格のドリフト（意図しない変質）」や「以前できていたことの破壊（回帰）」を引き起こします。</p>
<p>したがって本章では、更新対象を分解し、どの更新がどんな失敗モードを持つかを理解した上で、教師あり微調整（supervised fine-tuning）、選好学習（preference learning）、強化学習（reinforcement learning）、継続学習（continual learning）、知識編集（model editing）を、人物らしさの実務に接続していきます。通し例としては、実在人物のデジタルツイン（CEO/COO/CTO/CFO）と、社内で役に立つ架空キャラの両方を扱い、同じ学習手法でも「許される更新」と「やってはいけない更新」が異なることを明確にします。</p>
<hr>
<h2 id="111-「更新」とは何を更新することか重みだけが学習ではない">11.1　「更新」とは何を更新することか：重みだけが学習ではない</h2>
<h3 id="1111-人物らしいシステムの全体像を確率分布として書く">11.1.1　人物らしいシステムの全体像を確率分布として書く</h3>
<p>大規模言語モデル（Large Language Model: LLM）は、入力テキスト $x$ を受けて出力テキスト $y$ を生成する確率分布 $p_\theta(y\mid x)$ として表せます。ここで $\theta$ はモデルのパラメータ（重み）です。しかし第7章・第8章で見たように、実際の人物らしいシステムは、外部記憶ストア $M$、検索器 $R$、ツール集合 $\mathcal{T}$、会話状態 $h$（対話履歴）、会議プロトコル $\Pi$（第9章）などを含みます。すると、実際にモデルへ入る「最終コンテクスト」は、これらの関数として組み立てられ、出力分布は概念的に</p>
<p>$$ p(y \mid x; \theta, M, R, \mathcal{T}, \Pi) $$</p>
<p>のような形になります。</p>
<p>この式が示す重要な事実は、「人物らしさの不具合」は、$\theta$ の問題とは限らない、ということです。たとえば本人らしい判断が出ない原因が、モデルの能力不足ではなく、必要な過去ログを検索できていない（第7章）ことだった、ということは頻繁に起きます。あるいは、会議が不自然に同調する原因が、各役員の人格ではなく、情報共有の順序が悪い（第9章）ことだった、ということも起きます。</p>
<p>したがって更新戦略の基本は「なるべく局所的で可逆な更新から始める」ことです。可逆とは、元に戻せるという意味です。外部記憶の書き込み規則や検索の重みを変えるのは、多くの場合、重みの学習より可逆です。会議プロトコルの変更も可逆です。一方で重み更新は、元の挙動を完全に復元するのが難しく、回帰が起きやすい。これが更新戦略の順序を決めます。</p>
<h3 id="1112-更新対象の階層軽い更新から重い更新へ">11.1.2　更新対象の階層：軽い更新から重い更新へ</h3>
<p>人物らしさの改善は、経験的に次の順序で効きやすいことが多いです。最初に「記憶・検索・ツール」の設計（第7章・第8章）を直し、次に「会話や会議の制度」を直し（第6章・第9章）、それでも足りないところに「学習」を当てます。この順序は、単なる好みではなく、失敗コストの非対称性から来ています。</p>
<p>重み更新は、うまくいけば大きく効きますが、うまくいかなければ人格のドリフトを起こし、しかも原因が追いにくい。一方、検索の改善やプロトコル変更は、原因と結果の対応が比較的追いやすく、評価（第10章）を回しながら改善しやすい。このため、学習を議論するときも「何を学習で解決し、何をシステム設計で解決するか」を常に意識します。</p>
<hr>
<h2 id="112-データ設計何を集めどうラベル付けしどう混ぜるか">11.2　データ設計：何を集め、どうラベル付けし、どう混ぜるか</h2>
<p>学習はデータが全てです。しかし人物らしさのデータは、一般の機械学習より難しい特徴があります。第一に、正解が一つではない（第10章）。第二に、実在人物のデータはプライバシーや権利の制約が強い。第三に、会話は文脈依存で、単発のQAより「一連の意思決定」の方が重要です。第四に、複数エージェントでは「相互作用のログ」がデータになるため、個々の発話だけを切り出すと性質が失われます。</p>
<h3 id="1121-教師データを「行動データ」として整形する">11.2.1　教師データを「行動データ」として整形する</h3>
<p>人物らしさを学習させたいとき、多くの人が最初にやりがちなのは「本人の文章を大量に集めて学習する」ことです。もちろん文体の模倣には効きます。しかし人物らしさの中心は文体ではなく意思決定だと本書は繰り返し述べてきました。意思決定を学ぶには、文章の断片よりも「状況 $s$ と行動 $a$」としてデータを整形する方が効きます。</p>
<p>会話における行動 $a$ は、単なる応答テキストではなく、「提案」「保留」「条件提示」「追加質問」「拒否」「合意」「宿題化」などの発話行為（第6章）を含みます。従って、教師データは可能なら</p>
<p>$$ (s_t, a_t, y_t) $$</p>
<p>の形、つまり状況 $s_t$（議題、制約、参照可能な資料など）、行動ラベル $a_t$（発話行為の種類）、実際の表現 $y_t$（自然言語の発話）を持つ構造にしておくと、学習が安定しやすい。行動ラベルが難しければ、少なくとも「この場面では追加質問をすべき」「この場面では断言すべきではない」といった高レベルの意図ラベルを付けるだけでも効果があります。</p>
<h3 id="1122-選好データ絶対評価より比較の方が作りやすい">11.2.2　選好データ：絶対評価より比較の方が作りやすい</h3>
<p>人物らしさの「正解」を作るのは難しいですが、「AとBのどちらが本人らしいか」「どちらが安全か」「どちらが役に立つか」という比較は、比較的作りやすいことが多い（第10章の議論）でした。これは学習にも直結します。選好データは、後述する選好学習や強化学習の土台になります。</p>
<p>選好データは典型的には、同じ状況 $x$ に対し、二つの応答 $y^+$（好ましい）と $y^-$（好ましくない）を用意し、比較ラベルを付けたデータ</p>
<p>$$ (x, y^+, y^-) $$</p>
<p>として表現します。重要なのは、選好の軸を混ぜないことです。デジタルツインでは「本人らしさ」を軸にするのか「会社にとっての合理性」を軸にするのかでラベルが変わります。架空キャラでも「カノン整合性」と「面白さ」を混ぜると評価が壊れます。選好データは“何を最適化したいか”をデータとして固定する行為なので、軸設計は第10章の構成概念設計そのものです。</p>
<h3 id="1123-データ混合（mixture）回帰を防ぐための基本操作">11.2.3　データ混合（mixture）：回帰を防ぐための基本操作</h3>
<p>人物らしさを学習させると、元のモデルが持つ一般能力（丁寧な説明、幅広い知識、基本的推論など）が壊れることがあります。これはデータ分布が偏ることで起きます。対策の最も基本は「混ぜる」ことです。すなわち、人物らしさデータ $D_{\text{persona}}$ だけで学習せず、一般データ $D_{\text{general}}$ や安全データ $D_{\text{safety}}$ と混合し、学習分布を</p>
<p>$$D = \lambda_1 D_{\text{persona}} + \lambda_2 D_{\text{general}} + \lambda_3 D_{\text{safety}} \quad (\lambda_k \ge 0,\ \sum_k \lambda_k = 1)$$ のように作ります。ここで $\lambda_k$ は混合比率です。これは単純ですが非常に強力です。混合をしない更新は、ほぼ確実に回帰を起こします。混合比率は、第10章の評価で「どの能力を落としたくないか」を見ながら調整します。</p>
<hr>
<h2 id="113-教師あり微調整最も基本で最も誤用されやすい学習">11.3　教師あり微調整：最も基本で、最も誤用されやすい学習</h2>
<h3 id="1131-教師あり微調整（SFT）とは何か条件付き最尤推定">11.3.1　教師あり微調整（SFT）とは何か：条件付き最尤推定</h3>
<p>教師あり微調整（Supervised Fine-Tuning: SFT）とは、入力 $x$ と望ましい出力 $y$ のペアから、モデルが $y$ を高確率で出すようにパラメータ $\theta$ を更新する学習です。目的関数は条件付き対数尤度の最大化、すなわち交差エントロピー最小化で書けます。</p>
<p>$$ \max_\theta \ \mathbb{E}_{(x,y)\sim D}\left[\log p*\theta(y\mid x)\right] \quad\Longleftrightarrow\quad \min_\theta \ \mathcal{L}_{\text{SFT}}(\theta) = -\mathbb{E}_{(x,y)\sim D}\left[\log p_\theta(y\mid x)\right]$$ この式は単純ですが、人物らしさにおいては「何を $x$ に入れるか」が成否を決めます。第7章で述べたように、外部記憶や参照文書をコンテクストへ入れるなら、SFTは「参照文書を見た上で、どう統合して答えるか」を学習させることになります。逆に参照なしでSFTすると、モデルは“それっぽく補完する”方向へ学びやすく、デジタルツインでは特に危険です。したがってSFTは、参照設計（第7章）とセットで設計します。</p>
<h3 id="1132-SFTの典型的失敗文体だけが強化され判断が壊れる">11.3.2　SFTの典型的失敗：文体だけが強化され、判断が壊れる</h3>
<p>SFTは強い一方で、人物らしさに特有の失敗が起きます。その代表が「文体模倣の過学習」です。本人の文章を大量に入れてSFTすると、口調や言い回しは似ますが、本人が持っていない事実まで“本人風”に語ってしまう危険が増えます。これは第3章で述べた「もっともらしさ」と「真実性」が一致しない問題が、学習によって強化される形です。</p>
<p>対策は二つあります。第一に、実在人物のデジタルツインでは、エピソードとして語ってよい範囲を「参照できるログ」に限定し、参照がないときは保留・確認に切り替える例を教師データとして入れることです。第二に、文体を学習させたい場合でも、内容は一般データや社内規程など「根拠があるもの」を中心にし、本人の“経験談”に相当する文は、出典付きでしか学習させないことです。SFTはデータが規範になるので、規範の設計を誤ると、非常に頑固に誤ります。</p>
<h3 id="1133-パラメータ効率のよい微調整LoRA・アダプタ・プロンプト学習">11.3.3　パラメータ効率のよい微調整：LoRA・アダプタ・プロンプト学習</h3>
<p>SFTをするにしても、全パラメータを更新するとコストが大きく、回帰やドリフトも起きやすい。そこで近年広く使われるのが、パラメータ効率のよい微調整（Parameter-Efficient Fine-Tuning: PEFT）です。代表が LoRA（Low-Rank Adaptation）です（Hu et al., 2021  <a href="https://arxiv.org/abs/2106.09685" target="_blank">https://arxiv.org/abs/2106.09685</a> ）。</p>
<p>LoRAの基本は、線形層の重み行列 $W\in\mathbb{R}^{d\times k}$ を直接更新する代わりに、低ランク行列の積で表せる更新 $\Delta W=BA$（$B\in\mathbb{R}^{d\times r}, A\in\mathbb{R}^{r\times k}$, $r\ll \min(d,k)$）だけを学習することです。出力は</p>
<p>$$ h = (W + \Delta W)x = (W + BA)x $$</p>
<p>となり、学習するのは (A,B) だけなので、学習パラメータ数が大幅に減ります。これにより、（i）学習が軽い、（ii）元の重み $W$ を凍結しているので回帰が起きにくい、（iii）複数の人格や役割に対して LoRA を付け替えるような運用がしやすい、という利点があります。</p>
<p>同系統として、アダプタ（adapter）による微調整（Houlsby et al., 2019  <a href="https://arxiv.org/abs/1902.00751" target="_blank">https://arxiv.org/abs/1902.00751</a> ）や、プロンプトの一部だけを学習するプロンプトチューニング（Lester et al., 2021  <a href="https://arxiv.org/abs/2104.08691" target="_blank">https://arxiv.org/abs/2104.08691</a> ）、Prefix-Tuning（Li & Liang, 2021  <a href="https://arxiv.org/abs/2101.00190" target="_blank">https://arxiv.org/abs/2101.00190</a> ）などがあります。これらは「モデルを大きく変えずに、特定の振る舞いを付加する」という意味で、人物らしさのドリフト制御と相性が良いことが多い。</p>
<p>ただし注意があります。PEFTは回帰を減らしやすい一方で、「何を学習させたか」がLoRA重みの中に隠れ、監査しにくくなります。デジタルツインでは、本人の発言に見える出力が“いつ・どのデータで学習したLoRA由来か”を追跡できるように、データとLoRAのバージョン管理を厳格に行う必要があります（第10章の監査設計）。</p>
<hr>
<h2 id="114-選好学習と強化学習人間の「良し悪し」を最適化に落とす">11.4　選好学習と強化学習：人間の「良し悪し」を最適化に落とす</h2>
<p>人物らしさは、教師ありで「この文章を出せ」と言い切れない領域が多い一方で、「どちらが良いか」は言えることが多い。そこで中心になるのが選好学習（preference learning）です。さらに選好を報酬として扱い、方策（policy）を更新する枠組みが、強化学習（reinforcement learning）です。</p>
<h3 id="1141-報酬モデル比較データから「好ましさ関数」を学習する">11.4.1　報酬モデル：比較データから「好ましさ関数」を学習する</h3>
<p>選好データ $(x,y^+,y^-)$ から、応答の好ましさを数値化する関数 $r_\phi(x,y)$ を学習するのが報酬モデル（reward model）です。最も基本の確率モデルは Bradley–Terry 型で、好ましい方が選ばれる確率をロジスティック関数で表します。</p>
<p>$$P(y^+ \succ y^- \mid x) = \sigma\big(r_\phi(x,y^+) - r_\phi(x,y^-)\big) = \frac{1}{1+\exp(-(r_\phi(x,y^+) - r_\phi(x,y^-)))}$$ このとき、対数尤度最大化（交差エントロピー最小化）で $\phi$ を学習できます。これは第10章で紹介した Bradley–Terry モデル（Bradley & Terry, 1952  <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a> ）と同型です。</p>
<p>人物らしさでのポイントは、報酬モデルの軸を混ぜないことです。例えば「本人らしさ」と「安全性」を同じ報酬に混ぜると、本人らしいがリスクがある発言が消えたり、逆に安全だが本人らしくない返答に寄ったりします。報酬は目的関数です。第10章の多目的評価と同様に、報酬も多目的として分解し、最後に重み付けで統合する方が設計しやすいことが多い。</p>
<h3 id="1142-RLHF人間のフィードバックから強化学習するパイプライン">11.4.2　RLHF：人間のフィードバックから強化学習するパイプライン</h3>
<p>選好学習を実務に落とした代表例が RLHF（Reinforcement Learning from Human Feedback：人間フィードバックからの強化学習）です。InstructGPT は、SFTで初期方策を作り、報酬モデルを学習し、その報酬を最大化するよう方策を強化学習で更新する、というパイプラインを示しました（Ouyang et al., 2022  <a href="https://arxiv.org/abs/2203.02155" target="_blank">https://arxiv.org/abs/2203.02155</a> ）。</p>
<p>RLHFの中心的な設計は、「報酬を最大化しつつ、元のモデルから逸脱しすぎない」ことです。逸脱しすぎると、言語の流暢さが壊れたり、報酬モデルの抜け穴を突いて不自然な出力が増えたりします（いわゆる報酬ハッキング）。そこで多くの実装では、参照方策（reference policy） $\pi_{\text{ref}}$ を置き、現在の方策 $\pi_\theta$ が参照から離れすぎないように、カルバック＝ライブラー・ダイバージェンス（Kullback–Leibler divergence, KL）による罰則を入れます。1つの書き方は次です。</p>
<p>$$ \max_\theta \ \mathbb{E}_{x\sim D}\mathbb{E}_{y\sim \pi_\theta(\cdot\mid x)}\left[r_\phi(x,y)\right] - \beta \ \mathbb{E}_{x\sim D}\left[D_{\mathrm{KL}}\left(\pi_\theta(\cdot\mid x)\ |\ \pi_{\text{ref}}(\cdot\mid x)\right)\right]$$ $\beta>0$ は逸脱をどれだけ嫌うかの係数です。これが「人物らしさのドリフト制御」と直結します。デジタルツインで、本人らしさを強化しようとしても、参照から逸脱しすぎると、一般能力や安全境界が壊れる可能性があります。逆に $\beta$ を大きくすると、更新が弱くなり、あまり変わりません。評価（第10章）を見ながら $\beta$ を調整するのが実務です。</p>
<p>この最適化に使われる代表的アルゴリズムが PPO（Proximal Policy Optimization）です（Schulman et al., 2017  <a href="https://arxiv.org/abs/1707.06347" target="_blank">https://arxiv.org/abs/1707.06347</a> ）。PPOの要点は、方策更新の比率が急激に変わらないように“クリップ”して安定化させることです。状態・行動を言語生成に対応させる議論は省略しますが、更新の安定性を確保するために、PPOのような制約付き更新が実務で好まれることだけ押さえておけば十分です。</p>
<h3 id="1143-DPO強化学習を回さずに選好最適化する">11.4.3　DPO：強化学習を回さずに選好最適化する</h3>
<p>RLHFは強力ですが、実装と運用が難しいことがあります。報酬モデルの学習、強化学習の不安定性、ログ確率計算、ハイパーパラメータ調整などのコストが大きい。そこで提案されたのが DPO（Direct Preference Optimization）です（Rafailov et al., 2023  <a href="https://arxiv.org/abs/2305.18290" target="_blank">https://arxiv.org/abs/2305.18290</a> ）。</p>
<p>DPOの直観はこうです。選好データがあるなら、方策 $\pi_\theta$ の尤度（$\log \pi_\theta(y\mid x)$）を使って、「好ましい応答の尤度を上げ、好ましくない応答の尤度を下げる」ように直接最適化すればよい。しかも、参照方策 $\pi_{\text{ref}}$ を入れることで、逸脱を制御できます。</p>
<p>DPOの代表的な損失は次の形です。選好データ $(x, y^+, y^-)$ に対し、</p>
<p>$$-\ \mathbb{E}\left[ \log \sigma\left( \beta\left( \log\pi_\theta(y^+\mid x)-\log\pi_\theta(y^-\mid x) -\log\pi_{\mathrm{ref}}(y^+\mid x)+\log\pi_{\mathrm{ref}}(y^-\mid x) \right)\right)\right]$$ を最小化します。ここで $\beta$ は温度（更新の強さ）です。式の意味は、参照方策に比べて「好ましい方をより確率的に選び、好ましくない方をより選ばない」ようにすることです。これにより、強化学習を明示的に回さなくても、選好に沿った更新ができます。</p>
<p>人物らしさの実務では、DPOの利点は「更新が比較的安定で、実装が軽い」点にあります。一方で、やはりデータが規範になるので、選好データの軸設計を誤ると一気に崩れます。たとえば架空キャラの選好データが「面白さ」だけに偏ると、社内で役に立つという本来目的が失われます。デジタルツインでも、評定者が“丁寧さ”に引っ張られると、本人らしさが消えます。第10章の妥当性点検が、ここでそのまま効きます。</p>
<h3 id="1144-憲法AI規範を「文章（ルール）」として与え自己批評でデータを作る">11.4.4　憲法AI：規範を「文章（ルール）」として与え、自己批評でデータを作る</h3>
<p>もう一つ重要な系統が、憲法AI（Constitutional AI）です。これは、人間が細かいラベルを大量に付ける代わりに、「こう振る舞うべき」という規範（憲法）を文章として与え、モデルが自己批評（critique）と修正（revision）を行い、さらにAIフィードバックで学習を回す枠組みです（Bai et al., 2022  <a href="https://arxiv.org/abs/2212.08073" target="_blank">https://arxiv.org/abs/2212.08073</a> ）。</p>
<p>人物らしさの文脈でこの発想が役に立つのは、「安全境界」や「会話の礼儀」のように、人間の評価が比較的一致しやすい軸を、規範として固定できる点です。ただしデジタルツインに関しては注意が必要です。規範で“良い子化”しすぎると、本人らしい判断（ときに厳しい、リスクを取る、曖昧に答えるなど）が消えてしまいます。したがって憲法的ルールは、社会的に必要な安全境界に限定し、「本人らしさの判断軸」と混線させない運用が重要です（第10章で述べた多目的設計の実務版です）。</p>
<hr>
<h2 id="115-継続学習とドリフト制御更新し続けるほど壊れる問題にどう対処するか">11.5　継続学習とドリフト制御：更新し続けるほど壊れる問題にどう対処するか</h2>
<p>人物らしさのシステムは運用中に必ず更新したくなります。社内制度が変わる、会社状況が変わる、ユーザーが増える、会議スタイルが変わる。ここで生じる難題が「更新し続けるほど壊れる」問題です。機械学習では、過去タスクの性能が新タスクの学習で落ちる現象を破滅的忘却（catastrophic forgetting）と呼びます。</p>
<h3 id="1151-破滅的忘却の数理新データだけで学習するとなぜ壊れるか">11.5.1　破滅的忘却の数理：新データだけで学習するとなぜ壊れるか</h3>
<p>最適化の観点で見ると、学習は損失最小化です。過去の望ましい挙動を表すデータ集合を $D_{\text{old}}$、新しいデータ集合を $D_{\text{new}}$ とすると、損失はそれぞれ $\mathcal{L}_{\text{old}}(\theta)$、$\mathcal{L}_{\text{new}}(\theta)$ です。新データだけで学習すると、$\mathcal{L}_{\text{new}}$ を下げる方向へ動きますが、その方向が $\mathcal{L}_{\text{old}}$ を上げる場合があり、過去性能が落ちます。人物らしさの更新ではこれが「性格が変わった」「口調が変わった」「以前は慎重だったのに断言するようになった」といった形で現れます。</p>
<h3 id="1152-EWC重要なパラメータを動かしにくくする正則化">11.5.2　EWC：重要なパラメータを動かしにくくする正則化</h3>
<p>破滅的忘却への古典的対策の一つが EWC（Elastic Weight Consolidation）です（Kirkpatrick et al., 2017  <a href="https://arxiv.org/abs/1612.00796" target="_blank">https://arxiv.org/abs/1612.00796</a> ）。EWCは「過去タスクにとって重要なパラメータは動かしにくくする」という正則化です。過去タスクで学習したパラメータを $\theta^*$ とし、各パラメータの重要度をフィッシャー情報 $F_i$ で近似すると、更新時の損失に次の罰則を加えます。</p>
<p>$$ \mathcal{L}(\theta)=\mathcal{L}_{\text{new}}(\theta) + \lambda \sum_i F_i(\theta_i-\theta_i^*)^2$$ $\lambda$ は過去保持の強さです。人物らしさの実務での解釈は単純で、「人格・安全境界・基本能力の核に関わる部分は動かしすぎない」という設計思想を、数学的に実装する方法です。もちろんLLMで厳密に $F_i$ を推定するのは難しい場合もありますが、「参照モデルからのKL罰則」や「PEFT」も同じ思想を別の形で実現しています。</p>
<h3 id="1153-リプレイ（replay）昔のデータを混ぜ続ける">11.5.3　リプレイ（replay）：昔のデータを混ぜ続ける</h3>
<p>もう一つの基本対策がリプレイです。これは第11.2で述べたデータ混合を、運用更新でも継続する方法です。更新時に $D_{\text{new}}$ だけでなく、代表的な $D_{\text{old}}$ の一部（リプレイバッファ）を混ぜて学習します。これにより、最適化が過去の損失を完全に無視しなくなります。リプレイは概念的に単純ですが、人物らしさでは非常に効きます。なぜなら人物らしさは「過去との整合」が中心で、過去を学習から外すと整合性が崩れやすいからです。</p>
<p>ただしリプレイには設計課題があります。過去データが大きすぎると学習が重くなり、古いルールや古い状況を固定してしまう危険があります。ここでは第7章の忘却設計と同様に、「消す」「薄める」「要約して残す」を学習データにも適用します。古い例は代表例だけを残し、比率を下げる。制度改定があった領域は古い例を消す。人物の基本方針だけは要約した形で残す。こうしたデータ運用が、継続学習を現実のものにします。</p>
<h3 id="1154-更新のガバナンス勝手に学習させない">11.5.4　更新のガバナンス：勝手に学習させない</h3>
<p>継続学習の最大の危険は、「勝手に人格が変わる」ことです。特にデジタルツインでは、本人の知らないところで人格が更新されるのは致命的です。したがって、運用での更新は、必ず評価ゲート（第10章）を通し、更新理由・データ・評価結果・リリース範囲を記録して監査可能にします。ソフトウェア開発でいう「CI/CDにテストを入れてからデプロイする」のと同じ発想ですが、人格システムではその重要性が一段上がります。</p>
<hr>
<h2 id="116-知識編集と「記憶に置くか重みに書くか」問題">11.6　知識編集と「記憶に置くか、重みに書くか」問題</h2>
<p>人物らしさの開発では、「この事実だけを直したい」「この設定だけを更新したい」という要求が必ず出ます。ここで迷うのが、外部記憶を書き換えるべきか、モデルの重みを編集すべきか、という問題です。</p>
<h3 id="1161-重み編集（model-editing）局所的にモデル知識を変える研究">11.6.1　重み編集（model editing）：局所的にモデル知識を変える研究</h3>
<p>モデル編集とは、特定の入力に対する出力を狙って変えつつ、他の出力への影響を最小にするようにパラメータを更新する研究領域です。典型的には、「あるプロンプトに対して誤った事実を出すので、その事実だけを正したい」という要求から出発します。</p>
<p>形式的には、編集目標を満たす損失 $\mathcal{L}_{\text{edit}}(\theta)$ と、編集による副作用（他の挙動の変化）を測る損失 $\mathcal{L}_{\text{loc}}(\theta)$ を置き、更新量を $\Delta\theta$ として</p>
<p>$$ \min_{\Delta\theta} \ \mathcal{L}_{\text{edit}}(\theta+\Delta\theta) + \lambda \mathcal{L}_{\text{loc}}(\theta+\Delta\theta) $$</p>
<p>のような最適化として表すことができます。</p>
<p>代表的手法として ROME（Rank-One Model Editing）が提案され、因果トレース的に「その事実を出すのに効いている重み部分」を推定して、低ランク更新で編集する方法を示しました（Meng et al., 2022  <a href="https://arxiv.org/abs/2202.05262" target="_blank">https://arxiv.org/abs/2202.05262</a> ）。さらに多数の事実を効率よく編集する MEMIT も提案されています（Meng et al., 2022  <a href="https://arxiv.org/abs/2210.07229" target="_blank">https://arxiv.org/abs/2210.07229</a> ）。</p>
<p>これらは強力ですが、人物らしさの実務にそのまま適用するのは注意が必要です。なぜなら、デジタルツインで編集したいのは「世界の一般事実」よりも「本人のエピソード」や「会社の内規」のような可変・機密・出典依存の情報であることが多いからです。そうした情報を重みに書き込むと、（i）後で出典が追えない、（ii）削除要求に応えにくい、（iii）誤りや改定のたびに再編集が必要になる、という問題が起きます。</p>
<h3 id="1162-原則可変情報は外部記憶安定した技能は重み">11.6.2　原則：可変情報は外部記憶、安定した技能は重み</h3>
<p>実務での基本原則は次です。頻繁に変わる情報、出典が重要な情報、個人・社内の機密情報は、外部記憶（第7章）や参照ツール（第8章）に置き、モデル重みには書き込まない。一方、安定した技能、例えば「会話の礼儀」「適切な保留・確認」「会議での議事運営の型」など、情報ではなく手続きに近い部分は、SFTや選好学習で重みに焼き付ける価値があります。重みは“技能”、外部記憶は“事実”、という分業です。</p>
<p>架空キャラの場合は少し事情が違います。カノン（設定）が安定しているなら、それを重みに学習させてもよい場合があります。しかしそれでも、設定が更新される可能性があるなら、外部記憶に置いた方が運用は楽です。重みに書くか記憶に置くかは、技術の優劣ではなく、更新頻度と監査要求で決まります。</p>
<hr>
<h2 id="117-学習を「プロダクション」にする再現性・監査・安全のための運用工学">11.7　学習を「プロダクション」にする：再現性・監査・安全のための運用工学</h2>
<p>人物らしさの学習は、研究室の実験で終わりません。運用に入ると、学習はソフトウェア開発の一部になります。ここでは、再現性と監査を支える実務の骨格を押さえます。</p>
<h3 id="1171-データとモデルの来歴（provenance）を残すDatasheets-と-Model-Cards">11.7.1　データとモデルの来歴（provenance）を残す：Datasheets と Model Cards</h3>
<p>どのデータで学習したかが曖昧になると、人物らしさの議論が成立しません。そこでデータセットには「データシート（datasheet）」を作り、データの収集方法、目的、含まれるリスク、想定外の使い方などを記録する提案がなされています（Gebru et al., 2021 “Datasheets for Datasets”  <a href="https://arxiv.org/abs/1803.09010" target="_blank">https://arxiv.org/abs/1803.09010</a> ）。またモデルには「モデルカード（model card）」を作り、用途、性能、制限、倫理的配慮などをまとめる提案があります（Mitchell et al., 2019  <a href="https://arxiv.org/abs/1810.03993" target="_blank">https://arxiv.org/abs/1810.03993</a> ）。</p>
<p>デジタルツインでは特に、データの権利と同意が重要です。誰の発言ログを学習に使ったのか、その同意はあるのか、削除要求が来たらどうするのか、といった運用が必要になります。ここは次章以降の倫理・法務の章で詳しく扱いますが、本章の時点でも「来歴を残さない学習は、いずれ破綻する」という認識は持っておくべきです。</p>
<h3 id="1172-評価駆動の更新回帰テストを通らない更新は出さない">11.7.2　評価駆動の更新：回帰テストを通らない更新は出さない</h3>
<p>第10章で作った評価は、本章の更新に直結します。更新前後で評価セットを回し、（i）狙った指標が改善している、（ii）最低限守るべき指標が落ちていない、（iii）落ちた場合は理由が説明できる、という条件を満たす更新だけを採用します。これをルール化しないと、更新は「気分」で行われ、人格ドリフトを止められません。</p>
<p>評価は多目的なので、更新採用の判定も多目的になります。実務的には、いくつかの指標を「ゲート（必須条件）」として置き、それを満たしたものの中で総合指標が最も良いものを採用する、という二段階が扱いやすいです。例えば社内キャラなら「規程参照の正確性」「機密の扱い」「過度な断言の抑制」をゲートにし、その上で「役に立つ度合い」や「満足度」を最大化する、といった形です。</p>
<hr>
<h2 id="118-通し例A/Bデジタルツインと架空キャラで更新戦略はどう変わるか">11.8　通し例A/B：デジタルツインと架空キャラで更新戦略はどう変わるか</h2>
<h3 id="1181-通し例ACEO/COO/CTO/CFO-デジタルツインの更新戦略">11.8.1　通し例A：CEO/COO/CTO/CFO デジタルツインの更新戦略</h3>
<p>実在人物のデジタルツインで最重要なのは、「本人の経験や意思を捏造しない」ことです。したがって更新戦略の中心は、モデル重みではなく、参照可能な記録（議事録、メモ、決裁文書、公開インタビューなど）を外部記憶として整備し、検索と参照を改善することになります（第7章）。重み更新は、その次です。</p>
<p>重み更新をする場合でも、優先順位は「技能」に置きます。例えば、情報不足のときに保留し、必要な追加質問を最小限に出す、という技能はSFTや選好学習で改善できます。会議で根拠を提示し、反対意見を検討し、結論を条件付きにする、といった議事運営技能も学習可能です。一方で「CEOが過去にどの案件で何を言ったか」というエピソードは、重みに書くのではなく参照に寄せるべきです。なぜなら、出典が必要で、改定や訂正があり得るからです。</p>
<p>選好学習を使うなら、評定者は「本人を知る人」である必要があります。本人を知らない評定者が付ける「本人らしさ」ラベルは妥当性が低く、更新がズレます（第10章の妥当性）。評定が難しい場合は、「根拠に基づくか」「断言しすぎないか」「会議の制度に従うか」といった軸で選好を作り、人物らしさの核心（判断の癖）は外部記憶と制度設計で再現する、という分業の方が堅実です。</p>
<p>さらに、役員複数体の会議では、更新が「全員を同じ人格に近づける」危険があります。学習データに会議ログを入れると、平均的な議論スタイルに収束し、COO/CTO/CFOの差が薄れることがある。これを避けるには、役割ごとにデータを分ける、あるいは同じ議題でも役割ごとの“視点の違い”が出るようにラベルを付ける必要があります。これはデータ設計の問題で、アルゴリズムより先に決まります。</p>
<h3 id="1182-通し例B社内で役に立つ架空キャラの更新戦略">11.8.2　通し例B：社内で役に立つ架空キャラの更新戦略</h3>
<p>架空キャラは、デジタルツインより更新自由度が高い一方で、崩れ方も独特です。崩れ方の代表は二つで、カノン（設定）矛盾と、役立たなさ（実務能力の不足）です。従って更新は、「設定整合性」と「実務能力」を別々に改善し、最後に統合するのが安全です。</p>
<p>設定整合性は、外部記憶として設定文書を参照できるようにし、矛盾率を下げるのが第一です（第7章・第10章）。それでも崩れるなら、SFTで「設定文書を参照して答える」技能を学習させます。ここで重要なのは、設定を重みに焼き付けるのではなく、参照技能を焼き付けることです。設定が更新されても、参照技能は残ります。</p>
<p>実務能力の改善は、選好学習が特に効きます。「AとBのどちらが役に立つか」は比較的ラベルが安定し、Bradley–Terry型の報酬モデルやDPOが回しやすいからです。ただし、面白さやキャラ味を強化したい誘惑に注意が必要です。面白さはユーザー満足に効きますが、制度案内の正確性や安全境界とトレードオフになります。第10章で述べた通り、運用指標（満足度、再利用率）を最適化すると、重要な制約が崩れることがあります。ここでもゲート方式（最低限の正確性と安全を満たさないと更新採用しない）が重要になります。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、人物らしさの改善を「学習と更新」として体系化しました。重要なポイントは次の通りです。</p>
<p>人物らしさの更新は、モデル重みだけではなく、外部記憶・検索・ツール・会議プロトコルなど多層の更新として捉えるべきである。重み更新は強力だが危険なので、可逆な更新から始め、評価（第10章）でゲートを作ってから採用するのが堅実である。教師あり微調整（SFT）は最も基本だが、文体模倣の過学習や捏造強化に注意が必要で、参照設計とセットで使うべきである。選好学習とRLHFは「良し悪し」を最適化に落とす強力な道具であり、特にDPOのような安定な最適化も選択肢になる。ただし目的（本人らしさ・安全性・有用性）の混線は学習で増幅されるため、軸設計が最重要である。継続学習では破滅的忘却と人格ドリフトが最大の敵であり、混合・正則化・リプレイ・バージョン管理で制御する必要がある。知識編集は魅力的だが、可変で出典が重要な情報は重みに書かず、外部記憶へ置くのが原則である。</p>
<p>次章では、ここまでの技術を社会に置くときに避けて通れない、倫理・法務・プライバシー・同意・なりすましリスク・安全設計を扱います。デジタルツインは「技術的にできる」だけでは成立しません。社会的に許される形で運用できるかが、最後の関門になります。</p>
<hr>
<h2 id="参考文献（リンク）">参考文献（リンク）</h2>
<p>Ouyang, L., Wu, J., Jiang, X., et al. (2022). “Training language models to follow instructions with human feedback (InstructGPT).” <a href="https://arxiv.org/abs/2203.02155" target="_blank">https://arxiv.org/abs/2203.02155</a>)</p>
<p>Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017). “Proximal Policy Optimization Algorithms (PPO).” <a href="https://arxiv.org/abs/1707.06347" target="_blank">https://arxiv.org/abs/1707.06347</a>)</p>
<p>Rafailov, R., Sharma, A., Mitchell, E., et al. (2023). “Direct Preference Optimization: Your Language Model is Secretly a Reward Model (DPO).” <a href="https://arxiv.org/abs/2305.18290" target="_blank">https://arxiv.org/abs/2305.18290</a>)</p>
<p>Bai, Y., Jones, A., Ndousse, K., et al. (2022). “Constitutional AI: Harmlessness from AI Feedback.” <a href="https://arxiv.org/abs/2212.08073" target="_blank">https://arxiv.org/abs/2212.08073</a>)</p>
<p>Hu, E. J., Shen, Y., Wallis, P., et al. (2021). “LoRA: Low-Rank Adaptation of Large Language Models.” <a href="https://arxiv.org/abs/2106.09685" target="_blank">https://arxiv.org/abs/2106.09685</a>)</p>
<p>Houlsby, N., Giurgiu, A., Jastrzębski, S., et al. (2019). “Parameter-Efficient Transfer Learning for NLP (Adapters).” <a href="https://arxiv.org/abs/1902.00751" target="_blank">https://arxiv.org/abs/1902.00751</a>)</p>
<p>Lester, B., Al-Rfou, R., & Constant, N. (2021). “The Power of Scale for Parameter-Efficient Prompt Tuning.” <a href="https://arxiv.org/abs/2104.08691" target="_blank">https://arxiv.org/abs/2104.08691</a>)</p>
<p>Li, X. L., & Liang, P. (2021). “Prefix-Tuning: Optimizing Continuous Prompts for Generation.” <a href="https://arxiv.org/abs/2101.00190" target="_blank">https://arxiv.org/abs/2101.00190</a>)</p>
<p>Kirkpatrick, J., Pascanu, R., Rabinowitz, N., et al. (2017). “Overcoming catastrophic forgetting in neural networks (EWC).” <a href="https://arxiv.org/abs/1612.00796" target="_blank">https://arxiv.org/abs/1612.00796</a>)</p>
<p>Bradley, R. A., & Terry, M. E. (1952). “Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.” <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a>)</p>
<p>Meng, K., Sharma, A. S., Andonian, A., et al. (2022). “ROME: Locating and Editing Factual Associations in GPT.” <a href="https://arxiv.org/abs/2202.05262" target="_blank">https://arxiv.org/abs/2202.05262</a>)</p>
<p>Meng, K., et al. (2022). “MEMIT: Mass Editing Memory in a Transformer.” <a href="https://arxiv.org/abs/2210.07229" target="_blank">https://arxiv.org/abs/2210.07229</a>)</p>
<p>Gebru, T., Morgenstern, J., Vecchione, B., et al. (2021). “Datasheets for Datasets.” <a href="https://arxiv.org/abs/1803.09010" target="_blank">https://arxiv.org/abs/1803.09010</a>)</p>
<p>Mitchell, M., Wu, S., Zaldivar, A., et al. (2019). “Model Cards for Model Reporting.” <a href="https://arxiv.org/abs/1810.03993" target="_blank">https://arxiv.org/abs/1810.03993</a>)</p>
<h1 id="第12章-倫理・法務・社会実装人間らしいAIを“現実に置く”ための設計原則">第12章　倫理・法務・社会実装：人間らしいAIを“現実に置く”ための設計原則</h1>
<p>第11章までで、人物らしいAIを作るための設計・記憶・ツール利用・複数エージェント・評価・学習更新を扱ってきた。ここまでの議論は、技術としては「作れる」方向へ進んでいる。しかし、人物らしいAIが本当に難しくなるのは、実は“動いた瞬間”である。人間のように話すシステムは、ユーザーに強い信頼や依存、誤解、帰属（「この発言は本人の意思だ」）を生みやすい。さらに、実在人物のデジタルツインでは、なりすまし、名誉毀損、プライバシー侵害、権利侵害、差別や偏見の再生産といった社会的リスクが一気に増える。架空キャラでも、ユーザーが相手を「人格」と見なし、過信する（いわゆるELIZA効果）ことで、誤った助言や不適切な依存が問題になる。</p>
<p>この章では、人物らしいAIを社会に置くために必要な、倫理（ethics）、法務（law）、ガバナンス（governance）、安全設計（safety engineering）を体系化する。内容は「法律の条文暗記」ではなく、設計者が持つべき原理と、実装・運用での具体策を中心にする。法制度は国や時点で変わり得るため、本章は法的助言（legal advice）ではない。実運用では必ず、所属組織の規程と、専門家（法務・コンプライアンス・セキュリティ）による確認が必要である。その前提のもとで、本章は「どこが危険で、どんな設計が危険を減らし、何をログとして残すべきか」を、工学的に理解できるようにする。</p>
<hr>
<h2 id="121-まず押さえるべき前提人間らしさは“性能”であると同時に“危険源”でもある">12.1　まず押さえるべき前提：人間らしさは“性能”であると同時に“危険源”でもある</h2>
<p>人物らしいAIを作る動機は多くの場合ポジティブだ。実在人物のデジタルツインなら、意思決定の共有や、業務の高速化、意思決定プロセスの可視化に役立つ。架空キャラなら、社内の相談窓口、学習支援、文化づくり、チームの摩擦低減などに使える。しかし、人間らしさは次の二つを同時に増やす。</p>
<p>第一に、<strong>信頼の増加</strong>である。丁寧で、筋が通っていて、過去と矛盾せず、感情に寄り添う発話は、正しいかどうかに関係なく信頼を集める。これは心理学ではELIZA効果として古くから知られている。Weizenbaum が1966年に作ったELIZAは単純なパターン反応だったが、利用者が“理解されている”と感じてしまうことが報告された（Weizenbaum, 1966「ELIZA」 <a href="https://dl.acm.org/doi/10.1145/365153.365168" target="_blank">https://dl.acm.org/doi/10.1145/365153.365168</a> ）。現代のLLMはELIZAとは比較にならないほど流暢なので、この効果はさらに強い。</p>
<p>第二に、<strong>帰属の錯覚</strong>である。実在人物のデジタルツインが発言すると、ユーザーは「本人が言った」と誤解しやすい。架空キャラでも、あたかも人格が存在するかのように受け取られ、発言が“権威”を帯びる。ここでの危険は、誤りの内容が同じでも、「人格を帯びた誤り」は影響が大きくなることだ。したがって設計上は、人間らしさを上げるほど、「透明性（これはAIである）」「根拠（どこまで確実か）」「責任（誰が最終責任を持つか）」を同時に強化しないと、事故確率が上がる。</p>
<p>この章の以降では、倫理・法務・安全を「守るべき制約」として扱い、人物らしさの最適化が制約違反にならないようにする、という設計思想を採る。</p>
<hr>
<h2 id="122-倫理を“議論”から“設計仕様”へ原理と構成概念">12.2　倫理を“議論”から“設計仕様”へ：原理と構成概念</h2>
<p>倫理は抽象的に聞こえるが、設計に落とすには「守りたい原理」を明文化し、それを測れる形にし、運用に組み込む必要がある。ここで参考になるのが、生命倫理・研究倫理・情報倫理の古典である。</p>
<p>医療研究倫理でよく引用されるのがベルモント・レポート（Belmont Report, 1979）で、人格の尊重（respect for persons）、善行（beneficence）、正義（justice）を中心原理として提示した（米国HHSの公開資料が広く参照される）。情報セキュリティを含む研究倫理の枠組みとしては、情報通信分野へ拡張したメンロ・レポート（Menlo Report, 2012）があり、「人格の尊重、善行、正義」に加えて「法と公共利益の尊重」を強調した（The Menlo Report, 2012  <a href="https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/menlo_report_actual_formatted.pdf" target="_blank">https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/menlo_report_actual_formatted.pdf</a> ）。</p>
<p>AIに特化した原理の整理としては、OECDのAI原則（OECD AI Principles, 2019  <a href="https://oecd.ai/en/ai-principles" target="_blank">https://oecd.ai/en/ai-principles</a> ）、EUの「信頼できるAI」ガイドライン（European Commission High-Level Expert Group on AI, 2019  <a href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" target="_blank">https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai</a> ）、UNESCOのAI倫理勧告（UNESCO, 2021  <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455" target="_blank">https://unesdoc.unesco.org/ark:/48223/pf0000380455</a> ）などがある。これらは表現は異なるが、共通して次の要素を含む。</p>
<p>人間の自律を尊重し、害を避け、恩恵を最大化し、公正であり、説明可能で、責任主体が明確で、プライバシーが守られること。人物らしいAIに翻訳すると、少なくとも次の構成概念を評価対象として持つ必要がある。</p>
<p>第一に、<strong>透明性（transparency）</strong>である。ユーザーが「相手がAIである」ことを理解できるか、どこまでが推測でどこまでが根拠に基づくかを理解できるか、意思決定の手がかり（根拠や条件）が示されるか、という性質である。</p>
<p>第二に、<strong>自律性（autonomy）</strong>である。ユーザーが選択を奪われず、過度に誘導されず、依存を強められず、同意や撤回が可能か、という性質である。</p>
<p>第三に、<strong>害の最小化（non-maleficence）</strong>である。誤情報、差別、心理的損害、機密漏えい、なりすまし、信用毀損などのリスクを下げる設計があるか、という性質である。</p>
<p>第四に、<strong>公正（fairness）</strong>である。特定属性（性別、人種、国籍、年齢など）に対して不利な扱いをしない、または不当な差が説明できる、という性質である。</p>
<p>第五に、<strong>説明責任（accountability）</strong>である。誰が設計し、誰が運用し、何がログに残り、事故時にどう是正するかが明確か、という性質である。</p>
<p>これらは倫理の“正しさ”の議論ではなく、実務上の「失敗すると事故になる要件」であり、評価（第10章）と更新（第11章）に結びつく仕様である。</p>
<hr>
<h2 id="123-リスクを数学として扱う期待損失と制約付き最適化">12.3　リスクを数学として扱う：期待損失と制約付き最適化</h2>
<p>倫理や法務は感情論になりやすいが、工学として扱うには、リスクを定量化する枠組みが役に立つ。最小の定式化は、期待損失（expected loss）である。</p>
<p>ある状況を $s$、システムの行動（発話や実行）を $a$、望ましくない事象（事故）の集合を $\mathcal{E}$ とする。事故 $e\in\mathcal{E}$ の発生確率を $P(e\mid s,a)$、事故の被害（損失）を $C(e)\ge 0$ とすると、期待損失は</p>
<p>$$ \mathrm{Risk}(s,a)=\sum_{e\in\mathcal{E}} P(e\mid s,a), C(e)$$ で表せる。人物らしいAIの設計は、多くの場合「有用性」や「本人らしさ」を最大化したいが、同時にこのリスクを許容範囲内に抑えたい。すると設計は、制約付き最適化として</p>
<p>$$ \max_{\pi}\ \mathbb{E}[U(s,a)]\quad \text{s.t.}\quad \mathbb{E}[\mathrm{Risk}(s,a)] \le \tau$$ のように書ける。ここで $\pi$ は方策（どんな状況でどう行動するかの規則）、$U$ は有用性（または本人らしさスコア）、$\tau$ は許容リスク上限である。実務では $P(e\mid s,a)$ や (C$e$) を厳密に測れないが、重要なのは「安全は気合いではなく制約である」という考え方だ。第8章で述べた最小権限、確認フロー、監査ログは、この制約を満たすための構造である。</p>
<p>NIST（米国標準技術研究所）のAIリスク管理フレームワーク（NIST AI RMF 1.0, 2023）は、まさにこの発想を組織プロセスとして整理している（NIST AI RMF 1.0  <a href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf" target="_blank">https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf</a> ）。人物らしいAIは「人格」を扱うため、RMFが挙げる「ガバナンス（Govern）」「マップ（Map）」「測定（Measure）」「管理（Manage）」の各工程が特に重要になる。</p>
<hr>
<h2 id="124-プライバシーとデータ保護個人データを扱うAIの最小安全設計">12.4　プライバシーとデータ保護：個人データを扱うAIの最小安全設計</h2>
<p>人物らしいAIが最も扱いが難しいのはプライバシーである。デジタルツインはもちろん、社内キャラでも相談内容には個人情報や機密が含まれやすい。さらにLLMには、学習データの断片が出力として漏れる危険、会話ログが二次利用される危険、検索ツールへの入力が漏えいする危険がある。</p>
<h3 id="1241-プライバシーの基本原則最小化・目的限定・分離・監査">12.4.1　プライバシーの基本原則：最小化・目的限定・分離・監査</h3>
<p>プライバシー設計は、法律以前に工学として守るべき原則がある。特に重要なのは、データ最小化（必要最小限しか集めない）、目的限定（目的外利用をしない）、アクセス制御（権限を絞る）、保持期間の制限（必要以上に残さない）、分離（学習用・運用用・監査用の分離）、監査（誰が何にアクセスしたかログを残す）である。これらは多くのデータ保護制度（例えばEUの一般データ保護規則：General Data Protection Regulation, GDPR）とも整合するが、本章では条文の詳細より設計原則として理解する。</p>
<p>人物らしいAIでありがちな失敗は、「人物らしさのために全部のログを溜めてしまう」ことである。ログは記憶（第7章）と評価（第10章）に効くが、同時に漏えい時の被害を増やす。したがって「残す理由」と「消す規則」を対にして設計する必要がある。</p>
<h3 id="1242-差分プライバシー統計的保護を数式で保証する">12.4.2　差分プライバシー：統計的保護を数式で保証する</h3>
<p>プライバシーを数式で保証しようとする代表概念が差分プライバシー（Differential Privacy: DP）である。Dwork らが定式化し、個人のデータが含まれているかどうかが出力から推測されにくいことを保証する（Dwork et al., 2006  <a href="https://dl.acm.org/doi/10.1145/1143120.1143126" target="_blank">https://dl.acm.org/doi/10.1145/1143120.1143126</a> 、教科書的整理として Dwork & Roth, 2014  <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" target="_blank">https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf</a> ）。</p>
<p>隣接データ集合（1人分のデータだけが異なるデータ集合） $D$ と (D') に対し、ランダム化アルゴリズム（学習や集計） $M$ が $(\varepsilon,\delta)$-差分プライバシーを満たすとは、任意の出力集合 $S$ について</p>
<p>$$ \Pr[M(D)\in S] \le e^{\varepsilon}\Pr[M(D')\in S] + \delta $$</p>
<p>が成り立つことをいう。直観的には、ある一人のデータが入っているかどうかで出力分布が大きく変わらない、という保証である。$\varepsilon$ はプライバシー損失（小さいほど強い保護）、$\delta$ は例外確率である。</p>
<p>深層学習でDPを実現する代表手法がDP-SGD（Differentially Private Stochastic Gradient Descent）で、勾配をクリップし、ノイズを加えて学習する（Abadi et al., 2016  <a href="https://arxiv.org/abs/1607.00133" target="_blank">https://arxiv.org/abs/1607.00133</a> ）。人物らしいAIの学習（第11章）で個人ログを使う場合、DP-SGDのような方法で「学習からの漏えい」を抑える選択肢がある。ただしDPは万能ではない。性能低下とトレードオフがあり、また“運用ログ”や“ツール入力”が漏れれば学習がDPでも意味がない。DPは全体設計の一部であり、アクセス制御やログ最小化と組み合わせる必要がある。</p>
<h3 id="1243-漏えいの現実メンバーシップ推論と学習データ抽出">12.4.3　漏えいの現実：メンバーシップ推論と学習データ抽出</h3>
<p>LLMがプライバシー上危険である理由を、研究結果として知っておく必要がある。代表的な攻撃がメンバーシップ推論（membership inference）で、あるデータが学習に使われたかどうかを推測する攻撃である（Shokri et al., 2017  <a href="https://arxiv.org/abs/1610.05820" target="_blank">https://arxiv.org/abs/1610.05820</a> ）。また、学習データの断片が直接出力されることも報告されている。Carlini らは、言語モデルから学習データの文字列が抽出できることを示した（Carlini et al., 2021 “Extracting Training Data from Large Language Models”  <a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting" target="_blank">https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting</a> ）。</p>
<p>人物らしさのシステムでは、個人の発言ログや社内機密が学習や記憶に含まれやすい。したがって、学習時のDPやフィルタリングだけでなく、運用時に「機密を再現しにくい設計」を入れる必要がある。具体的には、機密をそのまま生成させない、必要なら引用として限定的に提示し、アクセス権を持つユーザーにだけ見せる、などの境界設計が必要になる（第8章の最小権限と同じ発想）。</p>
<hr>
<h2 id="125-同意（consent）と権利デジタルツインは“データ”ではなく“人格の代理”になり得る">12.5　同意（consent）と権利：デジタルツインは“データ”ではなく“人格の代理”になり得る</h2>
<p>実在人物のデジタルツインは、単なるデータ処理を超えて、「その人の意思や発言を代替する存在」に見えてしまう。ここで中核になるのが同意と権利である。</p>
<p>同意とは、本人が、何の目的で、どの範囲のデータが、どのように使われ、どのようなリスクがあり、撤回するとどうなるかを理解した上で許可することだ。AIの場合、同意が難しいのは、用途が拡張しやすく、再学習や二次利用が起きやすいからである。したがって、同意は一回のチェックボックスではなく、更新（第11章）のたびに境界を再確認するガバナンスとして設計する必要がある。</p>
<p>権利の論点は国・地域で違うが、人物らしいAIで頻出の論点として、少なくとも次を意識しておく必要がある。第一に、プライバシー（個人情報）の権利である。第二に、肖像・氏名・声などの人格的利益（いわゆるパブリシティ権や人格権の議論）である。第三に、著作権や契約（雇用契約、機密保持契約）による制約である。第四に、名誉毀損や信用毀損のような不法行為上の責任である。</p>
<p>本書は法律解釈を目的にしないため、条文や判例を断定的に述べることは避ける。しかし設計者として重要なのは、「実在人物のデジタルツインは、本人と第三者に実害を与え得る」ことを前提にし、同意・撤回・削除・説明責任を運用仕様に埋め込むことである。技術的には、データの来歴（第11章のDatasheets）とモデルの来歴（Model Cards）を整備することが、法務・倫理の両面で不可欠になる（Gebru et al., 2021  <a href="https://arxiv.org/abs/1803.09010" target="_blank">https://arxiv.org/abs/1803.09010</a> 、Mitchell et al., 2019  <a href="https://arxiv.org/abs/1810.03993" target="_blank">https://arxiv.org/abs/1810.03993</a> ）。</p>
<hr>
<h2 id="126-なりすましと真正性人間らしいAIは“偽造可能性”を上げる">12.6　なりすましと真正性：人間らしいAIは“偽造可能性”を上げる</h2>
<p>人物らしいAIで最も社会的に危険なのが、なりすまし（impersonation）と偽造（forgery）である。テキストだけでも、本人風の発言で周囲を誤導できる。音声や画像が加わると、詐欺や政治的操作などの被害が急増し得る。ここで重要なのは、「モデルの能力が上がるほど、偽造コストが下がる」という構造的問題である。</p>
<p>この問題への対策は大きく二つに分かれる。第一は、<strong>作る側の抑制</strong>で、システムが本人だと誤解される表現を避け、AIであることを明示し、権限を制限する設計である。第二は、<strong>出力の真正性（authenticity）を検証可能にする</strong>ことで、AIが出したものだと分かる、または本人が出したものだと検証できる仕組みを作ることである。</p>
<h3 id="1261-透かし（watermarking）生成テキストに検出可能な痕跡を埋め込む">12.6.1　透かし（watermarking）：生成テキストに検出可能な痕跡を埋め込む</h3>
<p>生成テキストの真正性に関する研究として、透かし（watermarking）がある。これは、生成確率分布をわずかに偏らせて、統計的に検出できるパターンを埋め込む方法である。Kirchenbauer らは大規模言語モデルのための透かしを提案し、検出器で判定可能にする枠組みを示した（Kirchenbauer et al., 2023 “A Watermark for Large Language Models”  <a href="https://arxiv.org/abs/2301.10226" target="_blank">https://arxiv.org/abs/2301.10226</a> ）。</p>
<p>透かしの基本発想はこうだ。語彙集合を“緑リスト” $G$ と“赤リスト” $R$ に分け、生成時に $G$ 側のトークン確率を少し上げる。すると通常より $G$ の出現比率が増え、検出時に統計検定で「透かしあり」を判断できる。ただし透かしには限界もある。テキストを言い換える、要約する、翻訳するなどで透かしが弱まる。したがって透かしは単独の決定打ではなく、後述する署名やプロヴェナンスと組み合わせる必要がある。</p>
<h3 id="1262-プロヴェナンス（provenance）生成物の来歴を暗号的に保証する">12.6.2　プロヴェナンス（provenance）：生成物の来歴を暗号的に保証する</h3>
<p>もう一つの方向は、暗号署名やメタデータによって来歴を保証する方法である。例えば「この文章はこの組織のこのシステムがこの時刻に生成した」という情報を、改ざん困難な形で付与し、検証できるようにする。画像・動画の分野では来歴標準（例：C2PA：Coalition for Content Provenance and Authenticity）が議論されている。人物らしいAIでも、重要な社内文書や対外発信には「生成物の署名」「生成ログへのリンク」を付け、後から検証できるようにすることが、事故時の責任分界に直結する。</p>
<p>設計のポイントは、来歴の付与は“技術の問題”であると同時に“運用の問題”であることだ。署名があっても、ユーザーがそれを確認しないUIなら意味がない。逆にUIに確認を強制しすぎると利便性が落ちる。したがって、出力の重要度（リスク）に応じて、署名・確認・権限のレベルを変える必要がある（第8章の期待情報価値と同様に、ここでもコストとリスクのトレードオフがある）。</p>
<hr>
<h2 id="127-公平性（fairness）と差別人物らしさは偏見も再現し得る">12.7　公平性（fairness）と差別：人物らしさは偏見も再現し得る</h2>
<p>人物らしいAIが再現するのは、良い性格だけではない。実在人物なら、その人が持つバイアスや偏見も再現し得る。架空キャラでも、作者の無意識の偏見が設計に入り得る。さらに学習データが社会の偏りを含むため、意図しない差別が生じることがある。</p>
<p>公平性を工学的に扱うには、まず「何を公平と呼ぶか」を定義し、測る必要がある。代表的な定義に、統計的パリティ（statistical parity）、機会均等（equal opportunity）、等化オッズ（equalized odds）などがある。Hardt らは、二値分類における等化オッズと機会均等を整理し、後処理で達成する方法を示した（Hardt et al., 2016  <a href="https://arxiv.org/abs/1610.02413" target="_blank">https://arxiv.org/abs/1610.02413</a> ）。</p>
<p>例えば二値分類の予測 $\hat{Y}$ と真のラベル $Y$、保護属性 $A$（例：性別）に対し、機会均等は</p>
<p>$$ P(\hat{Y}=1\mid Y=1, A=0) = P(\hat{Y}=1\mid Y=1, A=1) $$</p>
<p>を要求する。等化オッズはこれを $Y=0$ にも拡張し、真陽性率と偽陽性率が属性で等しいことを要求する。</p>
<p>重要なのは、これらの公平性定義は同時に満たせない場合があることだ。Kleinberg らは、校正（calibration）とある種の公平性制約が両立しない条件を示し、何を優先するかが必要になることを示した（Kleinberg et al., 2016  <a href="https://arxiv.org/abs/1609.05807" target="_blank">https://arxiv.org/abs/1609.05807</a> ）。つまり公平性は、万能の正解があるのではなく、価値判断を含む設計問題である。</p>
<p>人物らしいAIでは、差別が生じやすい箇所が二つある。第一に、社内キャラが人事・評価・採用などの領域に助言する場合である。第二に、会議シミュレーションで、特定の属性を持つ人物像（例えば「この属性は保守的だ」など）を固定してしまう場合である。前者は実害が大きいので、原則としてAIの出力を意思決定の唯一根拠にしない、透明性と説明責任を確保する、という制度設計が必要である。後者は研究用途でも社会的偏見を再生産し得るので、シミュレーション結果を社会の真実と誤解させない、評価軸と前提を明示する、という透明性が必要である。</p>
<hr>
<h2 id="128-説明可能性と責任ブラックボックスでも“説明責任”は逃げられない">12.8　説明可能性と責任：ブラックボックスでも“説明責任”は逃げられない</h2>
<p>人物らしいAIは、しばしばブラックボックス（内部の意思決定過程が直接は分からない）である。だが、説明責任はブラックボックスで免責されない。ここで重要なのは、「説明可能性（interpretability）」と「説明責任（accountability）」は同じではない、という点である。</p>
<p>説明可能性は、モデル内部や出力の理由を理解可能な形で示す性質である。説明責任は、事故が起きたときに原因を追跡し、是正し、責任主体を明確にする性質である。ブラックボックスでも、ログ・監査・運用プロセスを整備すれば説明責任はある程度担保できる。逆に、説明可能性が高く見えても、ログがなく運用が曖昧なら責任は取れない。</p>
<p>解釈可能性研究の概観として、Doshi-Velez & Kim（2017）が「厳密な解釈可能性科学」の必要性を論じた（ <a href="https://arxiv.org/abs/1702.08608" target="_blank">https://arxiv.org/abs/1702.08608</a> ）。Rudin（2019）は、重要領域ではブラックボックスを説明するより、そもそも解釈可能なモデルを使うべきだと主張した（<a href="https://arxiv.org/abs/1811.10154" target="_blank">https://arxiv.org/abs/1811.10154</a>）。人物らしいAIにそのまま当てはめると、重大な権限（採用、評価、契約、医療など）に近い用途ほど、AIは「助言」に留め、最終判断は人が行う設計が妥当になる。</p>
<p>工学として最小限必要なのは、出力の根拠と限界を明示し、監査ログで再現できることだ。第8章・第10章で述べた「参照文書」「ツール出力」「確信度・保留」「実行前確認」のログが、ここで説明責任の基盤になる。</p>
<hr>
<h2 id="129-安全設計危険な“人格化”を避けるための非欺瞞（non-deceptive）デザイン">12.9　安全設計：危険な“人格化”を避けるための非欺瞞（non-deceptive）デザイン</h2>
<p>人物らしいAIは、ユーザーに「人格がある」と感じさせやすい。これは利点でもあるが、同時に欺瞞（deception）のリスクでもある。ここでいう欺瞞は、悪意の詐欺だけでなく、ユーザーが誤解するような設計も含む。例えば、AIなのに「私はあなたのことをずっと見てきた」と言う、実在人物のデジタルツインなのに「本人です」と誤解される表現をする、医療や法務で確証がないのに断言する、といったケースである。</p>
<p>非欺瞞デザインの要点は次の通りだ。第一に、AIであることを明示し、本人や第三者の代理ではないことを誤解なく伝える。第二に、根拠がない個人エピソードを語らない。第三に、能力の限界（できないこと、知らないこと）を明確にする。第四に、重要行為は確認し、必要なら人間に引き継ぐ。</p>
<p>この思想は、単に倫理的に望ましいだけでなく、事故の期待損失を下げる（12.3）工学的手段でもある。特に社内キャラのように“役に立つ存在”を目指すほど、ユーザーが依存しやすくなるため、透明性と境界線がより重要になる。</p>
<hr>
<h2 id="1210-実装と運用のチェックリスト化制度・技術・人の三層で守る">12.10　実装と運用のチェックリスト化：制度・技術・人の三層で守る</h2>
<p>本章の議論を「運用に落とす」には、制度（policy）、技術（mechanism）、人（people）の三層で守る必要がある。制度だけでは実装が抜け穴を作る。技術だけでは組織が逸脱する。人だけでは属人化して再現できない。従って三層を同時に設計する。</p>
<p>制度の層では、用途と権限を定義し、同意と撤回の手続きを決め、データ保持・削除の規程を作り、監査の責任者とプロセスを決める。技術の層では、最小権限、アクセス制御、暗号化、ログ、透かしや署名、危険領域の拒否と代替提案、実行前確認、異常検知を実装する。人の層では、運用者教育、事故対応訓練、レッドチーミング（攻撃者視点での安全検査）、更新の承認フローを整備する。評価（第10章）と更新（第11章）は、この三層が噛み合って初めて機能する。</p>
<hr>
<h2 id="1211-通し例A/Bデジタルツインと架空キャラで「許されること」がどう違うか">12.11　通し例A/B：デジタルツインと架空キャラで「許されること」がどう違うか</h2>
<h3 id="12111-通し例ACEO/COO/CTO/CFO-デジタルツイン">12.11.1　通し例A：CEO/COO/CTO/CFO デジタルツイン</h3>
<p>デジタルツインの最重要リスクは、本人の意思の偽造と、組織に対する不正な権限行使である。従って、最初に決めるべきは「ツインができること・できないこと」であり、できないことに実行権限や対外発信を含めるのが基本になる。次に、本人の発言や判断の根拠として参照できる記録を整備し、参照できない内容は保留し、質問に切り替える。さらに、ツインの出力を会議や意思決定に使うなら、出力が本人の公式見解ではないこと、参照した資料、確信度、条件を明示し、監査ログを残す。最後に、更新（第11章）では、本人の同意の範囲内でしかデータを使わず、更新前後の評価（第10章）を必須にする。</p>
<h3 id="12112-通し例B社内で役に立つ架空キャラ">12.11.2　通し例B：社内で役に立つ架空キャラ</h3>
<p>架空キャラは、本人の権利侵害のリスクは低いが、依存と誤助言のリスクが中心になる。従って、AIであることの明示、能力限界の明示、危険領域での保留と人間への引き継ぎが重要になる。相談内容には個人情報が含まれるので、ログ最小化とアクセス制御が必須である。キャラを面白くしすぎると過信を誘発することがあるため、魅力と安全のバランスは評価指標として明示し、更新で崩れないようにゲートを設ける（第10章・第11章）。さらに、社内制度案内のような正確性が必要な領域では、根拠となる規程文書への参照を必須にし、曖昧な場合は質問を返す設計が安全である。</p>
<hr>
<h2 id="まとめ人物らしさは“社会との接点”で決まる">まとめ：人物らしさは“社会との接点”で決まる</h2>
<p>人物らしいAIの価値は、技術的にどれだけ人間っぽい文章を出せるかだけでは決まらない。むしろ、社会に置いたときに、透明性と同意が担保され、プライバシーが守られ、なりすましが抑制され、公平性が点検され、事故が監査可能で、更新がガバナンスされているかで決まる。倫理・法務・安全は「最後に付け足す装飾」ではなく、設計の中心要件である。</p>
<p>本書の技術（記憶、ツール、会議、評価、学習）は、この中心要件を満たすためにこそ使われるべきである。人物らしさを高めるほど、透明性・根拠・責任を同時に高める。この“二つを同時に上げる”ことが、人物らしいAIを実務で成立させる最短経路になる。</p>
<hr>
<h2 id="参考文献（リンク）">参考文献（リンク）</h2>
<p>Weizenbaum, J. (1966). “ELIZA—A Computer Program For the Study of Natural Language Communication Between Man and Machine.” <a href="https://dl.acm.org/doi/10.1145/365153.365168" target="_blank">https://dl.acm.org/doi/10.1145/365153.365168</a>)</p>
<p>The Menlo Report (2012). “Ethical Principles Guiding Information and Communication Technology Research.” <a href="https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/menlo_report_actual_formatted.pdf" target="_blank">https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/menlo_report_actual_formatted.pdf</a>)</p>
<p>OECD (2019). “OECD AI Principles.” <a href="https://oecd.ai/en/ai-principles" target="_blank">https://oecd.ai/en/ai-principles</a>)</p>
<p>European Commission HLEG on AI (2019). “Ethics Guidelines for Trustworthy AI.” <a href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" target="_blank">https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai</a>)</p>
<p>UNESCO (2021). “Recommendation on the Ethics of Artificial Intelligence.” <a href="https://unesdoc.unesco.org/ark:/48223/pf0000380455" target="_blank">https://unesdoc.unesco.org/ark:/48223/pf0000380455</a>)</p>
<p>NIST (2023). “Artificial Intelligence Risk Management Framework (AI RMF 1.0).” <a href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf" target="_blank">https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf</a>)</p>
<p>Dwork, C., McSherry, F., Nissim, K., & Smith, A. (2006). “Calibrating Noise to Sensitivity in Private Data Analysis.” <a href="https://dl.acm.org/doi/10.1145/1143120.1143126" target="_blank">https://dl.acm.org/doi/10.1145/1143120.1143126</a>)</p>
<p>Dwork, C., & Roth, A. (2014). “The Algorithmic Foundations of Differential Privacy.” <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" target="_blank">https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf</a>)</p>
<p>Abadi, M., Chu, A., Goodfellow, I., et al. (2016). “Deep Learning with Differential Privacy (DP-SGD).” <a href="https://arxiv.org/abs/1607.00133" target="_blank">https://arxiv.org/abs/1607.00133</a>)</p>
<p>Shokri, R., Stronati, M., Song, C., & Shmatikov, V. (2017). “Membership Inference Attacks Against Machine Learning Models.” <a href="https://arxiv.org/abs/1610.05820" target="_blank">https://arxiv.org/abs/1610.05820</a>)</p>
<p>Carlini, N., Tramer, F., Wallace, E., et al. (2021). “Extracting Training Data from Large Language Models.” <a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting" target="_blank">https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting</a>)</p>
<p>Hardt, M., Price, E., & Srebro, N. (2016). “Equality of Opportunity in Supervised Learning.” <a href="https://arxiv.org/abs/1610.02413" target="_blank">https://arxiv.org/abs/1610.02413</a>)</p>
<p>Kleinberg, J., Mullainathan, S., & Raghavan, M. (2016). “Inherent Trade-Offs in the Fair Determination of Risk Scores.” <a href="https://arxiv.org/abs/1609.05807" target="_blank">https://arxiv.org/abs/1609.05807</a>)</p>
<p>Doshi-Velez, F., & Kim, B. (2017). “Towards A Rigorous Science of Interpretable Machine Learning.” <a href="https://arxiv.org/abs/1702.08608" target="_blank">https://arxiv.org/abs/1702.08608</a>)</p>
<p>Rudin, C. (2019). “Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead.” <a href="https://arxiv.org/abs/1811.10154" target="_blank">https://arxiv.org/abs/1811.10154</a>)</p>
<p>Kirchenbauer, J., Geiping, J., Wen, Y., et al. (2023). “A Watermark for Large Language Models.” <a href="https://arxiv.org/abs/2301.10226" target="_blank">https://arxiv.org/abs/2301.10226</a>)</p>
<p>Gebru, T., Morgenstern, J., Vecchione, B., et al. (2021). “Datasheets for Datasets.” <a href="https://arxiv.org/abs/1803.09010" target="_blank">https://arxiv.org/abs/1803.09010</a>)</p>
<p>Mitchell, M., Wu, S., Zaldivar, A., et al. (2019). “Model Cards for Model Reporting.” <a href="https://arxiv.org/abs/1810.03993" target="_blank">https://arxiv.org/abs/1810.03993</a>)</p>
<h1 id="第13章-統合設計と実装ロードマップデジタルツインと架空キャラを「会社シミュレーション」へ接続する">第13章　統合設計と実装ロードマップ：デジタルツインと架空キャラを「会社シミュレーション」へ接続する</h1>
<p>この章は、これまでの章で扱った要素――人物表現、感情・性格、記憶、コンテクスト（文脈）制御、ツール利用、複数エージェント会議、評価、更新、倫理・法務――を、一つの「動くシステム」に統合するための実装指針をまとめる総合章である。目的は、読者が <strong>実在人物のデジタルツイン（CEO/COO/CTO/CFO）</strong> と、<strong>社内で役に立つ架空キャラクター</strong> を同じ基盤上で扱い、最終的に「会社の意思決定や振る舞いを、複数エージェントでシミュレーションできる」状態へ拡張できるようにすることだ。</p>
<p>ただし、ここで強調しておきたいのは、「統合」は“全部を足す”ことではない、という点である。人物らしいAIの失敗の多くは、要素の不足よりも、要素の混線と過剰結合から起きる。例えば、記憶を増やしすぎて参照が破綻したり、会議制度を複雑化しすぎて誤情報が増幅したり、更新パイプラインを強くしすぎて人格がドリフトしたりする。したがって本章では、統合設計の原理を「最小の分解」と「境界の明確化」として説明し、その上で、段階的に拡張できるアーキテクチャ、評価駆動のリリース、監査可能なログ、コストとレイテンシ（遅延）管理までを扱う。</p>
<p>以降では、まず統合設計の全体像を確率モデルとして表し、次にデータと記憶、推論ループ、会議オーケストレーション（進行制御）、評価と更新、運用（監視・障害対応・コスト最適化）へ進む。最後に、研究フロンティアと未解決課題を整理して、読者が自分のプロジェクトを「どこから始め、どこへ伸ばすか」を判断できる視点を与える。</p>
<hr>
<h2 id="131-統合の第一原理システムを「確率過程」として捉える">13.1　統合の第一原理：システムを「確率過程」として捉える</h2>
<p>人物らしいAIの統合設計を、最初に数学の言葉で書いておくと混線が減る。大規模言語モデル（Large Language Model: LLM）は、入力テキスト $x$ に対し出力テキスト $y$ を確率的に生成するモデルで、典型的には</p>
<p>$$ p_\theta(y\mid x) $$</p>
<p>という条件付き確率分布で表される（$\theta$ はモデルパラメータ）。しかし現実のシステムでは、外部記憶、検索、ツール、会議制度、アクセス制御、監査ログなどが加わるため、実際の生成分布は</p>
<p>$$ p(y \mid x; \theta, M, R, \mathcal{T}, \Pi, \mathcal{A}) $$</p>
<p>のように書ける。ここで $M$ は記憶ストア、$R$ は検索器（Information Retrieval: 情報検索）、$\mathcal{T}$ はツール集合、$\Pi$ は会議プロトコル（発言順序や検証ルール）、$\mathcal{A}$ はアクセス制御や監査の制度を表す。</p>
<p>この表現が重要なのは、改善の対象が $\theta$（重み）だけではないことを、最初から明確にするためである。実務では「本人らしさが出ない」原因がモデル能力ではなく、必要な過去ログが検索できていない、参照資料が曖昧、会議制度が同調を生む、ツール境界が甘く誤情報が増える、といった $(M,R,\Pi,\mathcal{A})$ 側の問題であることが多い。Generative Agents は、記憶検索と反省（reflection）を中心に、行動生成を外部構造で支える設計の強さを示した（Park et al., 2023  <a href="https://arxiv.org/abs/2304.03442" target="_blank">https://arxiv.org/abs/2304.03442</a> ）。つまり「統合」とは、LLMの外側に確率過程の構造を作ることでもある。</p>
<hr>
<h2 id="132-段階的統合の戦略可逆な部品から積み上げる">13.2　段階的統合の戦略：可逆な部品から積み上げる</h2>
<p>統合設計の実務的な鉄則は、「可逆な変更から始める」ことである。可逆とは、失敗したら戻せるという意味だ。重み更新（第11章）は強力だが、戻すのが難しく、人格ドリフトや回帰が起きやすい。これに対し、外部記憶の追加・修正、検索の改善、会議プロトコルの変更、ツール境界の強化は、比較的戻しやすく、原因と結果の対応も追いやすい。</p>
<p>したがって統合のロードマップは、次の順序を基本にすると失敗が減る。</p>
<p>まず、単体エージェントで「参照に基づく応答」と「情報不足時の保留・質問」が安定する状態を作る。次に、ツール利用を入れて「確かめてから言う」行動を増やす（ReAct: Reason+Act の枠組みがこの設計を支える。Yao et al., 2023  <a href="https://arxiv.org/abs/2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a> ）。その後、複数エージェント化し、会議の制度で誤情報カスケードや同調を抑える（第9章）。ここまでで初めて、評価（第10章）と更新（第11章）を回す価値が大きくなる。最後に、倫理・法務・真正性（第12章）の運用要件を“制度として固定”し、公開範囲と権限を設計する。</p>
<p>ここで注意すべきは、複数エージェントは「最後に足す」方が良いことが多い点である。複数エージェントは不具合を隠す。会議は“それっぽい結論”を生成しやすいが、その結論が根拠不足でも気づきにくい。ChatDev や MetaGPT が工程分解と検証を強調したのは、まさにこの問題に対する設計回答である（Qian et al., 2023  <a href="https://arxiv.org/abs/2307.07924" target="_blank">https://arxiv.org/abs/2307.07924</a> 、Hong et al., 2023  <a href="https://arxiv.org/abs/2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a> ）。</p>
<hr>
<h2 id="133-データと記憶の統合同じ基盤で「実在」と「架空」を扱う">13.3　データと記憶の統合：同じ基盤で「実在」と「架空」を扱う</h2>
<h3 id="1331-記憶の最小単位は「事実」ではなく「出来事＋出典＋権限」である">13.3.1　記憶の最小単位は「事実」ではなく「出来事＋出典＋権限」である</h3>
<p>人物らしいAIの記憶は、単に“知識を保存する箱”ではない。記憶は、（i）出典（provenance）、（ii）確度（confidence）、（iii）可視性（誰が見てよいか）、（iv）更新規則（いつ無効になるか）を含む必要がある。第12章で見たように、デジタルツインは本人の代理のように誤解され得るため、出典と権限が特に重要になる。架空キャラでも、社内相談は個人情報や機密を含むので同じだ。</p>
<p>このため、記憶の最小レコードを、次のような「イベント（event）」として設計すると統合がしやすい。ここでは概念設計として擬似スキーマを示す。</p>
<p>$$ m = (\text{id}, t, \text{actor}, \text{content}, \text{source}, \text{conf}, \text{visibility}, \text{ttl}) $$</p>
<p>ここで $t$ は時間、actor は誰の出来事か（CEO/COO/CTO/CFO/架空キャラ）、content は要約テキスト、source は出典（会議議事録、公開インタビュー、規程文書、ユーザーの申告など）、conf は確度、visibility はアクセス制御（部署・権限）、ttl は有効期限（time-to-live）である。ttl は「忘却」や「制度改定」と整合するために極めて有効である。情報は永遠に正しくない。ttl を持つと、運用での更新が自然になる。</p>
<p>このイベント設計は、Generative Agents が採用した「記憶を自然言語で保存し、検索で取り出す」方針と相性がよい（Park et al., 2023）。ただし、出典と権限は研究プロトタイプでは省略されがちなので、実務では必ず足すべきである。</p>
<h3 id="1332-検索のスコア関数類似度だけでは人物らしさが壊れる">13.3.2　検索のスコア関数：類似度だけでは人物らしさが壊れる</h3>
<p>記憶検索は情報検索（Information Retrieval: IR）の問題であるため、評価は precision@k や MRR、NDCG などが使える（第10章。NDCGは Järvelin & Kekäläinen, 2002  <a href="https://doi.org/10.1145/582415.582418" target="_blank">https://doi.org/10.1145/582415.582418</a> ）。しかし人物らしさでは、検索スコアが「意味類似度」だけだと壊れることが多い。なぜなら、人物らしさに効くのは、意味が似ている記憶ではなく、その人物の判断を決めた“典型局面”や“例外条件”だからである。</p>
<p>そこで実務では、検索スコアを少なくとも次の三要素の加重和として設計すると安定する。</p>
<p>$$ \mathrm{score}(q,m)=\alpha, \mathrm{sim}(q,m) + \beta, \mathrm{recency}(m) + \gamma, \mathrm{importance}(m) $$</p>
<p>$\mathrm{sim}$ はクエリ $q$ と記憶 $m$ の意味類似度、$\mathrm{recency}$ は新しさ、$\mathrm{importance}$ は重要度である。Generative Agents は、類似度・新しさ・重要度の組合せで記憶検索を行う設計を示した（Park et al., 2023）。重要度は、例えば「意思決定に影響した度合い」「後から参照された頻度」「人手で付けた重み」などで設計できる。ここで本質なのは、人物らしさは“平均的な類似”より“意思決定に効く記憶”に反応する、という点である。</p>
<h3 id="1333-実在と架空の違いを記憶の「許容創作領域」として表す">13.3.3　実在と架空の違いを、記憶の「許容創作領域」として表す</h3>
<p>統合システムで最も危険なのは、実在人物の領域に架空の創作が侵入することだ。そこで記憶には「この領域は創作可能か」を表すフラグを設けると運用が安定する。例えば、実在人物のエピソードは原則として創作不可で、出典があるときだけ引用できる。一方、架空キャラは未定義領域を創作してよいが、設定（カノン）と矛盾してはいけない。この違いを、記憶の visibility だけでなく、「創作可否（fictionality）」としても管理するのが有効である。</p>
<p>この設計は倫理・法務（第12章）を技術仕様へ落とす例であり、同時に評価（第10章）と更新（第11章）にも直結する。なぜなら、創作不可領域で創作が起きた場合は、人物らしさ以前に安全違反だからである。</p>
<hr>
<h2 id="134-推論ループとツール統合人間らしさを「確かめる行動」に寄せる">13.4　推論ループとツール統合：人間らしさを「確かめる行動」に寄せる</h2>
<h3 id="1341-ReActを最小骨格として採用する">13.4.1　ReActを最小骨格として採用する</h3>
<p>ツール利用を含む推論ループの最小設計として、ReAct（Reasoning and Acting）型が扱いやすい。ReActは、モデルが「考える（reason）」と「行動する（act）」を交互に行うことで、検索や計算など外部手段を使いながら解く枠組みを示した（Yao et al., 2023  <a href="https://arxiv.org/abs/2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a> ）。人物らしいAIに翻訳すると、重要なのは“賢い推論”そのものではなく、「確かめるべきことを確かめる」行動が自然に出ることだ。</p>
<p>ツールを使うべき条件を数式で書くと、最小には価値とコストの比較になる。あるツール呼び出し $a$ がもたらす期待価値を $\Delta V(a)$、コスト（時間・金銭・機密リスク）を (C$a$) とすると、</p>
<p>$$ \text{ツールを使う} \quad \Longleftrightarrow \quad \Delta V(a) > C(a) $$</p>
<p>という意思決定になる。ここで $\Delta V(a)$ は「誤り確率が下がる」「根拠が付く」「会議の合意が速くなる」といった価値を含む。ツール統合の核心は、モデルにこの比較を“暗黙に学ばせる”のではなく、制度として実装することだ。例えば、財務数値は必ず計算ツールで確認してから出力する、規程の引用は必ず文書検索で確認してから出力する、といった強制規則は、$\Delta V(a)$ を非常に大きくし、ツール利用を均衡にする（第9章のゲーム理論的発想）。</p>
<h3 id="1342-Toolformerの示唆ツール利用は「技能」として学習できる">13.4.2　Toolformerの示唆：ツール利用は「技能」として学習できる</h3>
<p>ツール利用を学習で強化する方向として Toolformer がある。Toolformer は、モデルがツール呼び出しを自律的に挿入し、その呼び出しが予測損失を下げるなら学習信号として採用する枠組みを提案した（Schick et al., 2023  <a href="https://arxiv.org/abs/2302.04761" target="_blank">https://arxiv.org/abs/2302.04761</a> ）。人物らしいAIでは、ツール呼び出しのタイミングや質問の出し方が“人間らしい慎重さ”に直結するため、ツール利用は有力な学習対象になる。</p>
<p>ただし注意がある。ツールはしばしば機密境界をまたぐ。したがって Toolformer 的に「必要なら勝手にツールを呼ぶ」を許すと、権限逸脱が起きやすい。第12章で述べた最小権限（least privilege）に従い、ツール呼び出しは、（i）入力最小化、（ii）出力のフィルタ、（iii）監査ログ、（iv）高リスク行為の人間承認、を制度として組み込む必要がある。ツール利用は“自由度”ではなく“責任”を増やす。</p>
<hr>
<h2 id="135-複数エージェント会議の統合制度で「誤情報の増幅」を止める">13.5　複数エージェント会議の統合：制度で「誤情報の増幅」を止める</h2>
<p>第9章で述べたように、複数エージェント化は相互依存と非定常性を導入し、誤情報カスケードや同調（groupthink）を起こしやすい（Janis, 1972）。統合設計では、会議プロトコル $\Pi$ を「人格」より上位の設計対象として扱う。</p>
<h3 id="1351-会議を四相に分ける独立思考→共有→検証→決定">13.5.1　会議を四相に分ける：独立思考→共有→検証→決定</h3>
<p>会議の最小プロトコルとして有効なのは、意見形成を次の四相に分離することだ。</p>
<p>第一相は独立思考である。CEO/COO/CTO/CFO それぞれが、他者の発言を見ずに見立てを作る。これにより、コンドルセ陪審定理で鍵になる独立性（独立に誤る確率を下げる）を部分的に確保できる（第9章）。</p>
<p>第二相は共有である。各自が結論と根拠を提出し、全員が読む。ここで重要なのは、根拠が「検証可能」な形で出ることだ。チープトーク（cheap talk）としての会話は歪むため、根拠の提示を制度として要求する（Crawford & Sobel, 1982  <a href="https://www.jstor.org/stable/1913390" target="_blank">https://www.jstor.org/stable/1913390</a> ）。</p>
<p>第三相は検証である。検証役（auditor）を置き、矛盾、根拠不足、数値の整合性を指摘する。これはAI安全で提案されるディベート（debate）的発想と整合する（Irving et al., 2018  <a href="https://arxiv.org/abs/1805.00899" target="_blank">https://arxiv.org/abs/1805.00899</a> ）。検証役は意思決定しない。意思決定に関わらせると、検証が政治化するためである。</p>
<p>第四相は決定である。ここで初めて、CEO単独決裁か、合意形成か、投票か、拒否権付き合議か（第9章の社会選択理論）を適用する。決定後は書記役が決定事項と未決事項をまとめ、次回の状態として保存する。MetaGPT が役割分担と標準作業手順（SOP）で品質を上げたのは、この分離の効果と同型である（Hong et al., 2023）。</p>
<p>この四相分離は、複数エージェントの会話フレームワーク（AutoGen 等）が採用する「役割と会話制御」の思想とも一致する（Wu et al., 2023  <a href="https://arxiv.org/abs/2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a> ）。ただし、本書の目的ではフレームワーク名より、相互作用を制御する原理の方が重要である。</p>
<h3 id="1352-社内の架空キャラを会議に入れるときの設計">13.5.2　社内の架空キャラを会議に入れるときの設計</h3>
<p>架空キャラ（社内で役に立つAIキャラクター）を会議に入れると、二つの設計方針がある。一つは「翻訳・整理役」として入れる方針で、議論の論点を整理し、矛盾を顕在化させ、意思決定を助ける。もう一つは「価値観の代表者」として入れる方針で、例えば顧客代表、現場代表、倫理代表など、会議が見落としがちな視点を担わせる。</p>
<p>前者は安全で、誤情報増幅を抑えやすい。後者は強力だが危険である。なぜなら、価値観代表は実質的に利得（第9章のゲーム理論）を持つプレイヤーになり、投票や合意形成に影響を与えるからだ。架空キャラを価値観代表として設計するなら、権限と責任の境界を明確にし、透明性（第12章）を強化する必要がある。特に社内では「AIが言ったから正しい」が起こりやすいので、架空キャラの発言が意思決定の唯一根拠にならない制度が不可欠である。</p>
<hr>
<h2 id="136-評価駆動リリース統合システムは「テストに合格したものだけを出す」">13.6　評価駆動リリース：統合システムは「テストに合格したものだけを出す」</h2>
<p>統合が進むほど、変更点が増え、回帰（以前できたことが壊れる）が起きやすい。第10章で述べた通り、評価は回帰テストとして機能させる必要がある。ここでは、その評価をリリース工程に埋め込む方法をまとめる。</p>
<h3 id="1361-ゲートと総合評価二段階の採用判断">13.6.1　ゲートと総合評価：二段階の採用判断</h3>
<p>多目的評価（第10章）をそのまま“重み付き平均”で統合してしまうと危険である。なぜなら、重要な制約（安全、機密、根拠）を満たしていないのに、会話が面白いだけで総合点が上がる、という事態が起きるからだ。統合設計では、評価を二段階にするのが扱いやすい。</p>
<p>第一段階はゲート（必須条件）である。例えば、根拠参照が必要な領域で参照がない断言をしていないか、アクセス制御違反がないか、矛盾率が一定以下か、確信度が校正されているか（Brier score など、第10章）、といった「落ちたら即不採用」の条件を置く。</p>
<p>第二段階は総合評価である。ゲートを通った候補の中で、本人らしさ、有用性、会議の納得感などを、ペア比較やElo/Bradley–Terryモデルで比較し採用する（Bradley & Terry, 1952  <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a> ）。</p>
<p>この二段階化は、倫理・法務（第12章）を評価仕様に落とす最も実務的な方法でもある。「守るべき境界」をゲートにし、それ以外の魅力や性能をその内側で最大化する。</p>
<h3 id="1362-LLM-as-a-Judge-は補助で使う評価モデルの妥当性点検">13.6.2　LLM-as-a-Judge は補助で使う：評価モデルの妥当性点検</h3>
<p>自動評価として、別のLLMに採点させる LLM-as-a-Judge は有用だが、バイアスが入りやすい（Zheng et al., 2023  <a href="https://arxiv.org/abs/2306.05685" target="_blank">https://arxiv.org/abs/2306.05685</a> ）。統合設計では、評価モデルに頼りすぎないために、少なくとも「評価モデルの判断」と「人間判断」の相関を定期的に測り、妥当性（第10章）を点検する運用が必要になる。評価モデルが好む文体（丁寧で長い説明）と、人物らしさ（意思決定の癖）がズレるのはよくある。評価の軸は、モデルが勝手に選ぶものではなく、設計者が定義するものである。</p>
<hr>
<h2 id="137-更新パイプラインの統合記憶更新と重み更新を混同しない">13.7　更新パイプラインの統合：記憶更新と重み更新を混同しない</h2>
<p>統合システムが成長すると、「この人物は最近変わった」「社内規程が改定された」「会議の方針が変わった」など、更新が必要になる。ここで最も危険なのは、可変情報をモデル重みに焼き付けてしまうことである（第11章）。</p>
<h3 id="1371-原則可変情報は外部安定技能は重み">13.7.1　原則：可変情報は外部、安定技能は重み</h3>
<p>実務の原則は単純で、頻繁に変わる情報（規程、組織構造、プロジェクト状況）、出典が重要な情報（本人発言、契約条件）、削除要求が来うる情報（個人情報）は外部記憶に置き、モデル重みには書き込まない。モデル重みで学習する価値が高いのは、手続きや技能である。例えば「不足時に断言せず質問する」「根拠を示す」「会議で反証を検討する」「機密を扱うときの手順を守る」といった技能は、SFT（教師あり微調整）や選好学習で改善できる（InstructGPT: Ouyang et al., 2022  <a href="https://arxiv.org/abs/2203.02155" target="_blank">https://arxiv.org/abs/2203.02155</a> ）。</p>
<h3 id="1372-選好最適化の実務DPOで“好ましい応答の確率差”を増やす">13.7.2　選好最適化の実務：DPOで“好ましい応答の確率差”を増やす</h3>
<p>更新の頻度が高い場合、強化学習（Reinforcement Learning: 強化学習）の運用コストが重いことがある。その場合、DPO（Direct Preference Optimization）が有力な選択肢になる（Rafailov et al., 2023  <a href="https://arxiv.org/abs/2305.18290" target="_blank">https://arxiv.org/abs/2305.18290</a> ）。DPOは、好ましい応答 $y^+$ と好ましくない応答 $y^-$ の対に対して、$\log \pi_\theta(y^+\mid x)-\log \pi_\theta(y^-\mid x)$ を大きくする方向へ直接最適化する。統合設計で重要なのは、DPOの“軸”を混ぜないことだ。本人らしさと安全性と面白さを一つの選好に混ぜると、更新がどこへ向かうか分からなくなる。多目的は分解し、ゲートを先に置き、その内側で選好最適化を回すのが安全である。</p>
<h3 id="1373-継続学習の落とし穴破滅的忘却と人格ドリフト">13.7.3　継続学習の落とし穴：破滅的忘却と人格ドリフト</h3>
<p>更新を続けると破滅的忘却（catastrophic forgetting）が起きる（Kirkpatrick et al., 2017 EWC  <a href="https://arxiv.org/abs/1612.00796" target="_blank">https://arxiv.org/abs/1612.00796</a> ）。人物らしさでは、忘却は単なる性能低下ではなく「人格が変わった」という事故になる。対策は第11章の通り、リプレイ（昔の代表例を混ぜる）と、参照モデルからの逸脱を抑える正則化（KL罰則）である。統合設計では、更新前後の評価を必須にし、さらに“戻せる”ようにバージョン管理を徹底する。人格を更新するとは、プロダクトを更新する以上に責任が重い。</p>
<hr>
<h2 id="138-運用工学監視・障害対応・観測可能性を「人格システム」に適用する">13.8　運用工学：監視・障害対応・観測可能性を「人格システム」に適用する</h2>
<p>人物らしいAIが実務で失敗する理由の一つは、運用設計がソフトウェア工学の基本から外れることだ。LLMは新しいが、運用で必要になる原理は古い。特に重要なのは、観測可能性（observability）、サービスレベル目標（Service Level Objective: SLO）、障害対応、変更管理である。</p>
<h3 id="1381-観測可能性分散トレーシングの思想を取り入れる">13.8.1　観測可能性：分散トレーシングの思想を取り入れる</h3>
<p>現代のシステムでは、単一の処理が、検索、複数のモデル呼び出し、ツール呼び出し、キャッシュ、監査、ログ書き込みなど多段になる。これを追跡できないと、なぜ誤ったかが分からない。分散トレーシングの古典的論文として、Googleの Dapper がある（Sigelman et al., 2010  <a href="https://research.google/pubs/dapper-a-large-scale-distributed-systems-tracing-infrastructure/" target="_blank">https://research.google/pubs/dapper-a-large-scale-distributed-systems-tracing-infrastructure/</a> ）。Dapper の要点は、「リクエスト単位のトレースIDを通し、各処理段の時間と因果関係を記録する」ことである。</p>
<p>人格システムのトレースでは、時間だけでなく「参照した記憶」「使ったツール」「会議の相（独立思考/検証/決定）」などの因果情報が重要になる。これは第10章の監査ログ設計と同じ方向である。トレースを残す目的は、個人監視ではなく、システムの失敗を再現し、是正できるようにすることだ。</p>
<h3 id="1382-SLOとエラーバジェット品質を“運用の数字”に落とす">13.8.2　SLOとエラーバジェット：品質を“運用の数字”に落とす</h3>
<p>SRE（Site Reliability Engineering: 信頼性工学）の考え方では、品質をSLOとして定義し、その達成度を継続監視する（Google SRE Book, 2016  <a href="https://sre.google/sre-book/table-of-contents/" target="_blank">https://sre.google/sre-book/table-of-contents/</a> ）。人格システムでは、SLOは単に「応答が速い」では足りない。例えば「根拠が必要な領域で根拠なし断言が一定以下」「機密違反がゼロ」「矛盾率が一定以下」「会議の誤情報カスケード率が一定以下」など、意味的品質のSLOが必要になる。</p>
<p>SLOを定量化する最小例として、ある期間における失敗率を $p$、許容上限を $\tau$ とすると、条件 $p\le \tau$ を満たすことが目標になる。エラーバジェットは $1-\tau$ に相当し、これを超える失敗が出たら新機能開発より安定化を優先する、という運用規律が成立する。これは「更新（第11章）を勝手に回さない」という倫理・法務の要求（第12章）とも整合する。</p>
<h3 id="1383-カオス工学壊しても致命傷にならない設計を確認する">13.8.3　カオス工学：壊しても致命傷にならない設計を確認する</h3>
<p>統合システムは必ず壊れる。検索が落ちる、外部APIが遅い、モデルが一時的に不安定、監査ストアが詰まる。重要なのは、壊れたときの振る舞いが安全であることだ。カオス工学（Chaos Engineering）は、意図的に障害を注入して、システムの耐障害性を検証する考え方である（Basiri et al., 2016 “Chaos Engineering”  <a href="https://doi.org/10.1109/MS.2016.31" target="_blank">https://doi.org/10.1109/MS.2016.31</a> ）。</p>
<p>人格システムでの“安全な劣化（graceful degradation）”の例を挙げるなら、検索が使えない場合は断言を避け、保留と追加質問に切り替える。会議の検証役が落ちた場合は、意思決定を止め、人間承認へ切り替える。監査ログが書けない場合は、高リスク領域では応答を止める。これらは「便利さ」より「責任」を優先する設計であり、第12章の制約付き最適化の具体例である。</p>
<hr>
<h2 id="139-コストとレイテンシ会社シミュレーションの“計算予算”を設計する">13.9　コストとレイテンシ：会社シミュレーションの“計算予算”を設計する</h2>
<p>会社シミュレーションは計算コストが膨らみやすい。複数役員×複数ターン×検証役×ツール呼び出しが積み上がるからだ。統合設計では、コストを“後から請求書で知る”のではなく、事前に式で見積もって設計を調整する。</p>
<h3 id="1391-トークンコストの最小モデル">13.9.1　トークンコストの最小モデル</h3>
<p>LLM利用のコストは多くの場合トークン数に比例する。入力トークン数を $t_{\text{in}}$、出力トークン数を $t_{\text{out}}$、単価を $c$（通貨/トークン）とすると、1呼び出しのコストは</p>
<p>$$ C = c,(t_{\text{in}} + t_{\text{out}}) $$</p>
<p>で近似できる。会議でエージェント数が $n$、ターン数が $m$、各ターンで平均コストが $\bar{C}$ なら、会議全体の概算コストは</p>
<p>$$ C_{\text{meeting}} \approx n,m,\bar{C} $$</p>
<p>になる。検証役や書記役を追加すると $n$ が増える。ツール呼び出しで検索結果を長く入れると $t_{\text{in}}$ が増える。つまり、会議制度の設計（第9章）はそのままコスト設計でもある。</p>
<h3 id="1392-レイテンシの見積もりとキューイング">13.9.2　レイテンシの見積もりとキューイング</h3>
<p>応答時間はユーザー体験と直結する。多段処理のレイテンシは、おおむね和で近似できる。検索時間を $T_R$、モデル呼び出し時間を $T_L$、ツール時間を $T_T$、その他を $T_0$ とすると、</p>
<p>$$ T_{\text{end-to-end}} \approx T_R + T_L + T_T + T_0 $$</p>
<p>になる。さらに実運用ではキュー（待ち行列）が効いてくる。到着率を $\lambda$、平均滞在時間を $W$、系内平均リクエスト数を $L$ とすると、リトルの法則（Little’s law）により</p>
<p>$$ L = \lambda W $$</p>
<p>が成り立つ。ここから、同時利用が増えると $W$ が急増する可能性があることが分かる。統合システムでは、会議が重い処理になるため、同期的に全部待たせるより、会議をバッチ処理にしたり、ユーザーに中間結果（暫定結論＋未確定点）を返して後続を続けるなど、UIと処理の分離が有効になる。</p>
<h3 id="1393-キャッシュと要約価値密度を上げてコストを下げる">13.9.3　キャッシュと要約：価値密度を上げてコストを下げる</h3>
<p>コスト削減で最も効くのは、同じことを何度も計算しないことである。検索結果のキャッシュ、会議の要約キャッシュ、個人の安定した設定のキャッシュは効果が高い。キャッシュヒット率を $h$ とすると、計算コストは</p>
<p>$$ C_{\text{eff}} \approx (1-h), C $$</p>
<p>に比例して減る。もちろんキャッシュは古くなる。そこで ttl（有効期限）を付け、重要度が低いものから短い ttl にする。これは第7章の忘却と同じ発想である。</p>
<p>要約も同様で、長い会議ログをそのまま次回コンテクストに入れるのではなく、情報価値密度の高い要約を作る必要がある。要約の価値を「評価スコアの差分」で見る、という発想は第6章・第10章で述べた。統合設計では、「要約で落とした情報が意思決定を変えない」ことを評価で保証しながら、コストを下げる。</p>
<hr>
<h2 id="1310-最終統合アーキテクチャ分業と境界を守る“教科書的ひな型”">13.10　最終統合アーキテクチャ：分業と境界を守る“教科書的ひな型”</h2>
<p>ここまでの設計原理を、実際のアーキテクチャとしてまとめる。以下は特定の製品やフレームワークを前提にしない、教科書的なひな型である。</p>
<p>まず、入力は「ユーザーの要求（質問）」と「状況（会議の議題、制約、参照権限）」である。次に、記憶検索と文書検索で必要情報を集める。ここで権限チェックを行い、参照してよいものだけを集める。次に、単体ならReAct型の推論ループで応答を生成する。会議なら四相プロトコルに従って複数エージェントを進行する。最後に、出力は根拠と不確実性を含めて提示し、監査ログ（トレース）を保存する。更新は運用ログと評価結果に基づいて別系統で回し、勝手に学習が走らないように承認フローを入れる。</p>
<p>この流れを図示すると、次のようになる（概念図）。</p>
<div class="architecture-diagram">
<svg viewBox="0 0 900 720" xmlns="http://www.w3.org/2000/svg" style="max-width: 100%; height: auto; font-family: 'Helvetica Neue', Arial, 'Hiragino Kaku Gothic ProN', 'Hiragino Sans', Meiryo, sans-serif;">
  <defs>
    <marker id="arrowhead" markerWidth="8" markerHeight="6" refX="7" refY="3" orient="auto">
      <polygon points="0 0, 8 3, 0 6" fill="#666"/>
    </marker>
    <marker id="arrowhead-feedback" markerWidth="8" markerHeight="6" refX="7" refY="3" orient="auto">
      <polygon points="0 0, 8 3, 0 6" fill="#9b59b6"/>
    </marker>
    <marker id="arrowhead-return" markerWidth="7" markerHeight="5" refX="6" refY="2.5" orient="auto">
      <polygon points="0 0, 7 2.5, 0 5" fill="#e67e22"/>
    </marker>
  </defs>

  <!-- 背景 -->
  <rect width="900" height="720" fill="#fafafa"/>

  <!-- Row 1: User → UI → Gateway → Access Control -->
  <g transform="translate(50, 30)">
    <!-- User -->
    <rect x="0" y="0" width="80" height="40" rx="20" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
    <text x="40" y="25" text-anchor="middle" fill="white" font-size="14" font-weight="bold">User</text>

    <!-- Arrow -->
    <line x1="80" y1="20" x2="120" y2="20" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

    <!-- UI/Client -->
    <rect x="130" y="0" width="100" height="40" rx="8" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
    <text x="180" y="25" text-anchor="middle" fill="white" font-size="13" font-weight="bold">UI/Client</text>

    <!-- Arrow -->
    <line x1="230" y1="20" x2="270" y2="20" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

    <!-- Gateway -->
    <rect x="280" y="0" width="120" height="40" rx="8" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
    <text x="340" y="25" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Gateway/API</text>

    <!-- Arrow -->
    <line x1="400" y1="20" x2="440" y2="20" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

    <!-- Access Control -->
    <rect x="450" y="0" width="130" height="40" rx="8" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
    <text x="515" y="25" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Access Control</text>
  </g>

  <!-- Arrow down from Access Control -->
  <line x1="565" y1="70" x2="565" y2="100" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

  <!-- Row 2: Memory Search / Doc Search (split) -->
  <g transform="translate(250, 110)">
    <!-- Memory Search -->
    <rect x="0" y="0" width="140" height="50" rx="8" fill="#1abc9c" stroke="#16a085" stroke-width="2"/>
    <text x="70" y="22" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Memory Search</text>
    <text x="70" y="40" text-anchor="middle" fill="white" font-size="11">記憶検索</text>

    <!-- Doc/Search Tools -->
    <rect x="180" y="0" width="160" height="50" rx="8" fill="#1abc9c" stroke="#16a085" stroke-width="2"/>
    <text x="260" y="22" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Doc/Search Tools</text>
    <text x="260" y="40" text-anchor="middle" fill="white" font-size="11">文書・検索ツール</text>
  </g>

  <!-- Split arrows from Access Control -->
  <path d="M 565 100 L 565 95 L 390 95 L 390 110" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 565 100 L 565 95 L 510 95 L 510 110" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

  <!-- Merge arrows to Context Builder -->
  <path d="M 320 160 L 320 175 L 450 175 L 450 190" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 510 160 L 510 175 L 450 175 L 450 190" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

  <!-- Row 3: Context Builder -->
  <g transform="translate(330, 195)">
    <rect x="0" y="0" width="160" height="50" rx="8" fill="#2ecc71" stroke="#27ae60" stroke-width="2"/>
    <text x="80" y="22" text-anchor="middle" fill="white" font-size="14" font-weight="bold">Context Builder</text>
    <text x="80" y="40" text-anchor="middle" fill="white" font-size="11">文脈構築</text>
  </g>

  <!-- Split: single-agent / multi-agent -->
  <path d="M 410 245 L 410 265 L 200 265 L 200 290" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 410 245 L 410 265 L 620 265 L 620 290" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

  <!-- Labels for split -->
  <text x="280" y="280" text-anchor="middle" fill="#666" font-size="12" font-style="italic">single-agent</text>
  <text x="540" y="280" text-anchor="middle" fill="#666" font-size="12" font-style="italic">multi-agent</text>

  <!-- Row 4: Agent Loop / Meeting Orchestrator -->
  <g transform="translate(80, 295)">
    <!-- Agent Loop -->
    <rect x="0" y="0" width="180" height="55" rx="8" fill="#27ae60" stroke="#1e8449" stroke-width="2"/>
    <text x="90" y="22" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Agent Loop</text>
    <text x="90" y="42" text-anchor="middle" fill="white" font-size="11">(ReAct-like)</text>
  </g>

  <g transform="translate(500, 295)">
    <!-- Meeting Orchestrator -->
    <rect x="0" y="0" width="190" height="55" rx="8" fill="#27ae60" stroke="#1e8449" stroke-width="2"/>
    <text x="95" y="22" text-anchor="middle" fill="white" font-size="13" font-weight="bold">Meeting Orchestrator</text>
    <text x="95" y="42" text-anchor="middle" fill="white" font-size="11">会議オーケストレータ</text>
  </g>

  <!-- Multi-agent details -->
  <line x1="595" y1="350" x2="595" y2="375" stroke="#666" stroke-width="2"/>
  <path d="M 595 375 L 430 375 L 430 395" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 595 375 L 595 395" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 595 375 L 760 375 L 760 395" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>

  <!-- Row 5: Multi-agent sub-components -->
  <g transform="translate(340, 400)">
    <rect x="0" y="0" width="130" height="45" rx="6" fill="#58d68d" stroke="#27ae60" stroke-width="2"/>
    <text x="65" y="18" text-anchor="middle" fill="white" font-size="11" font-weight="bold">CEO/COO/CTO/CFO</text>
    <text x="65" y="35" text-anchor="middle" fill="white" font-size="10">専門エージェント群</text>
  </g>

  <g transform="translate(510, 400)">
    <rect x="0" y="0" width="120" height="45" rx="6" fill="#58d68d" stroke="#27ae60" stroke-width="2"/>
    <text x="60" y="18" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Verifier/Auditor</text>
    <text x="60" y="35" text-anchor="middle" fill="white" font-size="10">検証・監査</text>
  </g>

  <g transform="translate(670, 400)">
    <rect x="0" y="0" width="130" height="45" rx="6" fill="#58d68d" stroke="#27ae60" stroke-width="2"/>
    <text x="65" y="18" text-anchor="middle" fill="white" font-size="11" font-weight="bold">Secretary/Summarizer</text>
    <text x="65" y="35" text-anchor="middle" fill="white" font-size="10">書記・要約</text>
  </g>

  <!-- Merge to Response -->
  <line x1="170" y1="350" x2="170" y2="480" stroke="#666" stroke-width="2"/>
  <path d="M 735 445 L 735 460 L 595 460 L 595 480" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 170 480 L 450 480 L 450 500" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 595 480 L 450 480" stroke="#666" stroke-width="2" fill="none"/>

  <!-- Row 6: Response -->
  <g transform="translate(340, 505)">
    <rect x="0" y="0" width="150" height="45" rx="8" fill="#e67e22" stroke="#d35400" stroke-width="2"/>
    <text x="75" y="18" text-anchor="middle" fill="white" font-size="14" font-weight="bold">Response</text>
    <text x="75" y="36" text-anchor="middle" fill="white" font-size="11">応答出力</text>
  </g>

  <!-- Response → UI (curved back) -->
  <path d="M 490 527 L 850 527 L 850 5 L 230 5 L 230 28" stroke="#e67e22" stroke-width="2" fill="none" stroke-dasharray="5,3" marker-end="url(#arrowhead-return)"/>
  <text x="860" y="300" text-anchor="middle" fill="#e67e22" font-size="11" transform="rotate(90, 860, 300)">→ UI へ返却</text>

  <!-- Response → Log -->
  <line x1="415" y1="550" x2="415" y2="575" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

  <!-- Row 7: Trace Log -->
  <g transform="translate(280, 580)">
    <rect x="0" y="0" width="200" height="40" rx="6" fill="#f39c12" stroke="#d68910" stroke-width="2"/>
    <text x="100" y="16" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Trace Log + Provenance</text>
    <text x="100" y="32" text-anchor="middle" fill="white" font-size="10">トレースログ・来歴</text>
  </g>

  <!-- Log → Evaluation -->
  <line x1="380" y1="620" x2="380" y2="645" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>

  <!-- Row 8: Evaluation -->
  <g transform="translate(240, 650)">
    <rect x="0" y="0" width="220" height="40" rx="6" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
    <text x="110" y="16" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Offline/Online Evaluation</text>
    <text x="110" y="32" text-anchor="middle" fill="white" font-size="10">オフライン・オンライン評価</text>
  </g>

  <!-- Feedback arrows (Update Pipeline) -->
  <path d="M 240 670 L 50 670 L 50 135 L 250 135" stroke="#9b59b6" stroke-width="2" fill="none" stroke-dasharray="4,2" marker-end="url(#arrowhead-feedback)"/>
  <path d="M 50 320 L 80 320" stroke="#9b59b6" stroke-width="2" fill="none" stroke-dasharray="4,2" marker-end="url(#arrowhead-feedback)"/>
  <path d="M 50 420 L 340 420" stroke="#9b59b6" stroke-width="2" fill="none" stroke-dasharray="4,2" marker-end="url(#arrowhead-feedback)"/>

  <!-- Feedback label -->
  <text x="30" y="420" text-anchor="middle" fill="#9b59b6" font-size="10" transform="rotate(-90, 30, 420)">Update Pipeline（更新パイプライン）</text>

  <!-- Legend -->
  <g transform="translate(620, 620)">
    <text x="0" y="0" fill="#666" font-size="11" font-weight="bold">凡例:</text>
    <rect x="0" y="10" width="16" height="12" rx="2" fill="#3498db"/>
    <text x="22" y="20" fill="#666" font-size="10">入力・アクセス</text>
    <rect x="0" y="28" width="16" height="12" rx="2" fill="#2ecc71"/>
    <text x="22" y="38" fill="#666" font-size="10">処理・エージェント</text>
    <rect x="0" y="46" width="16" height="12" rx="2" fill="#e67e22"/>
    <text x="22" y="56" fill="#666" font-size="10">出力・ログ</text>
    <rect x="0" y="64" width="16" height="12" rx="2" fill="#9b59b6"/>
    <text x="22" y="74" fill="#666" font-size="10">評価・更新</text>
    <line x1="110" y1="20" x2="140" y2="20" stroke="#9b59b6" stroke-width="2" stroke-dasharray="4,2"/>
    <text x="145" y="24" fill="#666" font-size="10">フィードバック</text>
  </g>
</svg>
</div>
<p>この図で最も大事なのは、「更新パイプライン」が推論経路と分離されている点である。推論経路に更新を混ぜると、運用中に人格が変わり、監査不能になる。更新は必ず評価ゲート（第10章）と承認（第12章）を通すべきである。</p>
<p>13.11　研究フロンティアと未解決課題：統合して初めて見える難問</p>
<p>最後に、統合したときに見えてくる未解決課題を整理する。ここでは「今すぐ解ける」とは限らないが、設計者が避けて通れない論点を、研究としての形で提示する。</p>
<p>第一の課題は、“本人らしさ”の妥当な定義と測定である。第10章で述べたように、妥当性と信頼性を満たす評価は難しい。特にデジタルツインは「本人が変わる」ので、固定ベンチマークでは追従できない。継続評価とドリフト検知（第10章）を、人格評価に適用する理論はまだ発展途上である。</p>
<p>第二の課題は、記憶の圧縮と可逆性である。会話ログや会議ログを要約すると、意思決定に重要な例外条件が落ちやすい。Generative Agents は反省（reflection）で高次の記憶を作る設計を示したが（Park et al., 2023）、圧縮がどの情報を落とすべきかを理論的に保証するのは難しい。情報理論的には、圧縮は相互情報量の保持問題に近い。状態 𝑆 S と要約 𝑍 Z の間の相互情報量 𝐼 ( 𝑆 ; 𝑍 ) I(S;Z) を保ちながら圧縮する、という発想がここに接続するが、実務で直接最適化するのは簡単ではない。</p>
<p>第三の課題は、<strong>複数エージェントの“真実性”</strong>である。第9章で述べた誤情報カスケードは、会議制度で抑えられるが完全には消えない。AI安全のディベート（Irving et al., 2018）や、検証役の導入、根拠付き生成の評価（FactScore: Min et al., 2023  <a href="https://arxiv.org/abs/2305.14251" target="_blank">https://arxiv.org/abs/2305.14251</a> ）などは部分解であるが、会議という相互作用の中で「どの条件で真実に収束するか」を一般に保証する理論はまだ弱い。ゲーム理論・意見ダイナミクス・情報検索・自然言語生成の交差点にある難問である。</p>
<p>第四の課題は、社会実装における真正性と信頼である。透かし（Kirchenbauer et al., 2023  <a href="https://arxiv.org/abs/2301.10226" target="_blank">https://arxiv.org/abs/2301.10226</a> ）は有望だが万能ではない。来歴保証（provenance）の標準化や、ユーザーが理解できる透明性UI、権限境界の設計は、技術と制度の共同設計が必要である。ここは「モデルが賢くなる」だけでは解決しない。</p>
<p>これらの課題は、研究としても実務としても、今後の中心になる。読者がこの本を読み終えたあとにすべきことは、最新フレームワークを追いかけることよりも、まず自分の用途に対して「何が真実で、何が創作で、何が危険で、どこに責任があるか」を仕様として書き、評価とログでそれを守れるようにすることである。そこから先に、学習や高度化が意味を持つ。</p>
<p>参考文献（リンク）</p>
<p>Park, J. S., O'Brien, J., Cai, C. J., et al. (2023). “Generative Agents: Interactive Simulacra of Human Behavior.”  <a href="https://arxiv.org/abs/2304.03442" target="_blank">https://arxiv.org/abs/2304.03442</a>)</p>
<p>Yao, S., Zhao, J., Yu, D., et al. (2023). “ReAct: Synergizing Reasoning and Acting in Language Models.”  <a href="https://arxiv.org/abs/2210.03629" target="_blank">https://arxiv.org/abs/2210.03629</a>)</p>
<p>Schick, T., Dwivedi-Yu, J., Dessì, R., et al. (2023). “Toolformer: Language Models Can Teach Themselves to Use Tools.”  <a href="https://arxiv.org/abs/2302.04761" target="_blank">https://arxiv.org/abs/2302.04761</a>)</p>
<p>Wu, Q., Bansal, G., Zhang, J., et al. (2023). “AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation.”  <a href="https://arxiv.org/abs/2308.08155" target="_blank">https://arxiv.org/abs/2308.08155</a>)</p>
<p>Hong, S., Zhuge, M., Chen, J., et al. (2023). “MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework.”  <a href="https://arxiv.org/abs/2308.00352" target="_blank">https://arxiv.org/abs/2308.00352</a>)</p>
<p>Qian, C., Cong, X., Yang, W., et al. (2023). “ChatDev: Communicative Agents for Software Development.”  <a href="https://arxiv.org/abs/2307.07924" target="_blank">https://arxiv.org/abs/2307.07924</a>)</p>
<p>Janis, I. L. (1972). Victims of Groupthink.（概説PDF例）  <a href="https://med.stanford.edu/content/dam/sm/pedsendo-1/documents/Groupthink_by_Iriving_L_Janis_Summary_pd.pdf" target="_blank">https://med.stanford.edu/content/dam/sm/pedsendo-1/documents/Groupthink_by_Iriving_L_Janis_Summary_pd.pdf</a>)</p>
<p>Crawford, V. P., & Sobel, J. (1982). “Strategic Information Transmission.” Econometrica.  <a href="https://www.jstor.org/stable/1913390" target="_blank">https://www.jstor.org/stable/1913390</a>)</p>
<p>Irving, G., Christiano, P., & Amodei, D. (2018). “AI Safety via Debate.”  <a href="https://arxiv.org/abs/1805.00899" target="_blank">https://arxiv.org/abs/1805.00899</a>)</p>
<p>Bradley, R. A., & Terry, M. E. (1952). “Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons.” Biometrika.  <a href="https://doi.org/10.1093/biomet/39.3-4.324" target="_blank">https://doi.org/10.1093/biomet/39.3-4.324</a>)</p>
<p>Sigelman, B. H., Barroso, L. A., Burrows, M., et al. (2010). “Dapper, a Large-Scale Distributed Systems Tracing Infrastructure.”  <a href="https://research.google/pubs/dapper-a-large-scale-distributed-systems-tracing-infrastructure/" target="_blank">https://research.google/pubs/dapper-a-large-scale-distributed-systems-tracing-infrastructure/</a>)</p>
<p>Beyer, B., Jones, C., Petoff, J., & Murphy, N. R. (2016). Site Reliability Engineering: How Google Runs Production Systems.（Web版）  <a href="https://sre.google/sre-book/table-of-contents/" target="_blank">https://sre.google/sre-book/table-of-contents/</a>)</p>
<p>Basiri, A., Behnam, N., de Rooij, R., et al. (2016). “Chaos Engineering.” IEEE Software.  <a href="https://doi.org/10.1109/MS.2016.31" target="_blank">https://doi.org/10.1109/MS.2016.31</a>)</p>
<p>Ouyang, L., Wu, J., Jiang, X., et al. (2022). “Training language models to follow instructions with human feedback (InstructGPT).”  <a href="https://arxiv.org/abs/2203.02155" target="_blank">https://arxiv.org/abs/2203.02155</a>)</p>
<p>Rafailov, R., Sharma, A., Mitchell, E., et al. (2023). “Direct Preference Optimization (DPO).”  <a href="https://arxiv.org/abs/2305.18290" target="_blank">https://arxiv.org/abs/2305.18290</a>)</p>
<p>Kirkpatrick, J., Pascanu, R., Rabinowitz, N., et al. (2017). “Overcoming catastrophic forgetting in neural networks (EWC).”  <a href="https://arxiv.org/abs/1612.00796" target="_blank">https://arxiv.org/abs/1612.00796</a>)</p>
<p>Järvelin, K., & Kekäläinen, J. (2002). “Cumulated gain-based evaluation of IR techniques.” ACM TOIS.  <a href="https://doi.org/10.1145/582415.582418" target="_blank">https://doi.org/10.1145/582415.582418</a>)</p>
<p>Kirchenbauer, J., Geiping, J., Wen, Y., et al. (2023). “A Watermark for Large Language Models.”  <a href="https://arxiv.org/abs/2301.10226" target="_blank">https://arxiv.org/abs/2301.10226</a>)</p>
<p>Min, S., et al. (2023). “FActScore: Fine-grained Evaluation of Factuality in Long-form Text Generation.”  <a href="https://arxiv.org/abs/2305.14251" target="_blank">https://arxiv.org/abs/2305.14251</a>)</p>
<h1 id="第14章-コンテクスト圧縮と要約長期一貫性を保つための情報理論と実装技法">第14章　コンテクスト圧縮と要約：長期一貫性を保つための情報理論と実装技法</h1>
<p>大規模言語モデル（Large Language Model: LLM）を「人間らしい意思決定や振る舞い」をするシステムに組み込むと、必ず直面する制約がある。<strong>会話が長くなると、過去の情報をすべて入力として与えられない</strong>という制約である。これは単に「入力できる文字数（トークン数）が有限」という話に留まらない。人物らしさは、過去の合意、以前の発言、価値観、未決事項、誰が何を約束したか、といった履歴に強く依存する。履歴が欠落すると、人格は揺らぎ、矛盾が増え、会議では誤情報が増幅しやすくなる（第9章）。したがって、人物らしさの実務における重要課題は「長い履歴を、短い入力にどう圧縮して残すか」である。</p>
<p>本章では、この問題を「コンテクスト圧縮（context compression）」として扱う。コンテクストとは、モデルが次の応答を生成する際に参照できる情報集合である。圧縮とは、元の情報量を減らしつつ、意思決定に必要な情報を保持する操作である。圧縮は単なる要約ではない。要約は圧縮の一手段に過ぎず、他にも、必要な部分だけを選び出して入れる「選択（selection）」、外部に保存して必要時に取り出す「検索（retrieval）」、意思決定に必要な状態だけを持つ「状態表現（state representation）」がある。さらに複数エージェント会議では、個々の発話ではなく「決定」「論点」「根拠」「反対理由」「宿題」といった構造を保つ圧縮が重要になる。</p>
<p>この章の目標は、圧縮を「勘と経験」ではなく、<strong>統計学と情報理論の言葉で定式化し、実装上の選択肢と評価方法まで含めて理解する</strong>ことにある。通し例として、実在人物のデジタルツイン（CEO/COO/CTO/CFO）と、社内で役に立つ架空キャラクターの双方を扱い、「実在は創作できない」「架空は未定義を埋められる」という違いが圧縮設計にどう影響するかも明確にする。</p>
<hr>
<h2 id="141-なぜ圧縮が難しいのか長期一貫性は「情報の保持」ではなく「意思決定の保持」である">14.1　なぜ圧縮が難しいのか：長期一貫性は「情報の保持」ではなく「意思決定の保持」である</h2>
<p>会話履歴を短くする最も素朴な方法は、過去ログを短く要約することだ。しかし、単に短くするだけでは失敗しやすい。理由は二つある。</p>
<p>第一に、人物らしさに効くのは「話題の概要」よりも「意思決定の条件」である。例えば、CEOが「この投資は前提として資金調達が成功したら進める」と言った、という条件付き合意は、要約で落ちると人格が壊れる。条件は文章として短いが、意思決定への影響は大きい。つまり、圧縮が保つべきものは「文章量」ではなく「将来の行動を決める情報」である。</p>
<p>第二に、要約自体が誤ると、その誤りが“公式記録”として固定される。元ログに誤りがあっても、あとで元ログへ戻れば修復できる。しかし要約が誤ると、その誤りが次の判断の前提になり、誤りが連鎖する。特に複数エージェント会議では、要約の誤りが共有状態となって誤情報カスケードを引き起こす（第9章）。この問題は第3章で扱った「もっともらしさ」と「真実性」が一致しないという性質と結びつく。要約はしばしば流暢で、誤っていても“それっぽい”ため、危険である。</p>
<p>したがって、圧縮の設計目標は次のように言い換えるのがよい。</p>
<p><strong>「履歴 $H$ を、将来の意思決定に必要な情報だけを含む表現 $Z$ に写像する。ただし $Z$ は短く、監査可能で、誤りが混入しにくい形を目指す。」</strong></p>
<hr>
<h2 id="142-統計学的見方履歴を「状態」に圧縮するという考え方">14.2　統計学的見方：履歴を「状態」に圧縮するという考え方</h2>
<h3 id="1421-履歴→状態十分統計量（sufficient-statistic）の直観">14.2.1　履歴→状態：十分統計量（sufficient statistic）の直観</h3>
<p>統計学には、観測データ全体を持たなくても推定に必要な情報だけを持てばよい、という考え方がある。その代表が<strong>十分統計量（sufficient statistic）</strong>である。例えば正規分布の平均を推定するとき、全データを保持しなくても「平均との差の二乗和」と「サンプル数」などが十分統計量になる、という古典的事実がある。</p>
<p>会話や意思決定にも同じ発想を適用できる。履歴 $H_t=(o_1,o_2,\dots,o_t)$（観測や発話の列）を、その人物が次にどう行動するかを決めるのに十分な状態 $Z_t$ に圧縮できれば、モデルは $H_t$ ではなく $Z_t$ を見ればよい。</p>
<p>形式的には、行動（応答やツール利用の選択）を $a_t$ とし、理想的な方策（policy）を $\pi^*(a_t\mid H_t)$ と書く。ここで状態 $Z_t=f(H_t)$ が「意思決定に関して十分」であるとは、次が近似的に成り立つことを意味する。</p>
<p>$$ \pi^*(a_t\mid H_t) \approx \pi^*(a_t\mid Z_t) $$</p>
<p>つまり、履歴の代わりに状態を見ても、同じような行動分布が得られるなら、その状態は意思決定に必要な情報を保っている。</p>
<p>人物らしさの圧縮が難しいのは、「どの情報が十分か」が人や状況で変わるからである。CFOの意思決定に必要な状態は、キャッシュフローやリスク許容度や規制制約を強く含む。CTOなら技術負債や信頼性や採用状況を含む。架空キャラなら設定（カノン）上の制約や口調の原則を含む。圧縮は、状態設計そのものになる。</p>
<h3 id="1422-POMDPの信念状態理論上の「最小状態」への道筋">14.2.2　POMDPの信念状態：理論上の「最小状態」への道筋</h3>
<p>より体系的な理論として、部分観測マルコフ決定過程（Partially Observable Markov Decision Process: POMDP）がある。POMDPは、環境の真の状態 $s_t$ が直接観測できず、観測 $o_t$ しか得られない状況で、行動 $a_t$ を選びながら報酬を最大化する枠組みである。代表的な入門サーベイとして Kaelbling, Littman, Cassandra（1998）がある（ <a href="https://doi.org/10.1016/S0004-3702%2898%2900023-X" target="_blank">https://doi.org/10.1016/S0004-3702(98)00023-X</a> ）。00023-X）。)</p>
<p>POMDPでは、履歴をすべて覚える代わりに、<strong>信念状態（belief state）</strong> $b_t(s)=P(s_t=s\mid o_{1:t},a_{1:t-1})$ を持てば十分だと示される。信念状態は「真の状態が何であるかについての確率分布」であり、これが履歴の十分統計量になる。信念更新はベイズ則で書ける。</p>
<p>$$b_t(s') \propto P(o_t\mid s') \sum_{s} P(s'\mid s, a_{t-1}), b_{t-1}(s)$$ 人物らしさの会話にこの式をそのまま適用することは難しいが、重要な示唆は明確である。すなわち、</p>
<p><strong>「過去をそのまま保持するのではなく、将来に必要な不確実性を含んだ“状態”へ圧縮し、状態を更新し続ける」</strong></p>
<p>という設計が、理論的にも筋が通っている。実務での圧縮は、厳密な確率分布 $b_t$ を持つ代わりに、「確からしさ（確信度）」「未確定な論点」「条件付き合意」などを状態として持つ設計になる。</p>
<hr>
<h2 id="143-情報理論的見方圧縮は「ビット数」と「歪み」のトレードオフである">14.3　情報理論的見方：圧縮は「ビット数」と「歪み」のトレードオフである</h2>
<h3 id="1431-シャノン情報とレート歪み理論圧縮の限界を定義する">14.3.1　シャノン情報とレート歪み理論：圧縮の限界を定義する</h3>
<p>情報理論の出発点は、シャノンの通信理論である（Shannon, 1948 “A Mathematical Theory of Communication”  <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x" target="_blank">https://doi.org/10.1002/j.1538-7305.1948.tb01338.x</a> ）。ここで重要なのは、情報量を「ビット」で扱い、圧縮の限界を数学で述べられることだ。</p>
<p>圧縮に直接関係する理論が<strong>レート歪み理論（rate–distortion theory）</strong>である。これは、圧縮後の表現が元の情報を完全には再現できない（歪みがある）とき、どれだけの情報量（レート）でどれだけの歪みまで許せるかの限界を与える理論で、シャノンが提案し、その後標準的に体系化された（教科書的整理として Cover & Thomas『Elements of Information Theory』が有名である）。</p>
<p>この枠組みでは、元のデータを $X$、圧縮表現を $Z$ とし、歪みを (d(X,Z)) と定義する。ここで歪みは「文章が一致するか」ではなく、意思決定に必要な情報がどれだけ失われたかとして設計すべきである。例えば、履歴 $H$ から導かれる望ましい行動分布 $\pi^*(a\mid H)$ と、圧縮表現 $Z$ から導かれる行動分布 $\pi^*(a\mid Z)$ のズレを、カルバック＝ライブラー・ダイバージェンス（Kullback–Leibler divergence）で定義するなら、</p>
<p>$$ d(H,Z) = D_{\mathrm{KL}}\big(\pi^*(\cdot\mid H)\ |\ \pi^*(\cdot\mid Z)\big) $$</p>
<p>が「意思決定歪み」になる。これを用いると、圧縮は「平均歪みを $D$ 以下に抑えつつ、表現の情報量を最小化する」問題として書ける。</p>
<p>$$ \min_{p(z\mid h)} I(H;Z)\quad \text{s.t.}\quad \mathbb{E}[d(H,Z)] \le D$$ ここで (I(H;Z)) は相互情報量（mutual information）で、履歴と圧縮表現の間にどれだけ情報が残っているかを表す。相互情報量は</p>
<p>$$I(H;Z)=\mathbb{E}_{h,z}\left[\log\frac{p(h,z)}{p(h)p(z)}\right]$$ で定義される。直観的には、$Z$ が $H$ を強く特定するほど (I(H;Z)) は大きい。圧縮とは (I(H;Z)) を下げることに相当する。</p>
<p>この定式化が与える最大の価値は、圧縮を「短くする工夫」ではなく、<strong>意思決定歪み $d$ をどう定義するかの設計問題</strong>として扱える点である。デジタルツインなら歪みは「本人の判断分布のズレ」に置くのが自然で、架空キャラなら歪みは「カノン矛盾」「有用性低下」の組合せとして定義するのが自然になる。</p>
<h3 id="1432-情報ボトルネック未来に必要な情報だけを残す圧縮">14.3.2　情報ボトルネック：未来に必要な情報だけを残す圧縮</h3>
<p>レート歪み理論は一般的だが、人物らしいAIでは「未来のタスクに必要な情報だけ残したい」という形で圧縮が現れる。この発想を直接扱うのが<strong>情報ボトルネック法（Information Bottleneck method）</strong>である（Tishby, Pereira, Bialek, 2000 “The Information Bottleneck Method”  <a href="https://arxiv.org/abs/physics/0004057" target="_blank">https://arxiv.org/abs/physics/0004057</a> ）。</p>
<p>情報ボトルネックでは、元のデータを $X$、保持したい目的変数（未来の意思決定やラベル）を $Y$、圧縮表現を $Z$ とし、「$Z$ は $X$ をできるだけ圧縮しつつ、$Y$ についての情報はできるだけ保持する」ことを目標にする。典型的な目的関数は</p>
<p>$$ \min_{p(z\mid x)}\ I(X;Z) - \beta I(Z;Y) $$</p>
<p>である。ここで $\beta$ はトレードオフ係数で、圧縮を重視するか、目的保持を重視するかを調整する。</p>
<p>会話圧縮に翻訳すると、$X$ を履歴 $H_t$、$Y$ を次の意思決定（例えば次に選ぶ行動 $a_{t+1}$ や、次の会議の結論）と見なせる。すると、良い要約とは「履歴を短くしている（(I(H;Z)) が小さい）」だけでなく、「次の意思決定に必要な情報を保っている（(I(Z;Y)) が大きい）」も同時に満たす要約である、ということになる。</p>
<p>実務でこの式を直接最適化することは簡単ではないが、設計指針として非常に強い。要約を評価するとき、ROUGEのような表層一致だけを見るのではなく、「この要約を入れたとき、意思決定や会議結論がどれだけ変わるか」を主要評価に据えるべきである、という結論が自然に導かれる。</p>
<hr>
<h2 id="144-実装技法Ⅰ選択（selection）としての圧縮――何を入れて何を捨てるか">14.4　実装技法Ⅰ：選択（selection）としての圧縮――何を入れて何を捨てるか</h2>
<p>圧縮の最も堅牢な実装は、要約で文章を作り直すより、<strong>元ログから必要な部分を選んで入れる</strong>ことだ。これは誤り混入（要約の幻覚）を抑えやすい。もちろん、選び方を誤ると重要情報が落ちるので、ここでは「選択」を最適化問題として扱う。</p>
<h3 id="1441-予算制約付き選択ナップサックとしてのコンテクスト設計">14.4.1　予算制約付き選択：ナップサックとしてのコンテクスト設計</h3>
<p>入力に入れられる量（トークン数）には予算 $B$ があると考える。候補となる情報片（発話、メモ、会議ログ断片）を $i=1,\dots,n$ とし、長さ（コスト）を $c_i$、価値（意思決定への効き）を $v_i$ とする。すると「総コストが $B$ 以下で、価値の合計を最大化する」という問題は、古典的な0-1ナップサック問題として書ける。</p>
<p>$$ \max_{S\subseteq {1,\dots,n}} \sum_{i\in S} v_i \quad \text{s.t.}\quad \sum_{i\in S} c_i \le B$$ ナップサック問題は一般に計算困難（組合せ最適化として難しい）だが、実務では厳密解よりも「良い近似」が重要である。最小の近似は、価値密度 $v_i/c_i$ の高いものから貪欲（greedy）に入れていく方法で、シンプルだが意外に効くことが多い。ここで重要なのは $v_i$ の設計である。価値は「類似度が高い」だけではなく、「条件」「約束」「例外」「決定事項」を高く評価するように作るべきである。</p>
<h3 id="1442-多様性を保つ最大周辺関連（MMR）で「似たものばかり」を避ける">14.4.2　多様性を保つ：最大周辺関連（MMR）で「似たものばかり」を避ける</h3>
<p>検索や類似度に基づく選択では、似た情報片が上位を占め、重要だが異なる観点の情報が落ちやすい。これを抑える古典的手法が<strong>最大周辺関連（Maximum Marginal Relevance: MMR）</strong>である（Carbonell & Goldstein, 1998  <a href="https://doi.org/10.1145/290941.291025" target="_blank">https://doi.org/10.1145/290941.291025</a> ）。</p>
<p>MMRは、すでに選んだ集合を $S$、候補文書を $d$、クエリを $q$ とし、「クエリへの関連性」と「選んだ集合との冗長性」の差を最大化する。</p>
<p>$$ \mathrm{MMR}(d) = \lambda, \mathrm{Sim}(q,d) - (1-\lambda)\max_{d'\in S}\mathrm{Sim}(d,d') $$</p>
<p>$\lambda\in[0,1]$ は関連性と多様性の重みである。これを繰り返して選ぶと、「クエリに関係しつつ、同じ話ばかりにならない」コンテクストが作れる。人物らしさでは、多様性は単なる飾りではない。CEO/COO/CTO/CFO会議では、財務・技術・運用・市場の観点が同時に必要であり、似た根拠ばかり集めると判断が偏る。MMRはこの偏りを減らす最小の道具になる。</p>
<h3 id="1443-選択の品質を上げる鍵は「単位」の設計である">14.4.3　選択の品質を上げる鍵は「単位」の設計である</h3>
<p>実務でよくある失敗は、候補の単位が粗すぎることだ。例えば議事録1本を丸ごと候補にすると、長すぎて予算を食い、重要箇所だけ残すことができない。逆に1文単位だと、文脈が切れて意味が壊れる。したがって候補単位は、「1つの決定」「1つの条件」「1つの反対理由」「1つの宿題」など、意思決定に直結する粒度に分割しておくと、選択が安定する。これは第7章で扱った「記憶の最小単位」を、圧縮の観点から再確認していることに他ならない。</p>
<hr>
<h2 id="145-実装技法Ⅱ要約（summarization）としての圧縮――文章を作り直すときの設計">14.5　実装技法Ⅱ：要約（summarization）としての圧縮――文章を作り直すときの設計</h2>
<p>選択は堅牢だが、長期運用では限界が来る。会話が数百・数千ターンになると、毎回検索して断片を貼るだけでは、全体像が失われる。そこで要約が必要になる。ただし要約は危険であり、設計原則が必要である。</p>
<h3 id="1451-抽出的要約と生成的要約どちらが安全か">14.5.1　抽出的要約と生成的要約：どちらが安全か</h3>
<p>要約には大きく二種類ある。<strong>抽出的要約（extractive summarization）</strong>は元文から重要文を抜き出して並べる方法で、誤り混入が少ない。一方、<strong>生成的要約（abstractive summarization）</strong>は元文の内容を言い換えて新しい文章を生成する方法で、読みやすいが誤り混入が起きやすい。</p>
<p>抽出的要約の代表的アルゴリズムとして TextRank がある。TextRankは文をノードとするグラフを作り、PageRankのように重要文をランキングする（Mihalcea & Tarau, 2004 “TextRank: Bringing Order into Texts”  <a href="https://aclanthology.org/W04-3252/" target="_blank">https://aclanthology.org/W04-3252/</a> ）。抽出的要約は「文を抜く」だけなので、デジタルツインのように出典が重要な領域で特に有効である。</p>
<p>生成的要約は、会議の論点整理や、社内キャラの応対履歴の整理には便利だが、誤り混入の危険がある。したがって生成的要約を使うなら、「要約文は、必ず元文の引用可能な根拠に紐づく」という制約を設けるべきである。要約の各文に、根拠となった原文箇所のID（ログ位置や文書ID）を持たせる設計は、監査可能性（第10章・第12章）に直結する。</p>
<h3 id="1452-段階要約（hierarchical-summarization）一気に要約しない">14.5.2　段階要約（hierarchical summarization）：一気に要約しない</h3>
<p>長い履歴を一発で要約すると、重要な条件や例外が落ちやすい。そこで有効なのが段階要約である。例えば「日次要約→週次要約→月次要約」のように、短い範囲をまず要約し、それをさらに要約する階層を作る。人間の記憶も、出来事（エピソード）を束ねて一般化したスキーマ（概念）として保持する傾向がある。心理学では、エピソード記憶と意味記憶の区別が古典的に議論されている（Tulving, 1972 “Episodic and Semantic Memory”）。</p>
<p>段階要約の設計で最も重要なのは、「何を上位へ持ち上げ、何を下位に残すか」である。意思決定に効く条件や例外、未決事項、責任者、期限は上位へ持ち上げる価値が高い。一方、雑談や一時的な感情表現は上位では不要なことが多い。ただし架空キャラの場合は、口調や感情表現がキャラ性そのものなので、感情の傾向を上位要約に残す価値がある。このように、要約階層に何を残すかは「人物らしさの定義」に依存する。</p>
<h3 id="1453-要約の誤りを固定しない定期的な“再接地（re-grounding）”">14.5.3　要約の誤りを固定しない：定期的な“再接地（re-grounding）”</h3>
<p>段階要約の最大の危険は、誤りが上位へ伝播して固定されることだ。そこで必要なのが、定期的な再接地である。再接地とは、上位要約だけを信じるのではなく、一定頻度で元ログへ戻り、要約が妥当かを検証し直すことだ。これは第10章で扱った監査と同じ思想である。</p>
<p>実装としては、上位要約が参照する「根拠ID」を必ず保持し、疑義が出たときに根拠へ遡れるようにする。さらに、重要な要約（決定事項や条件付き合意）については、根拠へ戻って抽出的に確認し、生成的要約を修正する。要約は“真実”ではなく“便利な近似”であり、近似である以上、検証可能性を必ずセットで持つべきである。</p>
<hr>
<h2 id="146-実装技法Ⅲ構造化圧縮――「文章」ではなく「台帳」として残す">14.6　実装技法Ⅲ：構造化圧縮――「文章」ではなく「台帳」として残す</h2>
<p>人物らしさの長期一貫性に特に効くのは、文章の要約ではなく、<strong>構造化された記録</strong>である。会議の後に残すべきものは、会話の全文ではなく、意思決定の台帳（ledger）である、という発想がここにある。</p>
<h3 id="1461-決定台帳会議ログを「決定」「根拠」「未決」「宿題」に分解する">14.6.1　決定台帳：会議ログを「決定」「根拠」「未決」「宿題」に分解する</h3>
<p>会社シミュレーションにおいて、会議の目的は「結論と次の行動」を作ることだ。従って圧縮結果として最低限必要なのは、次の時間ステップに影響する状態である。POMDPの信念状態が「未来の最適行動に十分」であったのと同様、会議台帳は「次の会議・次の実行に十分」である必要がある。</p>
<p>例えば、CEO/COO/CTO/CFO会議の圧縮結果は、文章よりも次のような構造を持つ方が壊れにくい。</p>
<ul>
<li>決定事項：何を、いつ、誰が、どの条件で実行するか</li>
<li>根拠：参照した資料、数値、仮定</li>
<li>反対意見：反対理由と、解消条件（反証が出たらどうするか）</li>
<li>未決事項：不確実性が残る論点と、追加で集めるべき情報</li>
<li>宿題：担当者（owner）と期限（due date）</li>
</ul>
<p>ここで重要なのは、反対意見を残すことだ。反対意見を落とす要約は、会議を“合意の物語”に変えてしまい、次の会議で同じ議論を繰り返すか、誤った合意を強化する。第9章で扱った集団意思決定の失敗（同調、誤情報カスケード）は、反対意見が記録から消えると起きやすい。したがって、圧縮は「議論の記録」ではなく「反証可能性の維持」を目標に含めるべきである。</p>
<h3 id="1462-約束の追跡人物らしさは「発言」より「コミットメント」で保たれる">14.6.2　約束の追跡：人物らしさは「発言」より「コミットメント」で保たれる</h3>
<p>人物らしさを支える情報の一つは、誰が何を約束したかである。会議でも1対1の対話でも、約束は信頼の土台であり、約束を忘れると人格が崩れる。そこで圧縮結果に「コミットメント（commitment）」を明示的に残す設計が有効になる。</p>
<p>コミットメントは、時間 $t$ における人物 $p$ の約束を $c=(p,\ \text{action},\ \text{deadline},\ \text{conditions})$ のように表せる。これを集合 $C_t$ として状態に含めれば、次の応答や会議では $C_t$ を参照して矛盾を減らせる。これは「人物らしさ」を、文体模倣ではなく、行動の一貫性として扱う（第4章・第10章）ことと整合する。</p>
<hr>
<h2 id="147-圧縮の評価ROUGEより「下流タスク性能」で測る">14.7　圧縮の評価：ROUGEより「下流タスク性能」で測る</h2>
<p>圧縮の評価は難しい。要約研究では、要約と参照要約の表層一致を測る ROUGE が有名である（Lin, 2004 “ROUGE”  <a href="https://aclanthology.org/W04-1013/" target="_blank">https://aclanthology.org/W04-1013/</a> ）。また、埋め込み表現の類似で評価する BERTScore も提案されている（Zhang et al., 2019  <a href="https://arxiv.org/abs/1904.09675" target="_blank">https://arxiv.org/abs/1904.09675</a> ）。しかし人物らしさの圧縮では、これらは補助に留めるべきである。理由は、表層一致が高くても意思決定に必要な条件が落ちていることがあり、逆に表層一致が低くても意思決定に十分な要約があり得るからである。</p>
<p>本書の立場では、圧縮評価は原則として「下流タスク性能」で測る。下流タスクとは、圧縮表現を入力に入れたときの、人物らしさや会議品質の指標である（第10章）。例えば、圧縮表現 $Z$ を使ったときの性能を $J(\pi;Z)$、元履歴 $H$ を使ったときの性能を $J(\pi;H)$ とし、性能差を</p>
<p>$$ \Delta J = J(\pi;H) - J(\pi;Z) $$</p>
<p>として測れば、圧縮による劣化が直接測れる。圧縮の設計は、「$\Delta J$ を小さくしつつ、コスト（トークン数）を下げる」多目的最適化になる。</p>
<p>さらに、圧縮で特に重要な失敗を「ゲート条件」として評価に入れるべきである。例えば、条件付き合意が要約から消えて断言が増える、未決事項が消えてリスクが見えなくなる、反対意見が消えて同調が増える、といった失敗は、総合点で相殺されてはいけない。第13章で述べた「ゲートと総合評価」の二段階は、圧縮評価でも同じく有効である。</p>
<hr>
<h2 id="148-通し例CEO/COO/CTO/CFO-会議と社内キャラにおける圧縮設計">14.8　通し例：CEO/COO/CTO/CFO 会議と社内キャラにおける圧縮設計</h2>
<h3 id="1481-実在人物のデジタルツイン圧縮は「創作禁止」を守れる形で行う">14.8.1　実在人物のデジタルツイン：圧縮は「創作禁止」を守れる形で行う</h3>
<p>実在人物のデジタルツインでは、圧縮の最大リスクは“創作の混入”である。要約が「本人が言っていないこと」をそれっぽく書くと、次の応答でそれが事実のように扱われる。したがって、デジタルツインの圧縮は、抽出的要約や、根拠ID付きの構造化圧縮を基本にするのが安全である。</p>
<p>例えば、CEOの意思決定に関わる条件を圧縮で残すとき、「本人が言った原文の引用」または「原文箇所への参照」を必須にする。条件が見つからないなら、圧縮結果に「未確定」として残す。圧縮が“分からない”を表現できるようにすることは、人物らしさだけでなく安全（第12章）にも直結する。</p>
<p>会議の圧縮では、決定台帳を中心にする。特に「前提」「反対意見」「未決事項」を残すと、次回会議で「なぜそう決めたか」「何が変われば撤回するか」が追跡できる。これは、デジタルツインが本人の“合理性”を装って誤りを固定することを防ぐ。</p>
<h3 id="1482-社内で役に立つ架空キャラ圧縮は「役立つ状態」を作るために行う">14.8.2　社内で役に立つ架空キャラ：圧縮は「役立つ状態」を作るために行う</h3>
<p>架空キャラの圧縮は、デジタルツインより自由度が高いが、別のリスクがある。ユーザーの相談履歴を圧縮して残すと、個人情報や機密が混入しやすい（第12章）。従って、圧縮結果にはアクセス制御と保持期限（ttl: time-to-live）を付け、必要以上に残さない設計が重要になる。</p>
<p>架空キャラが“役に立つ”ための圧縮は、ユーザーの状況を「状態」として保持する設計と相性が良い。例えば「ユーザーはどの制度で困っているか」「何を既に試したか」「どの選択肢が禁則か」といった、次の助言に必要な情報を状態に残す。逆に、雑談の全文や感情表現の細部は、役立つ状態には不要なことが多い。ただし、キャラ性を維持するために「口調の方針」や「価値観の核」だけは上位状態に残す価値がある。このときも、状態は短く、更新規則が明確で、誤りが固定しにくい形が望ましい。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、長期一貫性を支えるコンテクスト圧縮を、統計学（十分統計量、POMDPの信念状態）と情報理論（レート歪み理論、情報ボトルネック）で定式化し、実装技法として「選択」「要約」「構造化圧縮」を整理した。</p>
<p>最も重要な結論は、圧縮は「短くする技術」ではなく、「意思決定に必要な情報を保持する設計」であるという点である。文章の要約だけに頼ると誤りが固定されやすい。選択と構造化を組み合わせ、根拠への参照と再接地を組み込み、下流タスク性能で圧縮品質を測る。これが、人物らしいAIを長期運用へ持ち込むための現実的な道筋になる。</p>
<p>次章では、ここまでで作った人物らしい複数エージェントを、「組織シミュレーション」からさらに進めて、制度設計・市場環境・外乱（事故、競合、規制）を含む動的環境でどう運用し、どんな研究課題が残るかを扱う。圧縮はその基盤であり、圧縮を誤るとシミュレーション全体が“それっぽいが壊れた物語”になってしまう。圧縮は地味だが、最重要の土台である。</p>
<hr>
<h2 id="参考文献（リンク）">参考文献（リンク）</h2>
<p>Shannon, C. E. (1948). “A Mathematical Theory of Communication.” <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x" target="_blank">https://doi.org/10.1002/j.1538-7305.1948.tb01338.x</a>)</p>
<p>Cover, T. M., & Thomas, J. A. (2006). *Elements of Information Theory (2nd ed.).*（レート歪み理論の標準的整理） <a href="https://onlinelibrary.wiley.com/doi/book/10.1002/047174882X" target="_blank">https://onlinelibrary.wiley.com/doi/book/10.1002/047174882X</a>)</p>
<p>Tishby, N., Pereira, F. C., & Bialek, W. (2000). “The Information Bottleneck Method.” <a href="https://arxiv.org/abs/physics/0004057" target="_blank">https://arxiv.org/abs/physics/0004057</a>)</p>
<p>Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). “Planning and Acting in Partially Observable Stochastic Domains.” <a href="https://doi.org/10.1016/S0004-3702%2898%2900023-X" target="_blank">https://doi.org/10.1016/S0004-3702(98)00023-X</a> 00023-X)</p>
<p>Carbonell, J., & Goldstein, J. (1998). “The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries.” <a href="https://doi.org/10.1145/290941.291025" target="_blank">https://doi.org/10.1145/290941.291025</a>)</p>
<p>Mihalcea, R., & Tarau, P. (2004). “TextRank: Bringing Order into Texts.” <a href="https://aclanthology.org/W04-3252/" target="_blank">https://aclanthology.org/W04-3252/</a>)</p>
<p>Lin, C.-Y. (2004). “ROUGE: A Package for Automatic Evaluation of Summaries.” <a href="https://aclanthology.org/W04-1013/" target="_blank">https://aclanthology.org/W04-1013/</a>)</p>
<p>Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., & Artzi, Y. (2019). “BERTScore: Evaluating Text Generation with BERT.” <a href="https://arxiv.org/abs/1904.09675" target="_blank">https://arxiv.org/abs/1904.09675</a>)</p>
<p>Tulving, E. (1972). “Episodic and Semantic Memory.”（記憶の古典的整理。書誌情報例） <a href="https://psycnet.apa.org/record/1973-03982-001" target="_blank">https://psycnet.apa.org/record/1973-03982-001</a>)</p>
<h1 id="第15章-環境・因果・不確実性会社／社会シミュレーションを「反実仮想の実験装置」にする">第15章　環境・因果・不確実性：会社／社会シミュレーションを「反実仮想の実験装置」にする</h1>
<p>第13章では、人物らしいエージェントを実装・運用へ統合するためのロードマップを示し、第14章では長期一貫性のためのコンテクスト圧縮を情報理論と実装技法で整理した。ここまでで、実在人物のデジタルツイン（CEO/COO/CTO/CFO）や、社内で役に立つ架空キャラクターを、単体あるいは複数の会議として動かすところまでは見通しが立つ。</p>
<p>しかし「会社や社会をシミュレーションしたい」という目標に進むと、問題の性質が一段変わる。会話システムは、基本的に「与えられた入力に対して、どのような返答をするか」を問う。一方で会社や社会のシミュレーションは、「もし意思決定を変えたら、未来の状態がどう変わるか」を問う。つまり、必要なのは“文章生成”よりも、“介入（intervention）”と“反実仮想（counterfactual）”の扱いである。</p>
<p>この章では、人物らしいエージェントを、外部の動的環境（市場、競合、規制、事故、採用市場、技術トレンドなど）と結合し、意思決定の実験装置として使うための理論と実装原理を体系化する。中心となるのは、（i）環境を確率過程として定式化する枠組み（マルコフ決定過程・マルコフゲーム）、（ii）介入と反実仮想を扱う因果推論（構造的因果モデル・潜在結果）、（iii）シミュレーションの同定不能性（identifiability）と不確実性（uncertainty）を管理する手法（校正・感度分析・不確実性伝播）、である。</p>
<p>通し例としては、実在人物のデジタルツインを使った経営会議シミュレーションと、社内で役に立つ架空キャラを使った意思決定支援の両方を扱い、同じ理論でも「許される創作」と「許されない創作」が違うこと、そして“シミュレーション結果を真実と誤解させない”制度設計が不可欠であることを明確にする。</p>
<hr>
<h2 id="151-「予測」と「介入」は違う会社シミュレーションが因果を必要とする理由">15.1　「予測」と「介入」は違う：会社シミュレーションが因果を必要とする理由</h2>
<p>会社の意思決定で本当に知りたいのは、しばしば次のような問いである。</p>
<p>「価格を上げたら売上はどう変わるか」 「採用を増やしたら開発速度は上がるか」 「広告費を削ったら解約率はどう変わるか」 「セキュリティ投資を減らしたら、事故の期待損失はどう変わるか」</p>
<p>これらはすべて「もし〜したら」という問いで、統計学では介入、因果推論では反実仮想に対応する。ここで重要なのは、単なる予測 $P(Y\mid X=x)$ と、介入効果 $P(Y\mid do(X=x))$ は一般に一致しない、という点である（Pearl, 1995; Pearl, 2009）。</p>
<p>予測 $P(Y\mid X=x)$ は「$X$ が $x$ のとき $Y$ はどうなりがちか」を表す。介入 $P(Y\mid do(X=x))$ は「外部から $X$ を $x$ に固定したとき $Y$ はどうなるか」を表す。会社では、価格 $X$ が高いとき売上 $Y$ が高い、という相関が観測されても、それは「人気商品だから高くても売れる」という共通原因（confounder）があるだけかもしれない。価格を上げる介入をすると、売上は下がる可能性がある。したがって、会社シミュレーションを意思決定に使うなら、予測ではなく介入を扱う必要がある。</p>
<p>人物らしいAIを使ったシミュレーションで、ここを曖昧にすると危険である。エージェントが流暢に「価格を上げても売れます」と言っても、それが予測なのか介入なのかが混ざると、意思決定としては使えない。第10章で述べたように、流暢さは真実性を保証しない。会社シミュレーションは、まさにこの違いが致命的になる領域である。</p>
<hr>
<h2 id="152-環境を確率過程として書くマルコフ決定過程とマルコフゲーム">15.2　環境を確率過程として書く：マルコフ決定過程とマルコフゲーム</h2>
<h3 id="1521-単体の意思決定マルコフ決定過程（MDP）">15.2.1　単体の意思決定：マルコフ決定過程（MDP）</h3>
<p>動的環境を数学で扱う基本枠組みが、<strong>マルコフ決定過程（Markov Decision Process: MDP）</strong>である。MDPは、状態 $s_t$、行動 $a_t$、状態遷移確率 $P(s_{t+1}\mid s_t,a_t)$、報酬 $r_t=r(s_t,a_t)$ で定義される。時刻 $t$ の情報が状態 $s_t$ に十分に要約されていれば（第14章の「状態圧縮」）、未来は過去の詳細に依存せず</p>
<p>$$ P(s_{t+1}\mid s_{0:t}, a_{0:t}) = P(s_{t+1}\mid s_t, a_t) $$</p>
<p>が成り立つ。この性質がマルコフ性である。方策（policy） $\pi(a\mid s)$ を決めると、期待累積報酬</p>
<p>$$J(\pi)=\mathbb{E}*\pi\left[\sum_{t=0}^{T} \gamma^t r(s_t,a_t)\right]$$ を最大化する問題になる（(\gamma\in$0,1]$ は割引率）。MDPの教科書としては Sutton & Barto の強化学習入門が広く使われる（Sutton & Barto, 2018  <a href="https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf" target="_blank">https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf</a> ）。</p>
<p>会社シミュレーションに翻訳すると、状態 $s_t$ は「市場需要、競合状況、価格、顧客満足、キャッシュ、技術負債、人員構成、規制状態」といった変数の集合になる。行動 $a_t$ は「価格改定、採用、投資、製品リリース、広告配分、セキュリティ投資」などの意思決定になる。報酬は売上や利益だけでなく、リスクの罰則（期待損失）を入れてよい（第12章の制約付き最適化）。</p>
<h3 id="1522-複数の意思決定マルコフゲーム（Markov-game）">15.2.2　複数の意思決定：マルコフゲーム（Markov game）</h3>
<p>CEO/COO/CTO/CFO のように複数エージェントが同時に意思決定する場合、枠組みは <strong>マルコフゲーム（Markov game）</strong>（または確率ゲーム）になる。これは一般化されたMDPで、エージェント $i=1,\dots,n$ がそれぞれ行動 $a_t^i$ を選び、状態は共同行動 $\mathbf{a}_t=(a_t^1,\dots,a_t^n)$ に依存して遷移する。</p>
<p>$$ P(s_{t+1}\mid s_t, \mathbf{a}_t) $$</p>
<p>また報酬も各エージェントごとに $r^i(s_t,\mathbf{a}_t)$ を持つ。これが、会社シミュレーションにおける「利害の違い」や「役割の違い」を表現する最小の数学である。第9章で述べた通り、現実の会議では利害は必ずしも敵対ではないが、完全一致でもない。その中間（部分協調・部分競争）が普通である。マルコフゲームはその中間も扱える。</p>
<p>さらに、エージェントが環境を完全には観測できないなら、<strong>部分観測マルコフゲーム</strong>になり、各エージェントは観測 $o_t^i$ を受け取る。これは部分観測マルコフ決定過程（POMDP）の多エージェント版であり、信念状態（belief）という概念が重要になる（Kaelbling et al., 1998  <a href="https://doi.org/10.1016/S0004-3702%2898%2900023-X" target="_blank">https://doi.org/10.1016/S0004-3702(98)00023-X</a> ）。会社では、全員が全情報を持つことは稀なので、部分観測を前提にした設計の方が現実に近い。00023-X）。会社では、全員が全情報を持つことは稀なので、部分観測を前提にした設計の方が現実に近い。)</p>
<hr>
<h2 id="153-因果推論の二つの言語構造的因果モデルと潜在結果">15.3　因果推論の二つの言語：構造的因果モデルと潜在結果</h2>
<p>会社シミュレーションで「介入効果」を扱うには、因果推論（causal inference）の枠組みが必要になる。因果推論には、強い関係を持ちつつ表現が異なる二つの代表的枠組みがある。</p>
<p>第一が <strong>構造的因果モデル（Structural Causal Model: SCM）</strong>で、Judea Pearl によって体系化された（Pearl, 2009  <a href="https://doi.org/10.1017/CBO9780511803161" target="_blank">https://doi.org/10.1017/CBO9780511803161</a> ）。第二が <strong>潜在結果（potential outcomes）</strong> または Rubin の因果モデルである（Rubin, 1974  <a href="https://doi.org/10.1037/h0037350" target="_blank">https://doi.org/10.1037/h0037350</a> 、教科書として Imbens & Rubin, 2015  <a href="https://doi.org/10.1017/CBO9781139025751" target="_blank">https://doi.org/10.1017/CBO9781139025751</a> ）。</p>
<p>両者は対立というより、同じ問題を違う言葉で書く道具である。人物らしいAIをシミュレーションへ接続するなら、両方の直観が役立つ。</p>
<h3 id="1531-SCM方程式としての因果">15.3.1　SCM：方程式としての因果</h3>
<p>SCMでは、世界の変数 $X_1,\dots,X_d$ を、因果グラフ（有向非巡回グラフ：DAG）上の方程式として表す。各変数は親変数 $PA_i$ と外生ノイズ $U_i$ の関数で</p>
<p>$$ X_i = f_i(PA_i, U_i) $$</p>
<p>と書かれる。この集合が構造方程式である。介入 $do(X_j=x)$ は、「$X_j$ の方程式を切って $X_j=x$ に置き換える」という操作として定義される。これが、予測 $P(Y\mid X=x)$ と介入 $P(Y\mid do(X=x))$ の違いを明確にする（Pearl, 1995  <a href="https://doi.org/10.1093/biomet/82.4.669" target="_blank">https://doi.org/10.1093/biomet/82.4.669</a> ）。</p>
<p>会社を例にすると、需要 $D$、価格 $P$、品質 $Q$、広告 $A$ があるとき、単純化すれば</p>
<p>$$ D = f_D(P,Q,A,U_D), \quad Q = f_Q(\text{tech debt}, \text{headcount}, U_Q) $$</p>
<p>のように書ける。ここで価格を介入で変えるとは、価格を決める方程式（例えば「原価＋マージン」）を切って $P=p$ に固定することになる。この定義があると、「価格が高い会社ほど品質も高いから需要が高い」という共通原因があっても、介入として価格を固定したときに需要がどう変わるかを別物として考えられる。</p>
<h3 id="1532-潜在結果反実仮想としての因果">15.3.2　潜在結果：反実仮想としての因果</h3>
<p>潜在結果の枠組みでは、介入（処置）を $T\in{0,1}$ のような変数で表し、個体（ここでは会社やチーム、あるいはユーザー） $i$ について、処置が0のときの結果 $Y_i(0)$、処置が1のときの結果 $Y_i(1)$ を考える。因果効果は、例えば平均処置効果（Average Treatment Effect: ATE）</p>
<p>$$ \mathrm{ATE} = \mathbb{E}[Y(1)-Y(0)$$ として定義される（Imbens & Rubin, 2015）。ここで核心は、「同じ $i$ について $Y_i(0)$ と $Y_i(1)$ を同時に観測できない」という反事実の問題である。だからこそランダム化実験や仮定が必要になる。</p>
<p>会社シミュレーションに翻訳すると、「価格を上げた世界」と「価格を上げなかった世界」を同じ会社で同時に観測できないため、シミュレーションはその“反実仮想世界”を生成する装置として働く。ただし、装置が正しいとは限らない。装置が正しいかどうかは、次節以降の校正と検証（verification/validation）に依存する。</p>
<hr>
<h2 id="154-環境モデルの二大流儀システムダイナミクスとエージェントベースモデル">15.4　環境モデルの二大流儀：システムダイナミクスとエージェントベースモデル</h2>
<p>会社や社会をシミュレーションするには、環境（市場や組織）そのもののモデルが必要である。ここには大きく二つの伝統がある。どちらが正しいというより、目的が違う。</p>
<h3 id="1541-システムダイナミクス（System-Dynamics）">15.4.1　システムダイナミクス（System Dynamics）</h3>
<p><strong>システムダイナミクス（System Dynamics: SD）</strong>は、在庫（stock）と流量（flow）で、連続時間または離散時間のダイナミクスを記述する方法である。Forrester の産業ダイナミクスに起源があり（Forrester, 1961）、経営や政策の学習に広く使われてきた（Sterman, 2000  <a href="https://mitpress.mit.edu/9780262194402/business-dynamics/" target="_blank">https://mitpress.mit.edu/9780262194402/business-dynamics/</a> ）。</p>
<p>最小の離散時間モデルとして、キャッシュ $C_t$ を考えると</p>
<p>$$ C_{t+1} = C_t + R_t - E_t $$</p>
<p>のように書ける。ここで $R_t$ は収入、$E_t$ は支出である。さらに需要 $D_t$ が価格 $P_t$ と品質 $Q_t$ に依存するなら、例えば</p>
<p>$$ D_{t+1} = D_t + \alpha \cdot \mathrm{Marketing}_t - \beta \cdot \mathrm{Churn}_t $$</p>
<p>のような差分方程式を重ねていく。SDの強みは、少数の状態変数で全体像を把握し、フィードバック（正帰還・負帰還）によって起きる非直感的な挙動を理解できる点にある。例えば採用増による開発速度向上が、教育コストで一時的に逆効果になる、といった現象を、フィードバックとしてモデル化できる。</p>
<p>一方でSDは、個々の意思決定者の異質性や局所相互作用（現場の摩擦、部門間の情報非対称）を表しにくい。人物らしいエージェントを複数動かす本書の目的では、SDだけだと「人物らしさがどこにも出ない」モデルになりやすい。</p>
<h3 id="1542-エージェントベースモデル（Agent-Based-Model）">15.4.2　エージェントベースモデル（Agent-Based Model）</h3>
<p><strong>エージェントベースモデル（Agent-Based Model: ABM）</strong>は、個々の主体（エージェント）に行動規則を持たせ、その相互作用からマクロな現象を生成する方法である。社会シミュレーションの古典として Epstein & Axtell の *Growing Artificial Societies* がある（Epstein & Axtell, 1996  <a href="https://mitpress.mit.edu/9780262050531/growing-artificial-societies/" target="_blank">https://mitpress.mit.edu/9780262050531/growing-artificial-societies/</a> ）。</p>
<p>ABMの強みは、異なる役割や価値観を持つ人物（CEO/COO/CTO/CFO、現場、顧客、競合）を同じ枠組みで表現でき、局所相互作用が全体へ波及する様子（例えば誤情報、文化、同調）を自然に再現できる点にある。逆に弱みは、パラメータが増えやすく、同定（どのパラメータが本当か）の難しさが急激に増える点である。</p>
<p>人物らしいAIをABMの中核に置く場合、エージェントの行動規則は「手書きのif文」ではなく、言語モデル＋記憶＋ツール＋会議制度という複合体になる。これは表現力が高いが、同時に「何が原因でその挙動が出たか」が分かりにくい。したがってABMにLLMを入れるときは、後述する感度分析と検証、そしてログによる説明責任が不可欠になる。</p>
<h3 id="1543-現実的解SD×ABMのハイブリッド">15.4.3　現実的解：SD×ABMのハイブリッド</h3>
<p>会社シミュレーションの実務では、SDとABMをハイブリッドにするのが扱いやすいことが多い。例えば、マクロ状態（需要、売上、キャッシュ、ブランド）をSDの差分方程式で表し、意思決定（価格、投資、採用）をABM（人物らしい会議）で決める。つまり、</p>
<p>1) 会議（複数エージェント）が意思決定 $\mathbf{a}_t$ を出す 2) 環境（SD）が $\mathbf{a}_t$ を受けて状態 $s_{t+1}$ を更新する 3) 次の会議は $s_{t+1}$ を見て意思決定する</p>
<p>というループにする。これは第13章の統合アーキテクチャを、「外部環境が状態遷移を担う」形に拡張したものだ。</p>
<hr>
<h2 id="155-校正（calibration）シミュレーションを現実データに“接地”する">15.5　校正（calibration）：シミュレーションを現実データに“接地”する</h2>
<p>シミュレーションを意思決定に使うなら、環境モデルのパラメータ $\theta$ を現実に合わせる必要がある。これを校正（calibration）と呼ぶ。校正ができていないシミュレーションは、反実仮想を語っているように見えて、単なる作り話になりやすい。特にデジタルツインでは、作り話は「本人がそう言った」に見えてしまうため、危険度が上がる（第12章）。</p>
<h3 id="1551-最小の校正式観測統計量の一致としての推定">15.5.1　最小の校正式：観測統計量の一致としての推定</h3>
<p>観測データを $x_{\text{obs}}$、シミュレータ（環境モデル）を $x\sim p(x\mid \theta)$ と書く。理想的には、尤度 $p(x_{\text{obs}}\mid \theta)$ を最大化して</p>
<p>$$ \hat{\theta} = \arg\max_\theta \ p(x_{\text{obs}}\mid \theta) $$</p>
<p>で推定したい。しかしABMや複雑な環境では尤度が解析的に書けない、あるいは計算できないことが多い。そこで実務では、観測データを要約した統計量 (s$x$) を設計し、観測統計量 $s_{\text{obs}}=s(x_{\text{obs}})$ と、シミュレーション統計量 $s(\theta)=\mathbb{E}[s(x)\mid \theta]$ を近づける、という形を取ることが多い。</p>
<p>最小には、重み行列 $W$ を用いた二乗誤差で</p>
<p>$$ \hat{\theta}=\arg\min_\theta \ \left| s(\theta)-s_{\text{obs}}\right|_{W}^{2} \quad\text{where}\quad |v|_{W}^{2}=v^\top W v $$</p>
<p>のように書ける。ここで重要なのは、統計量 $s(\cdot)$ が「意思決定に関係する特徴」を含むように設計されていることだ。例えば売上の平均だけ合わせても、季節性やショック耐性が合わなければ、政策介入の評価は壊れる。</p>
<h3 id="1552-シミュレーションベース推論（SBI）とABC尤度がない世界のベイズ推定">15.5.2　シミュレーションベース推論（SBI）とABC：尤度がない世界のベイズ推定</h3>
<p>尤度が計算できないときの代表的手法が、近似ベイズ計算（Approximate Bayesian Computation: ABC）である。ABCは、観測統計量に近いシミュレーションだけを受け入れて、事後分布 $p(\theta\mid x_{\text{obs}})$ を近似する（Beaumont et al., 2002）。最も単純なABCの手続きは、事前分布から $\theta$ をサンプルし、シミュレーションして統計量距離が $\varepsilon$ 以下なら採用する、というものだ。</p>
<p>$$ \theta \sim p(\theta),\quad x\sim p(x\mid \theta),\quad \text{accept if } \rho(s(x), s_{\text{obs}}) \le \varepsilon $$</p>
<p>これにより、尤度がなくても「観測に整合する $\theta$ の分布」を得られる。近年は、ニューラルネットでこの推論を効率化するシミュレーションベース推論（Simulation-Based Inference: SBI）が発展しており、サーベイとして Cranmer et al.（2020）が参考になる（ <a href="https://arxiv.org/abs/1911.01429" target="_blank">https://arxiv.org/abs/1911.01429</a> ）。</p>
<p>会社シミュレーションにおいてベイズ推定が重要なのは、「パラメータが分からない」こと自体を不確実性として保持できるからである。点推定 $\hat{\theta}$ だけで反実仮想を出すと、確信過剰な意思決定になりやすい。事後分布 $p(\theta\mid x_{\text{obs}})$ を持てば、介入効果の分布 $p(\Delta Y\mid do(\cdot))$ をサンプルして、リスク（損失）の上振れまで含めて意思決定できる。</p>
<hr>
<h2 id="156-検証（verification）と妥当化（validation）シミュレーションを信じる条件を作る">15.6　検証（verification）と妥当化（validation）：シミュレーションを信じる条件を作る</h2>
<p>シミュレーションは“正しいかどうか”というより、“何に対して有用か”で評価すべきだ、という態度が重要である。これは統計学の有名な警句「すべてのモデルは間違っているが、役に立つものもある」に対応する（Box, 1976  <a href="https://doi.org/10.1080/01621459.1976.10480949" target="_blank">https://doi.org/10.1080/01621459.1976.10480949</a> ）。ただし、役に立つかどうかを判断するには、最低限の検証と妥当化が必要になる。</p>
<p>ここで用語を区別する。検証（verification）は「実装が仕様通りに動くか」であり、妥当化（validation）は「モデルが現実を目的に十分な程度で表しているか」である。検証はソフトウェア工学に近く、妥当化は科学実験に近い。</p>
<p>妥当化で典型的に行うのは、過去データへのバックテスト（backtesting）である。例えば、過去の四半期データを使ってパラメータを校正し、その次の四半期を予測し、統計量が合うかをチェックする。さらに重要なのは、単一の統計量ではなく、複数のスタイライズド・ファクト（stylized facts：典型的に成り立つ特徴）を同時に満たすかを見ることである。売上の平均は合うが、変動の大きさやショック回復が合わない、といったモデルは、介入評価で壊れやすい。</p>
<p>シミュレーションの検証・妥当化に関する実務的整理としては、Sargent のサーベイがよく参照される（Sargent, 2013 “Verification and Validation of Simulation Models”  <a href="https://doi.org/10.1057/jos.2013.10" target="_blank">https://doi.org/10.1057/jos.2013.10</a> ）。ここで強調されるのは、妥当化は「合格／不合格」の一発判定ではなく、目的と範囲を明確にした上で段階的に信頼を積み上げるプロセスである、という点だ。</p>
<hr>
<h2 id="157-不確実性と感度分析シミュレーション結果を「一本の物語」にしない">15.7　不確実性と感度分析：シミュレーション結果を「一本の物語」にしない</h2>
<p>人物らしいAIは、流暢な物語を作るのが得意である。だからこそ危険でもある。会社シミュレーションの出力を、一本の未来予測として提示すると、ユーザーはそれを真実だと思いやすい。しかしシミュレーションは不確実性の塊であり、特にパラメータ不確実性と構造不確実性が大きい。したがって、結果は分布として扱い、感度分析で「何に敏感か」を明示すべきである。</p>
<h3 id="1571-不確実性伝播介入効果の分布を出す">15.7.1　不確実性伝播：介入効果の分布を出す</h3>
<p>介入効果を $\Delta = Y_{do(X=x_1)} - Y_{do(X=x_0)}$ のように定義すると、パラメータ $\theta$ に不確実性があるとき、$\Delta$ も分布になる。ベイズ推定で事後分布 $p(\theta\mid x_{\text{obs}})$ を得ているなら、</p>
<p>\int p(\Delta\mid \theta), p(\theta\mid $x_{$\text{obs}$$}), d\theta ]</p>
<p>として介入効果の不確実性を評価できる。実装上は、$\theta$ を事後からサンプルしてシミュレーションを回し、$\Delta$ のサンプル分布を作ればよい。人物らしいAIがユーザーに提示すべきなのは、単一の結論よりも「効果の中心（平均や中央値）」「不確実性（分散や信用区間）」「最悪ケース（下側の分位点）」である。これは第10章の校正（calibration）と同じ思想を、シミュレーションへ拡張したものだ。</p>
<h3 id="1572-グローバル感度分析Sobol-指数で「何が効いているか」を測る">15.7.2　グローバル感度分析：Sobol 指数で「何が効いているか」を測る</h3>
<p>感度分析には局所（微分）とグローバル（分布）がある。会社シミュレーションは非線形で相互作用が強いので、グローバル感度分析が重要になる。その代表が <strong>Sobol 指数</strong>である（Sobol, 2001  <a href="https://doi.org/10.1016/S0378-4754%2800%2900270-6" target="_blank">https://doi.org/10.1016/S0378-4754(00)00270-6</a> 、体系的整理として00270-6、体系的整理として) Saltelli et al., 2008  <a href="https://doi.org/10.1002/9780470725184" target="_blank">https://doi.org/10.1002/9780470725184</a> ）。</p>
<p>出力 $Y=f(\theta_1,\dots,\theta_d)$ の分散を $\mathrm{Var}(Y)$ とし、パラメータ $\theta_i$ の寄与を分散分解で表す。一次のSobol指数は</p>
<p>$$S_i = \frac{\mathrm{Var}\left(\mathbb{E}[Y\mid \theta_i]\right)}{\mathrm{Var}(Y)}$$ であり、「$\theta_i$ だけを固定したときに残る平均的影響」がどれだけ分散を説明するかを示す。相互作用を含む総合寄与（total effect）も定義できる。これを使うと、「シミュレーション結果が不確実なのは、どの仮定が効いているからか」を定量的に示せる。</p>
<p>人物らしいAIを使う意味は、結果を物語として語ることではなく、意思決定者が「何を確かめれば不確実性が減るか」を理解できるようにすることだ。Sobol指数のような感度分析は、まさに「次に集めるべき情報（ツールで確認すべき情報）」を導く。これは第8章のツール利用と直結する。</p>
<hr>
<h2 id="158-政策評価としてのシミュレーションログデータとオフポリシー評価">15.8　政策評価としてのシミュレーション：ログデータとオフポリシー評価</h2>
<p>会社には過去の意思決定ログがある。価格改定の履歴、採用計画、広告配分、障害対応、会議議事録などである。これらを使って「別の方策ならどうだったか」を評価したいとき、強化学習では <strong>オフポリシー評価（Off-Policy Evaluation: OPE）</strong>と呼ぶ。OPEは、ある方策 $\mu$（実際に行われた方策）で収集されたログから、別の方策 $\pi$ の期待性能を推定する問題である。</p>
<h3 id="1581-重要度サンプリング確率比で補正する">15.8.1　重要度サンプリング：確率比で補正する</h3>
<p>最も基本の推定は重要度サンプリング（importance sampling）である。軌跡（trajectory） $\tau=(s_0,a_0,s_1,a_1,\dots)$ の下での累積報酬を $G(\tau)$ とし、ログ方策を $\mu$、評価したい方策を $\pi$ とすると、</p>
<p>$$\mathbb{E}_{\tau\sim \mu}\left[w(\tau),G(\tau)\right], \quad w(\tau)=\prod_{t}\frac{\pi(a_t\mid s_t)}{\mu(a_t\mid s_t)}$$ となる。これにより、$\mu$ のログでも $\pi$ の期待値を推定できる。だが実務では $w(\tau)$ の分散が爆発しやすい（確率比の積が不安定）ため、そのまま使うのは難しい。</p>
<h3 id="1582-Doubly-Robustモデルと比率の両方を使う">15.8.2　Doubly Robust：モデルと比率の両方を使う</h3>
<p>分散問題を抑える代表的手法が <strong>Doubly Robust（DR）推定</strong>である。DRは、環境モデル（価値関数近似）と重要度比の両方を使い、どちらかが正しければ不偏性（あるいは低バイアス）を保つ性質を狙う。強化学習の文脈での整理として Jiang & Li（2016）がよく引用される（ <a href="https://arxiv.org/abs/1511.03722" target="_blank">https://arxiv.org/abs/1511.03722</a> ）。また高信頼（confidence interval）を付けたOPEの研究として Thomas et al.（2016）も参考になる（ <a href="https://arxiv.org/abs/1606.00949" target="_blank">https://arxiv.org/abs/1606.00949</a> ）。</p>
<p>会社の意思決定にOPEを適用する価値は、「環境シミュレータを作る前に」、ログから安全に方策比較ができる可能性があることだ。逆に言えば、シミュレーションが十分に妥当化できない段階では、OPEや因果推論（差の差、傾向スコアなど）を併用し、「どの結論がデータから支持され、どの結論が仮定に依存しているか」を分離することが重要になる。</p>
<hr>
<h2 id="159-会社シミュレーションの限界同定不能性とGoodhart問題">15.9　会社シミュレーションの限界：同定不能性とGoodhart問題</h2>
<p>ここまでの理論は強力だが、会社シミュレーションには避けがたい限界がある。限界を理解しないと、人物らしいAIが“それっぽい結論”で人間を強く誤導する。</p>
<p>第一の限界は同定不能性（identifiability）である。データが有限で、観測できない変数（文化、士気、暗黙知、政治）が多いと、異なるモデルやパラメータが同じ観測を説明してしまう。つまり、観測だけでは「どの世界が本当か」が決められない。これは因果推論でよくある問題で、仮定（無交絡、操作変数、前門後門条件など）なしには解けない。</p>
<p>第二の限界は最適化の歪みである。シミュレーションを使ってKPI（指標）を最適化すると、指標自体が壊れることがある。これは Goodhart の法則（“When a measure becomes a target, it ceases to be a good measure”）や Campbell の法則として知られる。人物らしいAIが会議で「KPIを最大化する」提案ばかり出すと、短期売上は上がっても、長期信頼や文化が壊れるといった現象が起きる。したがって、シミュレーションの目的関数（報酬）は単一指標ではなく、多目的（第10章）として設計し、制約（第12章）を明示的に入れる必要がある。</p>
<p>第三の限界は、モデルが人間の意味世界を完全には表せないことだ。例えば「ブランド毀損」や「採用市場の評判」のような変数は、数式化が難しい。ここでは、完全な数理モデルを目指すより、シミュレーションを“思考実験の補助”として位置づけ、反実仮想の不確実性を明示し、意思決定者が前提を吟味できるようにすることが現実的である。</p>
<hr>
<h2 id="1510-通し例CEO/COO/CTO/CFO-会議シミュレーションを「介入比較」に変える">15.10　通し例：CEO/COO/CTO/CFO 会議シミュレーションを「介入比較」に変える</h2>
<p>最後に、本章の内容を通し例に接続する。会社シミュレーションの最小形は、次のループである。</p>
<p>時刻 $t$ に環境状態 $s_t$（売上、解約、キャッシュ、障害率、採用状況、競合圧力など）が与えられる。CEO/COO/CTO/CFO のエージェント会議が、意思決定 $\mathbf{a}_t$（価格、投資、採用、リリース計画）を出す。環境モデルが $\mathbf{a}_t$ を受け、確率遷移で $s_{t+1}$ を生成する。これを繰り返す。</p>
<p>ここで「介入比較」を行うには、同じ初期状態 $s_0$ から、異なる方策（異なる会議制度、異なる意思決定ルール、あるいは同じ会議だが別の意思決定）を走らせ、結果分布を比較する。例えば、価格を上げる方策 $\pi_1$ と、価格を据え置く方策 $\pi_0$ を比較し、利益の差だけでなく、解約率や障害率、採用難易度、事故期待損失まで含めた多目的ベクトルを比較する。</p>
<p>このとき重要なのは、結論を「上げるべき／上げないべき」で断言せず、介入効果の分布として提示し、どの仮定（パラメータ）が結果に効いているか（Sobol指数）を示し、次に確認すべき情報（追加の観測や実験）を提案することだ。これが、人物らしいAIを“賢い占い師”ではなく、“意思決定の科学的補助”として使うための姿勢である。</p>
<p>架空キャラを社内に一人置く場合も同じで、そのキャラは「結論を断言する人格」ではなく、「不確実性を見える化し、議論の前提と追加情報を整理する人格」として設計する方が、長期的に組織にとって役に立つ。人間らしさとは、確信満々で語ることではなく、分からないことを分からないと言い、確かめるべきことを提案できることでもある。</p>
<hr>
<h2 id="まとめ">まとめ</h2>
<p>本章では、会社／社会シミュレーションを「反実仮想の実験装置」にするために、環境を確率過程として定式化する（MDP・マルコフゲーム）、介入と反実仮想を扱う因果推論（SCM・潜在結果）、シミュレーションの校正と妥当化（calibration/validation）、そして不確実性と感度分析（不確実性伝播・Sobol指数）を体系化した。</p>
<p>人物らしいAIをシミュレーションに使う価値は、未来を当てることではなく、仮定を明示し、不確実性を分布として扱い、どの情報が意思決定を左右するかを明らかにすることにある。ここまでの章を通じて、人物らしさは単なる会話の自然さではなく、意思決定の一貫性、根拠への接続、検証可能性、更新の規律、社会的責任と結びつく、という姿勢が一貫してきた。本章はその姿勢を、会社／社会シミュレーションという最も誤解されやすい応用領域へ持ち込むための要点である。</p>
<hr>
<h2 id="参考文献（リンク）">参考文献（リンク）</h2>
<p>Pearl, J. (1995). “Causal Diagrams for Empirical Research.” *Biometrika*. <a href="https://doi.org/10.1093/biomet/82.4.669" target="_blank">https://doi.org/10.1093/biomet/82.4.669</a>)</p>
<p>Pearl, J. (2009). *Causality: Models, Reasoning, and Inference (2nd ed.).* Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511803161" target="_blank">https://doi.org/10.1017/CBO9780511803161</a>)</p>
<p>Rubin, D. B. (1974). “Estimating causal effects of treatments in randomized and nonrandomized studies.” *Journal of Educational Psychology*. <a href="https://doi.org/10.1037/h0037350" target="_blank">https://doi.org/10.1037/h0037350</a>)</p>
<p>Imbens, G. W., & Rubin, D. B. (2015). *Causal Inference for Statistics, Social, and Biomedical Sciences.* Cambridge University Press. <a href="https://doi.org/10.1017/CBO9781139025751" target="_blank">https://doi.org/10.1017/CBO9781139025751</a>)</p>
<p>Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). “Planning and Acting in Partially Observable Stochastic Domains.” *Artificial Intelligence*. <a href="https://doi.org/10.1016/S0004-3702%2898%2900023-X" target="_blank">https://doi.org/10.1016/S0004-3702(98)00023-X</a> 00023-X)</p>
<p>Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction (2nd ed.).*（無料公開PDF） <a href="https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf" target="_blank">https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf</a>)</p>
<p>Forrester, J. W. (1961). *Industrial Dynamics.* MIT Press.（出版社ページ例） <a href="https://mitpress.mit.edu/9780262560030/industrial-dynamics/" target="_blank">https://mitpress.mit.edu/9780262560030/industrial-dynamics/</a>)</p>
<p>Sterman, J. D. (2000). *Business Dynamics: Systems Thinking and Modeling for a Complex World.* MIT Press. <a href="https://mitpress.mit.edu/9780262194402/business-dynamics/" target="_blank">https://mitpress.mit.edu/9780262194402/business-dynamics/</a>)</p>
<p>Epstein, J. M., & Axtell, R. (1996). *Growing Artificial Societies: Social Science from the Bottom Up.* MIT Press. <a href="https://mitpress.mit.edu/9780262050531/growing-artificial-societies/" target="_blank">https://mitpress.mit.edu/9780262050531/growing-artificial-societies/</a>)</p>
<p>Beaumont, M. A., Zhang, W., & Balding, D. J. (2002). “Approximate Bayesian Computation in Population Genetics.” *Genetics*. <a href="https://doi.org/10.1093/genetics/162.4.2025" target="_blank">https://doi.org/10.1093/genetics/162.4.2025</a>)</p>
<p>Cranmer, K., Brehmer, J., & Louppe, G. (2020). “The frontier of simulation-based inference.” <a href="https://arxiv.org/abs/1911.01429" target="_blank">https://arxiv.org/abs/1911.01429</a>)</p>
<p>Sargent, R. G. (2013). “Verification and validation of simulation models.” *Journal of Simulation*. <a href="https://doi.org/10.1057/jos.2013.10" target="_blank">https://doi.org/10.1057/jos.2013.10</a>)</p>
<p>Sobol, I. M. (2001). “Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates.” *Mathematics and Computers in Simulation*. <a href="https://doi.org/10.1016/S0378-4754%2800%2900270-6" target="_blank">https://doi.org/10.1016/S0378-4754(00)00270-6</a>)</p>
<p>Saltelli, A., Ratto, M., Andres, T., et al. (2008). *Global Sensitivity Analysis: The Primer.* Wiley. <a href="https://doi.org/10.1002/9780470725184" target="_blank">https://doi.org/10.1002/9780470725184</a>)</p>
<p>Jiang, N., & Li, L. (2016). “Doubly Robust Off-policy Value Evaluation for Reinforcement Learning.” <a href="https://arxiv.org/abs/1511.03722" target="_blank">https://arxiv.org/abs/1511.03722</a>)</p>
<p>Thomas, P. S., Theocharous, G., & Ghavamzadeh, M. (2016). “High Confidence Off-Policy Evaluation.” <a href="https://arxiv.org/abs/1606.00949" target="_blank">https://arxiv.org/abs/1606.00949</a>)</p>
<p>Box, G. E. P. (1976). “Science and Statistics.” *Journal of the American Statistical Association*. <a href="https://doi.org/10.1080/01621459.1976.10480949" target="_blank">https://doi.org/10.1080/01621459.1976.10480949</a>)</p>
    </main>

    <!-- Settings Modal -->
    <div class="settings-modal" id="settingsModal">
        <div class="settings-modal-content">
            <button class="settings-close" onclick="toggleSettingsModal()">×</button>
            <h3>設定</h3>
            <div class="settings-modal-item">
                <div class="theme-toggle-section">
                    <span style="font-size: 0.9rem; font-weight: 500;">表示モード</span>
                    <button class="theme-toggle" onclick="toggleTheme()">
                        <div class="theme-toggle-icon" id="themeIcon">☀</div>
                        <span id="themeText">ライト</span>
                    </button>
                </div>
            </div>
            <div class="settings-modal-item">
                <button class="reset-progress" onclick="resetProgress()">進捗をリセット</button>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false}
                ],
                throwOnError: false,
                trust: true
            });

        });

        // Mermaid initialization moved to page-based system
    </script>
    <script>
        // Reading Progress Management
        const STORAGE_KEY = 'persona-text-reading-progress';
        
        // Pagination state
        let currentPageIndex = 0;
        let sections = [];
        let tocItems = [];
        
        // Initialize reading progress functionality
        function initReadingProgress() {
            // Transform existing TOC items to include checkboxes
            transformTOCItems();
            
            // Initialize pagination
            initPagination();
            
            // Load saved progress
            loadProgress();
            
            // Add event listeners
            addCheckboxListeners();
            
            // Update progress display
            updateProgressDisplay();
            
            // Add keyboard listeners
            addKeyboardListeners();
        }
        
        // Initialize pagination system
        function initPagination() {
            // Get all sections (h1, h2, h3)
            const headings = document.querySelectorAll('main h1, main h2, main h3');
            sections = Array.from(headings);
            
            // Get TOC items for navigation
            tocItems = Array.from(document.querySelectorAll('.toc-checkbox'));
            
            // Create page sections
            createPageSections();
            
            // Show first page
            showPage(0);
        }
        
        // Create page sections by wrapping content between headings
        function createPageSections() {
            const main = document.querySelector('main');
            if (!main) return;
            
            // First, completely remove all existing mermaid processing
            document.querySelectorAll('.mermaid').forEach(el => {
                // Store original text content
                const originalText = el.getAttribute('data-original-text') || el.textContent;
                el.innerHTML = originalText;
                el.removeAttribute('data-processed');
                el.classList.remove('mermaid');
                el.classList.add('mermaid-source');
                el.setAttribute('data-original-text', originalText);
            });
            
            // Get all children of main and store them
            const allChildren = Array.from(main.children);
            
            sections.forEach((heading, index) => {
                const pageDiv = document.createElement('div');
                pageDiv.className = 'page-section';
                pageDiv.id = `page-${index}`;
                
                // Find the position of current heading in allChildren
                const headingIndex = allChildren.indexOf(heading);
                
                // Find the position of next heading (if any)
                let nextHeadingIndex = allChildren.length;
                for (let i = headingIndex + 1; i < allChildren.length; i++) {
                    if (['H1', 'H2', 'H3'].includes(allChildren[i].tagName)) {
                        nextHeadingIndex = i;
                        break;
                    }
                }
                
                // Add heading to page
                const headingClone = heading.cloneNode(true);
                pageDiv.appendChild(headingClone);
                
                // Add all elements between this heading and the next
                for (let i = headingIndex + 1; i < nextHeadingIndex; i++) {
                    const element = allChildren[i];
                    if (!element) continue;
                    
                    const clone = element.cloneNode(true);
                    
                    // Handle mermaid source elements
                    if (clone.classList && clone.classList.contains('mermaid-source')) {
                        const originalText = clone.getAttribute('data-original-text') || clone.textContent;
                        clone.innerHTML = originalText;
                        clone.classList.remove('mermaid-source');
                        clone.classList.add('mermaid-pending');
                        clone.removeAttribute('data-processed');
                        clone.setAttribute('data-mermaid-content', originalText);
                    }
                    
                    // Check for nested mermaid elements
                    const nestedMermaid = clone.querySelectorAll('.mermaid-source');
                    nestedMermaid.forEach(nested => {
                        const originalText = nested.getAttribute('data-original-text') || nested.textContent;
                        nested.innerHTML = originalText;
                        nested.classList.remove('mermaid-source');
                        nested.classList.add('mermaid-pending');
                        nested.removeAttribute('data-processed');
                        nested.setAttribute('data-mermaid-content', originalText);
                    });
                    
                    pageDiv.appendChild(clone);
                }
                
                // Add navigation buttons to each page
                const navDiv = document.createElement('div');
                navDiv.className = 'page-navigation';
                navDiv.innerHTML = `
                    <button class="nav-button" data-direction="-1">← 前へ</button>
                    <button class="nav-button" data-direction="1">次へ →</button>
                `;
                
                // Add event listeners to navigation buttons
                const buttons = navDiv.querySelectorAll('.nav-button');
                buttons.forEach(button => {
                    button.addEventListener('click', function() {
                        const direction = parseInt(this.getAttribute('data-direction'));
                        navigatePage(direction);
                    });
                });
                
                pageDiv.appendChild(navDiv);
                main.appendChild(pageDiv);
            });
            
            // Hide all original content
            allChildren.forEach(element => {
                if (element && !element.classList.contains('page-section')) {
                    element.style.display = 'none';
                }
            });
        }
        
        // Show specific page
        function showPage(index, autoCheck = true) {
            if (index < 0 || index >= sections.length) return;
            
            currentPageIndex = index;
            
            // Hide all pages
            document.querySelectorAll('.page-section').forEach(page => {
                page.classList.remove('active');
            });
            
            // Show current page
            const currentPage = document.getElementById(`page-${index}`);
            if (currentPage) {
                currentPage.classList.add('active');
                currentPage.scrollIntoView({ behavior: 'smooth', block: 'start' });
                
                // Process mermaid diagrams in the current page only
                processMermaidInPage(currentPage);
            }
            
            // Auto-check current section only if autoCheck is true
            if (autoCheck) {
                autoCheckCurrentSection();
            }
            
            // Update navigation
            updateNavigation();
            
            
            // Update TOC active state
            updateTOCActiveState();
        }
        
        // Process mermaid diagrams only for the current page
        function processMermaidInPage(pageElement) {
            if (!window.mermaid) return;
            
            const mermaidElements = pageElement.querySelectorAll('.mermaid-pending');
            if (mermaidElements.length > 0) {
                mermaidElements.forEach((element, index) => {
                    try {
                        const content = element.getAttribute('data-mermaid-content') || element.textContent;
                        element.classList.remove('mermaid-pending');
                        element.classList.add('mermaid');
                        element.innerHTML = content;
                        element.removeAttribute('data-processed');
                        
                        // Generate unique ID for this element
                        const uniqueId = `mermaid-${Date.now()}-${index}`;
                        element.id = uniqueId;
                        
                        // Render this specific mermaid element
                        setTimeout(() => {
                            window.mermaid.render(uniqueId + '-svg', content).then(({svg}) => {
                                element.innerHTML = svg;
                                element.setAttribute('data-processed', 'true');
                            }).catch(e => {
                                console.warn('Mermaid rendering error:', e);
                                element.innerHTML = `<pre class="mermaid-error">${content}</pre>`;
                            });
                        }, 50 * index); // Stagger rendering to avoid conflicts
                    } catch (e) {
                        console.warn('Mermaid processing error:', e);
                    }
                });
            }
        }
        
        // Navigate to next/previous page
        function navigatePage(direction) {
            const newIndex = currentPageIndex + direction;
            if (newIndex >= 0 && newIndex < sections.length) {
                showPage(newIndex);
            }
        }
        
        // Auto-check current section when viewing
        function autoCheckCurrentSection() {
            if (currentPageIndex >= 0 && currentPageIndex < tocItems.length) {
                const checkbox = tocItems[currentPageIndex];
                if (checkbox && !checkbox.checked) {
                    checkbox.checked = true;
                    
                    // Update visual state
                    const tocItem = checkbox.closest('.toc-item');
                    if (tocItem) {
                        tocItem.classList.add('completed');
                    }
                    
                    // Save progress
                    const sectionId = checkbox.getAttribute('data-section');
                    if (sectionId) {
                        saveProgress(sectionId, true);
                    }
                    
                    // Update progress display
                    updateProgressDisplay();
                }
            }
        }
        
        // Update navigation buttons
        function updateNavigation() {
            const currentPage = document.getElementById(`page-${currentPageIndex}`);
            if (!currentPage) return;
            
            const prevButtons = currentPage.querySelectorAll('[data-direction="-1"]');
            const nextButtons = currentPage.querySelectorAll('[data-direction="1"]');
            
            prevButtons.forEach(button => {
                button.disabled = currentPageIndex <= 0;
            });
            
            nextButtons.forEach(button => {
                button.disabled = currentPageIndex >= sections.length - 1;
            });
        }
        
        
        // Update TOC active state
        function updateTOCActiveState() {
            // Remove active class from all TOC links
            document.querySelectorAll('.toc-list a').forEach(link => {
                link.classList.remove('active');
            });
            
            // Add active class to current section
            if (currentPageIndex >= 0 && currentPageIndex < tocItems.length) {
                const checkbox = tocItems[currentPageIndex];
                if (checkbox) {
                    const tocItem = checkbox.closest('.toc-item');
                    if (tocItem) {
                        const link = tocItem.querySelector('a');
                        if (link) {
                            link.classList.add('active');
                        }
                    }
                }
            }
        }
        
        // Add keyboard navigation
        function addKeyboardListeners() {
            document.addEventListener('keydown', function(event) {
                // Don't interfere if user is typing in an input
                if (event.target.tagName === 'INPUT' || event.target.tagName === 'TEXTAREA') {
                    return;
                }
                
                switch(event.key) {
                    case 'ArrowLeft':
                    case 'j':
                    case 'J':
                        event.preventDefault();
                        navigatePage(-1);
                        break;
                    case 'ArrowRight':
                    case 'k':
                    case 'K':
                        event.preventDefault();
                        navigatePage(1);
                        break;
                }
            });
        }
        
        // Transform existing TOC items to include checkboxes
        function transformTOCItems() {
            const tocList = document.querySelector('.toc-list');
            if (!tocList) return;
            
            const items = tocList.querySelectorAll('li');
            items.forEach(item => {
                const anchor = item.querySelector('a');
                if (!anchor) return;
                
                // Skip if already transformed
                if (item.querySelector('.toc-checkbox')) return;
                
                // Get section ID from href
                const href = anchor.getAttribute('href');
                if (!href || !href.startsWith('#')) return;
                
                const sectionId = href.substring(1);
                
                // Create wrapper div
                const wrapper = document.createElement('div');
                wrapper.className = 'toc-item';
                
                // Create checkbox
                const checkbox = document.createElement('input');
                checkbox.type = 'checkbox';
                checkbox.className = 'toc-checkbox';
                checkbox.setAttribute('data-section', sectionId);
                
                // Insert wrapper and move anchor
                item.insertBefore(wrapper, anchor);
                wrapper.appendChild(checkbox);
                wrapper.appendChild(anchor);
            });
        }
        
        // Add event listeners to checkboxes and TOC links
        function addCheckboxListeners() {
            const checkboxes = document.querySelectorAll('.toc-checkbox');
            checkboxes.forEach((checkbox, index) => {
                // Checkbox change event
                checkbox.addEventListener('change', function() {
                    const sectionId = this.getAttribute('data-section');
                    const isChecked = this.checked;
                    
                    // Update visual state
                    const tocItem = this.closest('.toc-item');
                    if (tocItem) {
                        if (isChecked) {
                            tocItem.classList.add('completed');
                        } else {
                            tocItem.classList.remove('completed');
                        }
                    }
                    
                    // Save progress
                    saveProgress(sectionId, isChecked);
                    
                    // Update progress display
                    updateProgressDisplay();
                });
                
                // TOC link click event for navigation
                const tocItem = checkbox.closest('.toc-item');
                if (tocItem) {
                    const link = tocItem.querySelector('a');
                    if (link) {
                        link.addEventListener('click', function(event) {
                            event.preventDefault();
                            // Find the corresponding page index
                            const href = this.getAttribute('href');
                            if (href) {
                                const targetId = href.substring(1);
                                const pageIndex = findPageIndexByTargetId(targetId);
                                if (pageIndex >= 0) {
                                    showPage(pageIndex, false); // Don't auto-check when clicking TOC
                                    
                                    // Close TOC on mobile after navigation
                                    if (window.innerWidth <= 768) {
                                        const toc = document.getElementById('toc');
                                        toc.classList.remove('show');
                                    }
                                }
                            }
                        });
                    }
                }
            });
        }
        
        // Find page index by target section ID
        function findPageIndexByTargetId(targetId) {
            return sections.findIndex(section => {
                return section.id === targetId || 
                       section.textContent.includes(targetId.replace(/-/g, ' '));
            });
        }
        
        // Save progress to localStorage
        function saveProgress(sectionId, isCompleted) {
            let progress = getStoredProgress();
            
            if (isCompleted) {
                progress[sectionId] = true;
            } else {
                delete progress[sectionId];
            }
            
            localStorage.setItem(STORAGE_KEY, JSON.stringify(progress));
        }
        
        // Get progress from localStorage
        function getStoredProgress() {
            try {
                const stored = localStorage.getItem(STORAGE_KEY);
                return stored ? JSON.parse(stored) : {};
            } catch (e) {
                console.error('Error reading progress from localStorage:', e);
                return {};
            }
        }
        
        // Load progress from localStorage
        function loadProgress() {
            const progress = getStoredProgress();
            
            Object.keys(progress).forEach(sectionId => {
                if (progress[sectionId]) {
                    const checkbox = document.querySelector(`[data-section="${sectionId}"]`);
                    if (checkbox) {
                        checkbox.checked = true;
                        const tocItem = checkbox.closest('.toc-item');
                        if (tocItem) {
                            tocItem.classList.add('completed');
                        }
                    }
                }
            });
        }
        
        // Update progress bar and text
        function updateProgressDisplay() {
            const checkboxes = document.querySelectorAll('.toc-checkbox');
            const checkedBoxes = document.querySelectorAll('.toc-checkbox:checked');
            
            const total = checkboxes.length;
            const completed = checkedBoxes.length;
            const percentage = total > 0 ? Math.round((completed / total) * 100) : 0;
            
            // Update progress bar
            const progressFill = document.getElementById('progressFill');
            if (progressFill) {
                progressFill.style.width = percentage + '%';
            }
            
            // Update progress text
            const progressText = document.getElementById('progressText');
            if (progressText) {
                progressText.textContent = `${completed} / ${total} 完了 (${percentage}%)`;
            }
        }
        
        // Reset all progress
        function resetProgress() {
            if (confirm('読書進捗をリセットしますか？この操作は取り消せません。')) {
                // Clear localStorage
                localStorage.removeItem(STORAGE_KEY);
                
                // Uncheck all checkboxes
                const checkboxes = document.querySelectorAll('.toc-checkbox');
                checkboxes.forEach(checkbox => {
                    checkbox.checked = false;
                    const tocItem = checkbox.closest('.toc-item');
                    if (tocItem) {
                        tocItem.classList.remove('completed');
                    }
                });
                
                // Update display
                updateProgressDisplay();
            }
        }
        
        // TOC toggle functionality
        function toggleTOC() {
            const toc = document.getElementById('toc');
            
            if (toc.classList.contains('show')) {
                // Hide TOC
                toc.classList.remove('show');
            } else {
                // Show TOC
                toc.classList.add('show');
            }
        }

        // Settings modal toggle functionality
        function toggleSettingsModal() {
            const modal = document.getElementById('settingsModal');
            
            if (modal.classList.contains('open')) {
                modal.classList.remove('open');
            } else {
                modal.classList.add('open');
            }
        }

        // Close modal when clicking outside
        document.addEventListener('click', function(event) {
            const modal = document.getElementById('settingsModal');
            const settingsButton = document.querySelector('.header-settings');
            
            if (modal && modal.classList.contains('open') && 
                !modal.querySelector('.settings-modal-content').contains(event.target) &&
                !settingsButton.contains(event.target)) {
                modal.classList.remove('open');
            }
        });

        // Theme toggle functionality
        function toggleTheme() {
            const body = document.body;
            const themeIcon = document.getElementById('themeIcon');
            const themeText = document.getElementById('themeText');
            
            if (body.getAttribute('data-theme') === 'dark') {
                // Switch to light mode
                body.removeAttribute('data-theme');
                themeIcon.textContent = '☀';
                themeText.textContent = 'ライト';
                localStorage.setItem('theme', 'light');
            } else {
                // Switch to dark mode
                body.setAttribute('data-theme', 'dark');
                themeIcon.textContent = '🌙';
                themeText.textContent = 'ダーク';
                localStorage.setItem('theme', 'dark');
            }
        }

        // Load saved theme
        function loadSavedTheme() {
            const savedTheme = localStorage.getItem('theme');
            const themeIcon = document.getElementById('themeIcon');
            const themeText = document.getElementById('themeText');
            
            if (savedTheme === 'dark') {
                document.body.setAttribute('data-theme', 'dark');
                themeIcon.textContent = '🌙';
                themeText.textContent = 'ダーク';
            } else {
                themeIcon.textContent = '☀';
                themeText.textContent = 'ライト';
            }
        }

        // Initialize when DOM is loaded
        document.addEventListener('DOMContentLoaded', function() {
            // Disable automatic mermaid initialization
            if (window.mermaid) {
                window.mermaid.initialize({ 
                    startOnLoad: false,
                    theme: 'default',
                    securityLevel: 'loose'
                });
                
                // Clear any existing mermaid processing
                document.querySelectorAll('.mermaid[data-processed]').forEach(el => {
                    const originalText = el.textContent;
                    el.innerHTML = originalText;
                    el.removeAttribute('data-processed');
                    el.classList.remove('mermaid');
                    el.classList.add('mermaid-source');
                    el.setAttribute('data-original-text', originalText);
                });
            }
            
            // Load saved theme
            loadSavedTheme();
            
            initReadingProgress();
        });
        
        // Auto-save every 30 seconds (as backup)
        setInterval(function() {
            // This is just to ensure data persistence, actual saving happens on checkbox change
            const progress = getStoredProgress();
            if (Object.keys(progress).length > 0) {
                localStorage.setItem(STORAGE_KEY, JSON.stringify(progress));
            }
        }, 30000);
    </script>
</body>
</html>